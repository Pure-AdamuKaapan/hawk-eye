-- Logs begin at Thu 2019-10-24 16:54:34 UTC, end at Mon 2022-09-05 18:38:37 UTC. --
Sep 05 13:58:26 ip-10-13-112-170.pwx.dev.purestorage.com systemd[1]: Starting Lightweight Kubernetes...
Sep 05 13:58:26 ip-10-13-112-170.pwx.dev.purestorage.com sh[6830]: + /usr/bin/systemctl is-enabled --quiet nm-cloud-setup.service
Sep 05 13:58:26 ip-10-13-112-170.pwx.dev.purestorage.com sh[6830]: Failed to get unit file state for nm-cloud-setup.service: No such file or directory
Sep 05 13:58:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:26Z" level=info msg="Acquiring lock file /var/lib/rancher/k3s/data/.lock"
Sep 05 13:58:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:26Z" level=info msg="Preparing data dir /var/lib/rancher/k3s/data/577968fa3d58539cc4265245941b7be688833e6bf5ad7869fa2afe02f15f1cd2"
Sep 05 13:58:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:28Z" level=info msg="Starting k3s agent v1.24.4+k3s1 (c3f830e9)"
Sep 05 13:58:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:28Z" level=info msg="Running load balancer k3s-agent-load-balancer 127.0.0.1:6444 -> [10.13.112.158:6443]"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Module overlay was already loaded"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Module nf_conntrack was already loaded"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Module iptable_nat was already loaded"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_established' to 86400"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Set sysctl 'net/netfilter/nf_conntrack_tcp_timeout_close_wait' to 3600"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Set sysctl 'net/bridge/bridge-nf-call-iptables' to 1"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Logging containerd to /var/lib/rancher/k3s/agent/containerd/containerd.log"
Sep 05 13:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:29Z" level=info msg="Running containerd -c /var/lib/rancher/k3s/agent/etc/containerd/config.toml -a /run/k3s/containerd/containerd.sock --state /run/k3s/containerd --root /var/lib/rancher/k3s/agent/containerd"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Containerd is now running"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Getting list of apiserver endpoints from server"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Updating load balancer k3s-agent-load-balancer default server address -> 10.13.112.158:6443"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Connecting to proxy" url="wss://10.13.112.158:6443/v1-k3s/connect"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Running kubelet --address=0.0.0.0 --anonymous-auth=false --authentication-token-webhook=true --authorization-mode=Webhook --cgroup-driver=cgroupfs --client-ca-file=/var/lib/rancher/k3s/agent/client-ca.crt --cloud-provider=external --cluster-dns=10.43.0.10 --cluster-domain=cluster.local --container-runtime-endpoint=unix:///run/k3s/containerd/containerd.sock --containerd=/run/k3s/containerd/containerd.sock --eviction-hard=imagefs.available<5%,nodefs.available<5% --eviction-minimum-reclaim=imagefs.available=10%,nodefs.available=10% --fail-swap-on=false --healthz-bind-address=127.0.0.1 --hostname-override=ip-10-13-112-170.pwx.dev.purestorage.com --kubeconfig=/var/lib/rancher/k3s/agent/kubelet.kubeconfig --node-labels= --pod-infra-container-image=rancher/mirrored-pause:3.6 --pod-manifest-path=/var/lib/rancher/k3s/agent/pod-manifests --read-only-port=0 --resolv-conf=/etc/resolv.conf --serialize-image-pulls=false --tls-cert-file=/var/lib/rancher/k3s/agent/serving-kubelet.crt --tls-private-key-file=/var/lib/rancher/k3s/agent/serving-kubelet.key"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: Flag --cloud-provider has been deprecated, will be removed in 1.24 or later, in favor of removing cloud provider code from Kubelet.
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: Flag --containerd has been deprecated, This is a cadvisor flag that was mistakenly registered with the Kubelet. Due to legacy concerns, it will follow the standard CLI deprecation timeline before being removed.
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: Flag --pod-infra-container-image has been deprecated, will be removed in 1.27. Image garbage collector will get sandbox image information from CRI.
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.281964    6839 server.go:192] "--pod-infra-container-image will not be pruned by the image garbage collector in kubelet and should also be set in the remote runtime"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Running kube-proxy --cluster-cidr=10.42.0.0/16 --conntrack-max-per-core=0 --conntrack-tcp-timeout-close-wait=0s --conntrack-tcp-timeout-established=0s --healthz-bind-address=127.0.0.1 --hostname-override=ip-10-13-112-170.pwx.dev.purestorage.com --kubeconfig=/var/lib/rancher/k3s/agent/kubeproxy.kubeconfig --proxy-mode=iptables"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.286169    6839 server.go:231] "Warning, all flags other than --config, --write-config-to, and --cleanup are deprecated, please begin using a config file ASAP"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.286852    6839 server.go:395] "Kubelet version" kubeletVersion="v1.24.4+k3s1"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.286881    6839 server.go:397] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.289922    6839 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/rancher/k3s/agent/client-ca.crt"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.294263    6839 server.go:644] "--cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulting to /"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.294621    6839 container_manager_linux.go:262] "Container manager verified user specified cgroup-root exists" cgroupRoot=[]
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.294689    6839 container_manager_linux.go:267] "Creating Container Manager object based on Node Config" nodeConfig={RuntimeCgroupsName: SystemCgroupsName: KubeletCgroupsName: KubeletOOMScoreAdj:-999 ContainerRuntime: CgroupsPerQOS:true CgroupRoot:/ CgroupDriver:cgroupfs KubeletRootDir:/var/lib/kubelet ProtectKernelDefaults:false NodeAllocatableConfig:{KubeReservedCgroupName: SystemReservedCgroupName: ReservedSystemCPUs: EnforceNodeAllocatable:map[pods:{}] KubeReserved:map[] SystemReserved:map[] HardEvictionThresholds:[{Signal:imagefs.available Operator:LessThan Value:{Quantity:<nil> Percentage:0.05} GracePeriod:0s MinReclaim:<nil>} {Signal:nodefs.available Operator:LessThan Value:{Quantity:<nil> Percentage:0.05} GracePeriod:0s MinReclaim:<nil>}]} QOSReserved:map[] ExperimentalCPUManagerPolicy:none ExperimentalCPUManagerPolicyOptions:map[] ExperimentalTopologyManagerScope:container ExperimentalCPUManagerReconcilePeriod:10s ExperimentalMemoryManagerPolicy:None ExperimentalMemoryManagerReservedMemory:[] ExperimentalPodPidsLimit:-1 EnforceCPULimits:true CPUCFSQuotaPeriod:100ms ExperimentalTopologyManagerPolicy:none}
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.294721    6839 topology_manager.go:133] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.294732    6839 container_manager_linux.go:302] "Creating device plugin manager" devicePluginEnabled=true
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.294802    6839 state_mem.go:36] "Initialized new in-memory state store"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.299423    6839 kubelet.go:376] "Attempting to sync node with API server"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.299444    6839 kubelet.go:267] "Adding static pod path" path="/var/lib/rancher/k3s/agent/pod-manifests"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.299473    6839 kubelet.go:278] "Adding apiserver pod source"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.299499    6839 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.300449    6839 kuberuntime_manager.go:239] "Container runtime initialized" containerRuntime="containerd" version="v1.6.6-k3s1" apiVersion="v1"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: W0905 13:58:30.300605    6839 probe.go:268] Flexvolume plugin directory at /usr/libexec/kubernetes/kubelet-plugins/volume/exec/ does not exist. Recreating.
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.306742    6839 server.go:1177] "Started kubelet"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.306923    6839 server.go:150] "Starting to listen" address="0.0.0.0" port=10250
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.307573    6839 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.307769    6839 volume_manager.go:289] "Starting Kubelet Volume Manager"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.307574    6839 server.go:410] "Adding debug handlers to kubelet server"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.308297    6839 cri_stats_provider.go:455] "Failed to get the info of the filesystem with mountpoint" err="unable to find data in memory cache" mountpoint="/var/lib/rancher/k3s/agent/containerd/io.containerd.snapshotter.v1.overlayfs"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.308347    6839 kubelet.go:1298] "Image garbage collection failed once. Stats initialization may not have completed yet" err="invalid capacity 0 on image filesystem"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.307853    6839 desired_state_of_world_populator.go:145] "Desired state populator starts to run"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.313449    6839 nodelease.go:49] "Failed to get node when trying to set owner ref to the node lease" err="nodes \"ip-10-13-112-170.pwx.dev.purestorage.com\" not found" node="ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.316584    6839 node.go:152] Failed to retrieve node info: nodes "ip-10-13-112-170.pwx.dev.purestorage.com" not found
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.351743    6839 cpu_manager.go:213] "Starting CPU manager" policy="none"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.351767    6839 cpu_manager.go:214] "Reconciling" reconcilePeriod="10s"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.351782    6839 state_mem.go:36] "Initialized new in-memory state store"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.352667    6839 kubelet_network_linux.go:76] "Initialized protocol iptables rules." protocol=IPv4
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.353516    6839 policy_none.go:49] "None policy: Start"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.354020    6839 memory_manager.go:168] "Starting memorymanager" policy="None"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.354038    6839 state_mem.go:35] "Initializing new in-memory state store"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.360735    6839 manager.go:610] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.360951    6839 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.361724    6839 eviction_manager.go:254] "Eviction manager: failed to get summary stats" err="failed to get node info: node \"ip-10-13-112-170.pwx.dev.purestorage.com\" not found"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.390127    6839 kubelet_network_linux.go:76] "Initialized protocol iptables rules." protocol=IPv6
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.390153    6839 status_manager.go:161] "Starting to sync pod status with apiserver"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.390171    6839 kubelet.go:1986] "Starting kubelet main sync loop"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.390207    6839 kubelet.go:2010] "Skipping pod synchronization" err="PLEG is not healthy: pleg has yet to be successful"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.407936    6839 kubelet.go:2424] "Error getting node" err="node \"ip-10-13-112-170.pwx.dev.purestorage.com\" not found"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.409061    6839 kubelet_node_status.go:70] "Attempting to register node" node="ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.508326    6839 kubelet.go:2424] "Error getting node" err="node \"ip-10-13-112-170.pwx.dev.purestorage.com\" not found"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:30.608951    6839 kubelet.go:2424] "Error getting node" err="node \"ip-10-13-112-170.pwx.dev.purestorage.com\" not found"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.706791    6839 kubelet_node_status.go:73] "Successfully registered node" node="ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Annotations and labels have been set successfully on node: ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Starting flannel with backend vxlan"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Flannel found PodCIDR assigned for node ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="The interface eth0 with ipv4 address 10.13.112.170 will be used by flannel"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.719024    6839 kube.go:121] Waiting 10m0s for node controller to sync
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.719058    6839 kube.go:402] Starting kube subnet manager
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.810091    6839 kuberuntime_manager.go:1095] "Updating runtime config through cri with podcidr" CIDR="10.42.2.0/24"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.810920    6839 kubelet_network.go:60] "Updating Pod CIDR" originalPodCIDR="" newPodCIDR="10.42.2.0/24"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="Starting the netpol controller"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:30Z" level=info msg="k3s agent is up and running"
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com systemd[1]: Started Lightweight Kubernetes.
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.824423    6839 network_policy_controller.go:162] Starting network policy controller
Sep 05 13:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:30.851880    6839 network_policy_controller.go:174] Starting network policy controller full sync goroutine
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.300817    6839 apiserver.go:52] "Watching apiserver"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.419395    6839 node.go:163] Successfully retrieved node IP: 10.13.112.170
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.419437    6839 server_others.go:138] "Detected node IP" address="10.13.112.170"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425328    6839 server_others.go:206] "Using iptables Proxier"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425369    6839 server_others.go:213] "kube-proxy running in dual-stack mode" ipFamily=IPv4
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425382    6839 server_others.go:214] "Creating dualStackProxier for iptables"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425399    6839 server_others.go:501] "Detect-local-mode set to ClusterCIDR, but no IPv6 cluster CIDR defined, , defaulting to no-op detect-local for IPv6"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425429    6839 proxier.go:259] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425586    6839 proxier.go:259] "Setting route_localnet=1, use nodePortAddresses to filter loopback addresses for NodePorts to skip it https://issues.k8s.io/90259"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425831    6839 server.go:661] "Version info" version="v1.24.4+k3s1"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.425849    6839 server.go:663] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.426871    6839 config.go:226] "Starting endpoint slice config controller"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.426890    6839 shared_informer.go:255] Waiting for caches to sync for endpoint slice config
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.427004    6839 config.go:444] "Starting node config controller"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.427019    6839 shared_informer.go:255] Waiting for caches to sync for node config
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.427050    6839 config.go:317] "Starting service config controller"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.427069    6839 shared_informer.go:255] Waiting for caches to sync for service config
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.513755    6839 reconciler.go:159] "Reconciler: start to sync state"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.527137    6839 shared_informer.go:262] Caches are synced for service config
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.527209    6839 shared_informer.go:262] Caches are synced for node config
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.527217    6839 shared_informer.go:262] Caches are synced for endpoint slice config
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.720043    6839 kube.go:128] Node controller sync successful
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.720122    6839 vxlan.go:138] VXLAN config: VNI=1 Port=0 GBP=false Learning=false DirectRouting=false
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.731802    6839 kube.go:357] Skip setting NodeNetworkUnavailable
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:31Z" level=info msg="Wrote flannel subnet file to /run/flannel/subnet.env"
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: time="2022-09-05T13:58:31Z" level=info msg="Running flannel backend."
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.733358    6839 vxlan_network.go:61] watching for new subnet leases
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:31.737310    6839 iptables.go:199] Failed to bootstrap IPTables: failed to apply partial iptables-restore unable to run iptables-restore (, ): exit status 4
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.738235    6839 iptables.go:312] Some iptables rules are missing; deleting and recreating rules
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 13:58:31.740785    6839 iptables.go:199] Failed to bootstrap IPTables: failed to apply partial iptables-restore unable to run iptables-restore (, ): exit status 4
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.740980    6839 iptables.go:177] bootstrap done
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.741674    6839 iptables.go:312] Some iptables rules are missing; deleting and recreating rules
Sep 05 13:58:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:31.745941    6839 iptables.go:177] bootstrap done
Sep 05 13:58:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 13:58:40.974085    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:00:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:44.069152    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:00:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:44.109079    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-g6hlc\" (UniqueName: \"kubernetes.io/projected/18599dbc-cab3-44aa-9ab2-cf11b0f481f8-kube-api-access-g6hlc\") pod \"stork-7ff877c64-4ddf8\" (UID: \"18599dbc-cab3-44aa-9ab2-cf11b0f481f8\") " pod="kube-system/stork-7ff877c64-4ddf8"
Sep 05 14:00:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:44.372717    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:00:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:51.926961    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:00:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:51.956644    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"socket-dir\" (UniqueName: \"kubernetes.io/host-path/0996c745-955b-4cb5-a1b8-31603c5872b0-socket-dir\") pod \"px-csi-ext-55db7dcbc4-n4mnh\" (UID: \"0996c745-955b-4cb5-a1b8-31603c5872b0\") " pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh"
Sep 05 14:00:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:51.956693    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-dkpx8\" (UniqueName: \"kubernetes.io/projected/0996c745-955b-4cb5-a1b8-31603c5872b0-kube-api-access-dkpx8\") pod \"px-csi-ext-55db7dcbc4-n4mnh\" (UID: \"0996c745-955b-4cb5-a1b8-31603c5872b0\") " pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh"
Sep 05 14:00:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:52.229770    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.648603    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.719292    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.729289    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.907792    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"containerd-k3s\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-containerd-k3s\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.907839    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-kktnq\" (UniqueName: \"kubernetes.io/projected/245427ef-4b2b-4e32-86a3-c113ce9dd374-kube-api-access-kktnq\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.907863    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-xw6l9\" (UniqueName: \"kubernetes.io/projected/f523f8fb-1dcb-431b-8a9f-3c264c58b148-kube-api-access-xw6l9\") pod \"portworx-api-lqjz4\" (UID: \"f523f8fb-1dcb-431b-8a9f-3c264c58b148\") " pod="kube-system/portworx-api-lqjz4"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.907882    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"procmount\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-procmount\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.907934    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"sysdmount\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-sysdmount\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908001    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"dbusmount\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-dbusmount\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908022    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"varlibosd\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-varlibosd\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908061    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"journalmount2\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-journalmount2\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908111    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"registration-dir\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-registration-dir\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908154    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"containerddir\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-containerddir\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908174    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"crioconf\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-crioconf\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908206    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"optpwx\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-optpwx\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908226    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"diagsdump\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-diagsdump\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908252    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcpwx\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-etcpwx\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908301    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"journalmount1\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-journalmount1\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908338    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"criosock\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-criosock\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908383    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"dockersock\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-dockersock\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:00:59.908421    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"csi-driver-path\" (UniqueName: \"kubernetes.io/host-path/245427ef-4b2b-4e32-86a3-c113ce9dd374-csi-driver-path\") pod \"tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff\" (UID: \"245427ef-4b2b-4e32-86a3-c113ce9dd374\") " pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff"
Sep 05 14:01:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:00.033173    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:00.321738    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:00.651931    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:06.667539    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:07.670731    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:08.674220    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:08.674817    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:09.678480    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:09.678733    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:10.680548    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:01:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:01:11.682671    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:02:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:02:14.391653    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:02:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:02:23.391677    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:02:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:02:23.391938    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:02:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:02:26.391383    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:03:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:03:24.391543    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:03:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:03:28.391524    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:03:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:03:39.391057    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:03:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:03:41.390809    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.390844    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.589630    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593801    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"varcache\" (UniqueName: \"kubernetes.io/host-path/362a4b17-1c39-4233-9bda-ae762fb7609e-varcache\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593843    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"journalmount2\" (UniqueName: \"kubernetes.io/host-path/362a4b17-1c39-4233-9bda-ae762fb7609e-journalmount2\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593866    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcpwx\" (UniqueName: \"kubernetes.io/host-path/362a4b17-1c39-4233-9bda-ae762fb7609e-etcpwx\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593884    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"proxy-config\" (UniqueName: \"kubernetes.io/configmap/362a4b17-1c39-4233-9bda-ae762fb7609e-proxy-config\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593904    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ccm-config\" (UniqueName: \"kubernetes.io/configmap/362a4b17-1c39-4233-9bda-ae762fb7609e-ccm-config\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593923    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"tls-certificate\" (UniqueName: \"kubernetes.io/configmap/362a4b17-1c39-4233-9bda-ae762fb7609e-tls-certificate\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.593941    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pure-telemetry-certs\" (UniqueName: \"kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.595859    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-2lcdm\" (UniqueName: \"kubernetes.io/projected/362a4b17-1c39-4233-9bda-ae762fb7609e-kube-api-access-2lcdm\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:27.596119    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"varcores\" (UniqueName: \"kubernetes.io/host-path/362a4b17-1c39-4233-9bda-ae762fb7609e-varcores\") pod \"px-telemetry-phonehome-l7wws\" (UID: \"362a4b17-1c39-4233-9bda-ae762fb7609e\") " pod="kube-system/px-telemetry-phonehome-l7wws"
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:27.698903    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:27.701053    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:04:28.19895901 +0000 UTC m=+359.874035427 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:04:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:28.201545    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:28.201628    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:04:29.201609276 +0000 UTC m=+360.876685678 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:04:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:29.207230    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:29.207350    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:04:31.207327005 +0000 UTC m=+362.882403426 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:04:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:31.220361    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:31.220473    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:04:35.220446713 +0000 UTC m=+366.895523132 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:04:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:35.246369    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:35.246448    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:04:43.246433169 +0000 UTC m=+374.921509584 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:04:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:43.295721    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:43.295795    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:04:59.295779422 +0000 UTC m=+390.970855824 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:04:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:43.391061    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:04:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:50.035712    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:04:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:57.391083    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:04:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:04:57.391377    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:04:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:59.299017    6839 secret.go:188] Couldn't get secret kube-system/pure-telemetry-certs: secret "pure-telemetry-certs" not found
Sep 05 14:04:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:04:59.299098    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs podName:362a4b17-1c39-4233-9bda-ae762fb7609e nodeName:}" failed. No retries permitted until 2022-09-05 14:05:31.299083186 +0000 UTC m=+422.974159589 (durationBeforeRetry 32s). Error: MountVolume.SetUp failed for volume "pure-telemetry-certs" (UniqueName: "kubernetes.io/secret/362a4b17-1c39-4233-9bda-ae762fb7609e-pure-telemetry-certs") pod "px-telemetry-phonehome-l7wws" (UID: "362a4b17-1c39-4233-9bda-ae762fb7609e") : secret "pure-telemetry-certs" not found
Sep 05 14:05:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:02.759202    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:05.591227    6839 csi_plugin.go:99] kubernetes.io/csi: Trying to validate a new CSI Driver with name: pxd.portworx.com endpoint: /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock versions: 1.0.0
Sep 05 14:05:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:05.591268    6839 csi_plugin.go:112] kubernetes.io/csi: Register new plugin with name: pxd.portworx.com at endpoint: /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock
Sep 05 14:05:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:05:05.606936    6839 nodeinfomanager.go:561] Invalid attach limit value 0 cannot be added to CSINode object for "pxd.portworx.com"
Sep 05 14:05:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:30.323781    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:31.494244    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:36.210664    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:37.214462    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:41.224254    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:42.225909    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:05:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:05:51.828018    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:06:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:06:15.391620    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:06:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:06:17.391102    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:06:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:06:18.391564    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:06:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:06:57.391342    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:06:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:06:59.391236    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:07:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:07:32.391114    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:07:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:07:42.391714    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:07:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:07:44.391949    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:08:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:04.391275    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:08:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:05.391780    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:08:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:09.126789    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:08:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:09.286360    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-mhp4m\" (UniqueName: \"kubernetes.io/projected/f7b162dc-66a5-4274-9ef1-89e1539ea084-kube-api-access-mhp4m\") pod \"es-load-769678797c-9b87n\" (UID: \"f7b162dc-66a5-4274-9ef1-89e1539ea084\") " pod="elasticsearch-setupteardown-0-09-05-14h07m47s/es-load-769678797c-9b87n"
Sep 05 14:08:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:13.766254    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:08:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:13.918163    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-05b19920-4646-470a-a4c8-19aa5247fe89\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"postgres-646f6f7487-w48fp\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") " pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp"
Sep 05 14:08:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:13.918227    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-xlvf9\" (UniqueName: \"kubernetes.io/projected/6552d0e5-606f-41d1-bf7f-478d7e7e60c1-kube-api-access-xlvf9\") pod \"postgres-646f6f7487-w48fp\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") " pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp"
Sep 05 14:08:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:14.021143    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:08:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:14.023428    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-05b19920-4646-470a-a4c8-19aa5247fe89\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"postgres-646f6f7487-w48fp\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/013aea1becf7bdada82556cbe0049b5841e28bb08404af1672389d6f22aed069/globalmount\"" pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp"
Sep 05 14:08:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:14.074274    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:08:14.57424151 +0000 UTC m=+586.249317934 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:14.665820    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:08:15.665788364 +0000 UTC m=+587.340864805 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:15.822009    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:08:17.821976614 +0000 UTC m=+589.497053032 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:17.906855    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:08:21.906820906 +0000 UTC m=+593.581897325 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:22.518412    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:08:30.518385205 +0000 UTC m=+602.193461627 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:31.074601    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:08:47.074571376 +0000 UTC m=+618.749647791 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:39.924090    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.022835    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-251d77bd-f5ac-4c82-9aca-f767058167e4\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"nginx-6b5d97d5cb-vfp6l\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") " pod="nginx-sharedv4-setupteardown-0-09-05-14h07m47s/nginx-6b5d97d5cb-vfp6l"
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.022903    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"nginx-6b5d97d5cb-vfp6l\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") " pod="nginx-sharedv4-setupteardown-0-09-05-14h07m47s/nginx-6b5d97d5cb-vfp6l"
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.022934    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4m84z\" (UniqueName: \"kubernetes.io/projected/6441dfed-9989-4d74-abfd-0e5d3ae66995-kube-api-access-4m84z\") pod \"nginx-6b5d97d5cb-vfp6l\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") " pod="nginx-sharedv4-setupteardown-0-09-05-14h07m47s/nginx-6b5d97d5cb-vfp6l"
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.126199    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.126274    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-251d77bd-f5ac-4c82-9aca-f767058167e4\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"nginx-6b5d97d5cb-vfp6l\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/fb7a950c5cc4988077f9656465ac58fc546cc96dd2792fedd3bbc32e0193ee19/globalmount\"" pod="nginx-sharedv4-setupteardown-0-09-05-14h07m47s/nginx-6b5d97d5cb-vfp6l"
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.126204    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:08:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:40.126378    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"nginx-6b5d97d5cb-vfp6l\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/01462ace0e26036575b27bc65f658aca938832f7f0f56939324f6162137f38a4/globalmount\"" pod="nginx-sharedv4-setupteardown-0-09-05-14h07m47s/nginx-6b5d97d5cb-vfp6l"
Sep 05 14:08:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:41.391233    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.134787    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.245416    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-3e439b06-b619-4695-8722-6f9355498835\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"vdbench-sharedv4-74b9988cdd-tddpj\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") " pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-tddpj"
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.245525    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-969d753c-aecf-40c2-b29d-33d09a422c19\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"vdbench-sharedv4-74b9988cdd-tddpj\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") " pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-tddpj"
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.245593    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-rm9ts\" (UniqueName: \"kubernetes.io/projected/10ec9604-1d90-404e-b703-5416e0cf99c0-kube-api-access-rm9ts\") pod \"vdbench-sharedv4-74b9988cdd-tddpj\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") " pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-tddpj"
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.347681    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.347736    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-969d753c-aecf-40c2-b29d-33d09a422c19\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"vdbench-sharedv4-74b9988cdd-tddpj\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/73c21d20771266b1e4a3f53037b8ed060d7223f8dcdec2aa419ab2184c81986f/globalmount\"" pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-tddpj"
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.347767    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:43.347802    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-3e439b06-b619-4695-8722-6f9355498835\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"vdbench-sharedv4-74b9988cdd-tddpj\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/dc72fd32ae02a45a1d9d178eb225f11b6c68e68f92d6165620e4add1bdb38a27/globalmount\"" pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-tddpj"
Sep 05 14:08:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:44.232598    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:08:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:44.559666    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9qzhd\" (UniqueName: \"kubernetes.io/projected/f992919f-d3a6-494d-9718-7632cc610ae7-kube-api-access-9qzhd\") pod \"vdbench-sharedv4-74b9988cdd-km4fv\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") " pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-km4fv"
Sep 05 14:08:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:45.827131    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:08:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:46.374530    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-mzxkg\" (UniqueName: \"kubernetes.io/projected/bbc12be1-fa09-4391-9bbf-2fa6c07e151a-kube-api-access-mzxkg\") pod \"vdbench-sharedv4-74b9988cdd-mddrn\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") " pod="vdbench-sharedv4-setupteardown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-mddrn"
Sep 05 14:08:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:08:47.770461    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:09:19.770429811 +0000 UTC m=+651.445506232 (durationBeforeRetry 32s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:08:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:49.391315    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:08:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:08:54.394812    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:09:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:09:06.393616    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:09:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:09:16.391359    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:09:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:09:20.884255    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:10:24.884213434 +0000 UTC m=+716.559289850 (durationBeforeRetry 1m4s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:10:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:10:03.391741    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:10:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:10:16.769143    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-xlvf9]: timed out waiting for the condition" pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp"
Sep 05 14:10:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:10:16.769210    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-xlvf9]: timed out waiting for the condition" pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp" podUID=6552d0e5-606f-41d1-bf7f-478d7e7e60c1
Sep 05 14:10:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:10:17.391701    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:10:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:10:19.390779    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:10:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:10:24.391606    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:10:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:10:26.056340    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:12:28.056310753 +0000 UTC m=+839.731387170 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:10:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:10:36.391198    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:11:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:11:05.392184    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:11:26.396188    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:11:29.390935    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:11:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:11:38.394584    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:11:40.391878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:12:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:07.390991    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:12:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:09.508764    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-mhp4m\" (UniqueName: \"kubernetes.io/projected/f7b162dc-66a5-4274-9ef1-89e1539ea084-kube-api-access-mhp4m\") pod \"f7b162dc-66a5-4274-9ef1-89e1539ea084\" (UID: \"f7b162dc-66a5-4274-9ef1-89e1539ea084\") "
Sep 05 14:12:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:09.527226    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f7b162dc-66a5-4274-9ef1-89e1539ea084-kube-api-access-mhp4m" (OuterVolumeSpecName: "kube-api-access-mhp4m") pod "f7b162dc-66a5-4274-9ef1-89e1539ea084" (UID: "f7b162dc-66a5-4274-9ef1-89e1539ea084"). InnerVolumeSpecName "kube-api-access-mhp4m". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:12:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:09.610088    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-mhp4m\" (UniqueName: \"kubernetes.io/projected/f7b162dc-66a5-4274-9ef1-89e1539ea084-kube-api-access-mhp4m\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:12:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:10.353180    6839 scope.go:110] "RemoveContainer" containerID="04d8df5bf17c68dfa9c122a264a57800cf893b2475b89c97b8603c305de4865a"
Sep 05 14:12:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:10.398037    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f7b162dc-66a5-4274-9ef1-89e1539ea084 path="/var/lib/kubelet/pods/f7b162dc-66a5-4274-9ef1-89e1539ea084/volumes"
Sep 05 14:12:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:12:29.052353    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:14:31.05230329 +0000 UTC m=+962.727379707 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "postgres-646f6f7487-w48fp" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:12:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:12:30.393817    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-xlvf9]: timed out waiting for the condition" pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp"
Sep 05 14:12:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:12:30.393932    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-xlvf9]: timed out waiting for the condition" pod="postgres-setupteardown-0-09-05-14h07m47s/postgres-646f6f7487-w48fp" podUID=6552d0e5-606f-41d1-bf7f-478d7e7e60c1
Sep 05 14:12:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:36.391758    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:12:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:39.391905    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:12:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:47.390884    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:12:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:12:53.391708    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:13:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:13:31.391100    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:13:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:13:56.391585    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:14:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:03.391201    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:14:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:05.391516    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:14:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:09.391249    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:14:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:33.391434    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.011792    6839 scope.go:110] "RemoveContainer" containerID="bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5"
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.017719    6839 scope.go:110] "RemoveContainer" containerID="bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5"
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:40.018272    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5\": not found" containerID="bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5"
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.018328    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5} err="failed to get container status \"bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5\": rpc error: code = NotFound desc = an error occurred when try to find container \"bc05d146a257e6e4ccd22444ebf2d15c6e588d03c265b4735c68bd015fbf08b5\": not found"
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.059631    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-xlvf9\" (UniqueName: \"kubernetes.io/projected/6552d0e5-606f-41d1-bf7f-478d7e7e60c1-kube-api-access-xlvf9\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.060386    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.081698    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/6552d0e5-606f-41d1-bf7f-478d7e7e60c1-kube-api-access-xlvf9" (OuterVolumeSpecName: "kube-api-access-xlvf9") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1"). InnerVolumeSpecName "kube-api-access-xlvf9". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:40.161123    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-xlvf9\" (UniqueName: \"kubernetes.io/projected/6552d0e5-606f-41d1-bf7f-478d7e7e60c1-kube-api-access-xlvf9\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:40.628074    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName:6552d0e5-606f-41d1-bf7f-478d7e7e60c1 nodeName:}" failed. No retries permitted until 2022-09-05 14:14:41.128037882 +0000 UTC m=+972.803114303 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes/kubernetes.io~csi/pvc-05b19920-4646-470a-a4c8-19aa5247fe89/mount
Sep 05 14:14:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:41.178977    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:41.418265    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName:6552d0e5-606f-41d1-bf7f-478d7e7e60c1 nodeName:}" failed. No retries permitted until 2022-09-05 14:14:42.418230038 +0000 UTC m=+974.093306456 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes/kubernetes.io~csi/pvc-05b19920-4646-470a-a4c8-19aa5247fe89/mount
Sep 05 14:14:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:42.498021    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:42.801317    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName:6552d0e5-606f-41d1-bf7f-478d7e7e60c1 nodeName:}" failed. No retries permitted until 2022-09-05 14:14:44.801287158 +0000 UTC m=+976.476363573 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes/kubernetes.io~csi/pvc-05b19920-4646-470a-a4c8-19aa5247fe89/mount
Sep 05 14:14:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:44.820116    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:45.232670    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName:6552d0e5-606f-41d1-bf7f-478d7e7e60c1 nodeName:}" failed. No retries permitted until 2022-09-05 14:14:49.232645193 +0000 UTC m=+980.907721617 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes/kubernetes.io~csi/pvc-05b19920-4646-470a-a4c8-19aa5247fe89/mount
Sep 05 14:14:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:49.270850    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:49.457421    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName:6552d0e5-606f-41d1-bf7f-478d7e7e60c1 nodeName:}" failed. No retries permitted until 2022-09-05 14:14:57.457388926 +0000 UTC m=+989.132465347 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes/kubernetes.io~csi/pvc-05b19920-4646-470a-a4c8-19aa5247fe89/mount
Sep 05 14:14:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:14:57.461929    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:14:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:14:57.707407    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920344019547246905 podName:6552d0e5-606f-41d1-bf7f-478d7e7e60c1 nodeName:}" failed. No retries permitted until 2022-09-05 14:15:13.707380831 +0000 UTC m=+1005.382457249 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes/kubernetes.io~csi/pvc-05b19920-4646-470a-a4c8-19aa5247fe89/mount
Sep 05 14:15:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:13.761783    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") pod \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\" (UID: \"6552d0e5-606f-41d1-bf7f-478d7e7e60c1\") "
Sep 05 14:15:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:13.978845    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^920344019547246905" (OuterVolumeSpecName: "postgredb") pod "6552d0e5-606f-41d1-bf7f-478d7e7e60c1" (UID: "6552d0e5-606f-41d1-bf7f-478d7e7e60c1"). InnerVolumeSpecName "pvc-05b19920-4646-470a-a4c8-19aa5247fe89". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:15:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:14.065285    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-05b19920-4646-470a-a4c8-19aa5247fe89\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:15:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:14.068693    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:15:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:14.069766    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-05b19920-4646-470a-a4c8-19aa5247fe89" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920344019547246905") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:15:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:14.166522    6839 reconciler.go:384] "Volume detached for volume \"pvc-05b19920-4646-470a-a4c8-19aa5247fe89\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920344019547246905\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:15:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:14.395171    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:15:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:22.391796    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:15:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:22.398127    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=6552d0e5-606f-41d1-bf7f-478d7e7e60c1 path="/var/lib/kubelet/pods/6552d0e5-606f-41d1-bf7f-478d7e7e60c1/volumes"
Sep 05 14:15:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:26.402271    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:15:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:33.391286    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:15:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:15:36.393058    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:16:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:28.391496    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:16:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:29.391203    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:16:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:33.391323    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:16:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:40.995529    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:40.995625    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-4m84z\" (UniqueName: \"kubernetes.io/projected/6441dfed-9989-4d74-abfd-0e5d3ae66995-kube-api-access-4m84z\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:40.996337    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.010102    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/6441dfed-9989-4d74-abfd-0e5d3ae66995-kube-api-access-4m84z" (OuterVolumeSpecName: "kube-api-access-4m84z") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995"). InnerVolumeSpecName "kube-api-access-4m84z". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.097770    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-4m84z\" (UniqueName: \"kubernetes.io/projected/6441dfed-9989-4d74-abfd-0e5d3ae66995-kube-api-access-4m84z\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:41.364718    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1005511893789026102 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:41.864691345 +0000 UTC m=+1093.539767759 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37/mount
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:41.368869    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^555410506377584416 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:41.868746853 +0000 UTC m=+1093.543823268 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-251d77bd-f5ac-4c82-9aca-f767058167e4/mount
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.446896    6839 scope.go:110] "RemoveContainer" containerID="f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386"
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.453334    6839 scope.go:110] "RemoveContainer" containerID="f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386"
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:41.453692    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386\": not found" containerID="f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386"
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.453727    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386} err="failed to get container status \"f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386\": rpc error: code = NotFound desc = an error occurred when try to find container \"f601c881b03f3b8ad2a010fca14c5c8152a07170405d1cbd52a750d31daeb386\": not found"
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.904713    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:41.904786    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:42.184679    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1005511893789026102 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:43.184653051 +0000 UTC m=+1094.859729467 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37/mount
Sep 05 14:16:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:43.216233    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:43.388867    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^555410506377584416 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:44.388840576 +0000 UTC m=+1096.063916990 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-251d77bd-f5ac-4c82-9aca-f767058167e4/mount
Sep 05 14:16:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:44.427978    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:44.429148    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1005511893789026102 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:46.429124794 +0000 UTC m=+1098.104201198 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37/mount
Sep 05 14:16:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:44.629237    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^555410506377584416 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:46.62921117 +0000 UTC m=+1098.304287585 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-251d77bd-f5ac-4c82-9aca-f767058167e4/mount
Sep 05 14:16:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:46.453190    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:46.655293    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:46.715451    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1005511893789026102 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:50.71542178 +0000 UTC m=+1102.390498197 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37/mount
Sep 05 14:16:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:46.855308    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^555410506377584416 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:50.855276872 +0000 UTC m=+1102.530353287 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-251d77bd-f5ac-4c82-9aca-f767058167e4/mount
Sep 05 14:16:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:49.391647    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:16:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:50.807723    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:50.911243    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:51.108238    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1005511893789026102 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:59.108203249 +0000 UTC m=+1110.783279670 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37/mount
Sep 05 14:16:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:51.227475    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^555410506377584416 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:16:59.227444258 +0000 UTC m=+1110.902520672 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-251d77bd-f5ac-4c82-9aca-f767058167e4/mount
Sep 05 14:16:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:53.391341    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:16:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:59.138510    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:16:59.241341    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:16:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:59.461605    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1005511893789026102 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:17:15.461579433 +0000 UTC m=+1127.136655836 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37/mount
Sep 05 14:16:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:16:59.592016    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^555410506377584416 podName:6441dfed-9989-4d74-abfd-0e5d3ae66995 nodeName:}" failed. No retries permitted until 2022-09-05 14:17:15.591978512 +0000 UTC m=+1127.267054930 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "nginx-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes/kubernetes.io~csi/pvc-251d77bd-f5ac-4c82-9aca-f767058167e4/mount
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.481156    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.686454    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"nginx-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") pod \"6441dfed-9989-4d74-abfd-0e5d3ae66995\" (UID: \"6441dfed-9989-4d74-abfd-0e5d3ae66995\") "
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.687964    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^1005511893789026102" (OuterVolumeSpecName: "nginx-persistent-storage-enc") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995"). InnerVolumeSpecName "pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.787974    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.792936    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.794158    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1005511893789026102") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.867826    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^555410506377584416" (OuterVolumeSpecName: "nginx-persistent-storage") pod "6441dfed-9989-4d74-abfd-0e5d3ae66995" (UID: "6441dfed-9989-4d74-abfd-0e5d3ae66995"). InnerVolumeSpecName "pvc-251d77bd-f5ac-4c82-9aca-f767058167e4". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.889034    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-251d77bd-f5ac-4c82-9aca-f767058167e4\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.889070    6839 reconciler.go:384] "Volume detached for volume \"pvc-a945884a-95ae-4b67-8ef1-ba3a7776de37\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1005511893789026102\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.893402    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.893958    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-251d77bd-f5ac-4c82-9aca-f767058167e4" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^555410506377584416") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:15.989909    6839 reconciler.go:384] "Volume detached for volume \"pvc-251d77bd-f5ac-4c82-9aca-f767058167e4\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^555410506377584416\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:17:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:22.397269    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=6441dfed-9989-4d74-abfd-0e5d3ae66995 path="/var/lib/kubelet/pods/6441dfed-9989-4d74-abfd-0e5d3ae66995/volumes"
Sep 05 14:17:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:30.394551    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:17:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:38.391985    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:17:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:17:52.391802    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:18:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:00.983376    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-9qzhd\" (UniqueName: \"kubernetes.io/projected/f992919f-d3a6-494d-9718-7632cc610ae7-kube-api-access-9qzhd\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:00.984761    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:00.985589    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:00.985679    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-rm9ts\" (UniqueName: \"kubernetes.io/projected/10ec9604-1d90-404e-b703-5416e0cf99c0-kube-api-access-rm9ts\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:00.987737    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:00.988338    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.000477    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/10ec9604-1d90-404e-b703-5416e0cf99c0-kube-api-access-rm9ts" (OuterVolumeSpecName: "kube-api-access-rm9ts") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0"). InnerVolumeSpecName "kube-api-access-rm9ts". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.002042    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/f992919f-d3a6-494d-9718-7632cc610ae7-kube-api-access-9qzhd" (OuterVolumeSpecName: "kube-api-access-9qzhd") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7"). InnerVolumeSpecName "kube-api-access-9qzhd". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.090318    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.091483    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.091573    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-mzxkg\" (UniqueName: \"kubernetes.io/projected/bbc12be1-fa09-4391-9bbf-2fa6c07e151a-kube-api-access-mzxkg\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.091640    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-rm9ts\" (UniqueName: \"kubernetes.io/projected/10ec9604-1d90-404e-b703-5416e0cf99c0-kube-api-access-rm9ts\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.091661    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-9qzhd\" (UniqueName: \"kubernetes.io/projected/f992919f-d3a6-494d-9718-7632cc610ae7-kube-api-access-9qzhd\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.156108    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/bbc12be1-fa09-4391-9bbf-2fa6c07e151a-kube-api-access-mzxkg" (OuterVolumeSpecName: "kube-api-access-mzxkg") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a"). InnerVolumeSpecName "kube-api-access-mzxkg". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.192706    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-mzxkg\" (UniqueName: \"kubernetes.io/projected/bbc12be1-fa09-4391-9bbf-2fa6c07e151a-kube-api-access-mzxkg\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:01.249139    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:01.749110692 +0000 UTC m=+1173.424187110 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:01.304886    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:01.804861884 +0000 UTC m=+1173.479938298 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:01.500278    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:02.000249765 +0000 UTC m=+1173.675326180 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.790895    6839 scope.go:110] "RemoveContainer" containerID="8a733541a8cbc3623826b8b09ffc5a1cc6c511974433853714a735a1e1a74c01"
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.798779    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.827111    6839 scope.go:110] "RemoveContainer" containerID="cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b"
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.830830    6839 scope.go:110] "RemoveContainer" containerID="cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b"
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:01.831273    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b\": not found" containerID="cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b"
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.831322    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b} err="failed to get container status \"cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b\": rpc error: code = NotFound desc = an error occurred when try to find container \"cc8a70e80b68bf6beec57b457581c067b42353581edc77e8b8d6f65cc04d258b\": not found"
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.831345    6839 scope.go:110] "RemoveContainer" containerID="bee9aded5b66b03b3490fde66231db9173f70297199bf68d632ccd81466fa2bf"
Sep 05 14:18:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:01.899996    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:02.000728    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:02.174304    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:02.674279008 +0000 UTC m=+1174.349355422 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:02.174335    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:02.674326487 +0000 UTC m=+1174.349402888 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:02.395049    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:03.395024094 +0000 UTC m=+1175.070100509 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:02.707219    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:02.707328    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:02.941364    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:03.94133778 +0000 UTC m=+1175.616414227 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:03.106794    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:04.106752739 +0000 UTC m=+1175.781829155 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:03.412692    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:03.643462    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:05.643434378 +0000 UTC m=+1177.318510792 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:03.911668    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:04.411637846 +0000 UTC m=+1176.086714250 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:04.018508    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:04.064801    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:05.064771476 +0000 UTC m=+1176.739847890 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:04.119445    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:04.279738    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:05.279712429 +0000 UTC m=+1176.954788843 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:04.348857    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:06.348824579 +0000 UTC m=+1178.023901000 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:04.348896    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:06.348881951 +0000 UTC m=+1178.023958357 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:04.421973    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:04.652102    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:05.652071253 +0000 UTC m=+1177.327147669 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:05.130111    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:05.332254    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:05.353938    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:07.353911493 +0000 UTC m=+1179.028987909 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:05.391415    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:05.563310    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:07.563279809 +0000 UTC m=+1179.238356227 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:05.736173    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:05.736390    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:05.958364    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:09.958337228 +0000 UTC m=+1181.633413642 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:05.971682    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:07.971654593 +0000 UTC m=+1179.646731011 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:06.443529    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:06.443617    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:06.591816    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:10.591788785 +0000 UTC m=+1182.266865191 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:06.732464    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:10.732437364 +0000 UTC m=+1182.407513768 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:07.453820    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:07.559563    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:11.559538348 +0000 UTC m=+1183.234614763 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:07.655948    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:07.782159    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:11.782130212 +0000 UTC m=+1183.457206626 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:08.058560    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:08.138022    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:12.13799636 +0000 UTC m=+1183.813072765 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:09.979357    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:10.118128    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:18.118095412 +0000 UTC m=+1189.793171830 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:10.687651    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:10.788682    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:10.847974    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:18.847944501 +0000 UTC m=+1190.523020915 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:11.025373    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:19.025340233 +0000 UTC m=+1190.700416648 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:11.596577    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:11.735169    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:19.735139828 +0000 UTC m=+1191.410216232 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:11.798429    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:11.954258    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:19.954217449 +0000 UTC m=+1191.629293870 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:12.203480    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:12.369881    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:20.369856136 +0000 UTC m=+1192.044932541 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:13.391350    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:18:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:18.158385    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:18.320461    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:34.320433605 +0000 UTC m=+1205.995510019 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:18.863805    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:19.046674    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:35.04664712 +0000 UTC m=+1206.721723525 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:19.065074    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:19.219368    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^78894272500902846 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:35.219338868 +0000 UTC m=+1206.894415284 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-969d753c-aecf-40c2-b29d-33d09a422c19/mount
Sep 05 14:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:19.771722    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:19.907299    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:f992919f-d3a6-494d-9718-7632cc610ae7 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:35.907270189 +0000 UTC m=+1207.582346594 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:19.973714    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:20.288443    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:10ec9604-1d90-404e-b703-5416e0cf99c0 nodeName:}" failed. No retries permitted until 2022-09-05 14:18:36.288417308 +0000 UTC m=+1207.963493723 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:20.376953    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:18:20.614930    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^552796702163989499 podName:bbc12be1-fa09-4391-9bbf-2fa6c07e151a nodeName:}" failed. No retries permitted until 2022-09-05 14:18:36.614903861 +0000 UTC m=+1208.289980276 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes/kubernetes.io~csi/pvc-3e439b06-b619-4695-8722-6f9355498835/mount
Sep 05 14:18:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:34.401418    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:34.671212    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^78894272500902846" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7"). InnerVolumeSpecName "pvc-969d753c-aecf-40c2-b29d-33d09a422c19". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.110231    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.311922    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.332627    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^78894272500902846" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a"). InnerVolumeSpecName "pvc-969d753c-aecf-40c2-b29d-33d09a422c19". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.577518    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^78894272500902846" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0"). InnerVolumeSpecName "pvc-969d753c-aecf-40c2-b29d-33d09a422c19". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.614478    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-969d753c-aecf-40c2-b29d-33d09a422c19\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.617077    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.618239    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-969d753c-aecf-40c2-b29d-33d09a422c19" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^78894272500902846") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.715844    6839 reconciler.go:384] "Volume detached for volume \"pvc-969d753c-aecf-40c2-b29d-33d09a422c19\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^78894272500902846\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:18:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:35.918042    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"f992919f-d3a6-494d-9718-7632cc610ae7\" (UID: \"f992919f-d3a6-494d-9718-7632cc610ae7\") "
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.166136    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^552796702163989499" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "f992919f-d3a6-494d-9718-7632cc610ae7" (UID: "f992919f-d3a6-494d-9718-7632cc610ae7"). InnerVolumeSpecName "pvc-3e439b06-b619-4695-8722-6f9355498835". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.321949    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"10ec9604-1d90-404e-b703-5416e0cf99c0\" (UID: \"10ec9604-1d90-404e-b703-5416e0cf99c0\") "
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.553168    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^552796702163989499" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "10ec9604-1d90-404e-b703-5416e0cf99c0" (UID: "10ec9604-1d90-404e-b703-5416e0cf99c0"). InnerVolumeSpecName "pvc-3e439b06-b619-4695-8722-6f9355498835". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.624157    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") pod \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\" (UID: \"bbc12be1-fa09-4391-9bbf-2fa6c07e151a\") "
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.872108    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^552796702163989499" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "bbc12be1-fa09-4391-9bbf-2fa6c07e151a" (UID: "bbc12be1-fa09-4391-9bbf-2fa6c07e151a"). InnerVolumeSpecName "pvc-3e439b06-b619-4695-8722-6f9355498835". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.925772    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-3e439b06-b619-4695-8722-6f9355498835\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.954582    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:36.955940    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-3e439b06-b619-4695-8722-6f9355498835" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^552796702163989499") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:18:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:37.026977    6839 reconciler.go:384] "Volume detached for volume \"pvc-3e439b06-b619-4695-8722-6f9355498835\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^552796702163989499\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:18:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:41.390839    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:18:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:42.396996    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=10ec9604-1d90-404e-b703-5416e0cf99c0 path="/var/lib/kubelet/pods/10ec9604-1d90-404e-b703-5416e0cf99c0/volumes"
Sep 05 14:18:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:42.399001    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=bbc12be1-fa09-4391-9bbf-2fa6c07e151a path="/var/lib/kubelet/pods/bbc12be1-fa09-4391-9bbf-2fa6c07e151a/volumes"
Sep 05 14:18:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:42.400276    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=f992919f-d3a6-494d-9718-7632cc610ae7 path="/var/lib/kubelet/pods/f992919f-d3a6-494d-9718-7632cc610ae7/volumes"
Sep 05 14:18:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:18:56.391310    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:19:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:19:06.390922    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:19:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:19:17.391367    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:19:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:19:25.390977    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:20:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:20:03.391242    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:20:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:20:08.391024    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:20:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:20:18.390969    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:20:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:20:22.391635    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:20:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:20:41.391684    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.134854    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:03.134933    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="f992919f-d3a6-494d-9718-7632cc610ae7" containerName="vdbench"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:03.134956    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="6441dfed-9989-4d74-abfd-0e5d3ae66995" containerName="nginx"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:03.134963    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="10ec9604-1d90-404e-b703-5416e0cf99c0" containerName="vdbench"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:03.134969    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="bbc12be1-fa09-4391-9bbf-2fa6c07e151a" containerName="vdbench"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:03.134975    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="6552d0e5-606f-41d1-bf7f-478d7e7e60c1" containerName="postgres"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:03.134981    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="f7b162dc-66a5-4274-9ef1-89e1539ea084" containerName="es-load"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.135016    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="f7b162dc-66a5-4274-9ef1-89e1539ea084" containerName="es-load"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.135025    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="10ec9604-1d90-404e-b703-5416e0cf99c0" containerName="vdbench"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.135031    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="6441dfed-9989-4d74-abfd-0e5d3ae66995" containerName="nginx"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.135037    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="bbc12be1-fa09-4391-9bbf-2fa6c07e151a" containerName="vdbench"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.135041    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="6552d0e5-606f-41d1-bf7f-478d7e7e60c1" containerName="postgres"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.135048    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="f992919f-d3a6-494d-9718-7632cc610ae7" containerName="vdbench"
Sep 05 14:21:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:03.210116    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-fzxs6\" (UniqueName: \"kubernetes.io/projected/41f74579-13d5-46d4-99e6-073f56acd616-kube-api-access-fzxs6\") pod \"es-load-769678797c-cnp9n\" (UID: \"41f74579-13d5-46d4-99e6-073f56acd616\") " pod="elasticsearch-applicationscaleupdown-0-09-05-14h07m47s/es-load-769678797c-cnp9n"
Sep 05 14:21:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:04.391390    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:10.751469    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:10.854712    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4pkkr\" (UniqueName: \"kubernetes.io/projected/06770dfb-c097-4a2a-89d8-05e752b6d0b7-kube-api-access-4pkkr\") pod \"postgres-646f6f7487-xkbfg\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") " pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:10.854790    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-2041c110-d270-4fdc-9cb9-d58b5a101021\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"postgres-646f6f7487-xkbfg\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") " pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:10.956676    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:10.956720    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-2041c110-d270-4fdc-9cb9-d58b5a101021\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"postgres-646f6f7487-xkbfg\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/8be87078440407b50f45d56d57dd80c9975af05463c8af457a1efcda53cd086f/globalmount\"" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:10.997457    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:21:11.497430325 +0000 UTC m=+1363.172506740 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:11.620304    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:21:12.62027908 +0000 UTC m=+1364.295355494 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:13.019560    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:21:15.019534487 +0000 UTC m=+1366.694610900 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:15.428357    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:21:19.428330702 +0000 UTC m=+1371.103407105 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:19.908198    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:21:27.908169004 +0000 UTC m=+1379.583245418 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:28.297433    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:21:44.297408079 +0000 UTC m=+1395.972484494 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:30.391594    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:21:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:35.391264    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:21:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:39.391129    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:21:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:21:44.744505    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:22:16.74446321 +0000 UTC m=+1428.419539615 (durationBeforeRetry 32s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:21:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:21:50.391748    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:22:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:22:10.390729    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:22:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:22:17.270538    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:23:21.270513331 +0000 UTC m=+1492.945589736 (durationBeforeRetry 1m4s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:22:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:22:33.391406    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:22:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:22:50.391976    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:23:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:23:03.390985    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:23:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:23:13.755552    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:23:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:23:13.755616    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg" podUID=06770dfb-c097-4a2a-89d8-05e752b6d0b7
Sep 05 14:23:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:23:20.391389    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:23:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:23:21.897731    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:25:23.897675496 +0000 UTC m=+1615.572751910 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:23:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:23:30.392076    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:23:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:23:58.391291    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:24:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:05.390984    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:24:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:09.390778    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:24:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:15.135286    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:24:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:15.301215    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"elasticsearch-config\" (UniqueName: \"kubernetes.io/configmap/5dde2ff1-3c2f-4265-8a32-04bff6216421-elasticsearch-config\") pod \"esnode-4\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") " pod="elasticsearch-applicationscaleupdown-0-09-05-14h07m47s/esnode-4"
Sep 05 14:24:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:15.301258    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-7frww\" (UniqueName: \"kubernetes.io/projected/5dde2ff1-3c2f-4265-8a32-04bff6216421-kube-api-access-7frww\") pod \"esnode-4\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") " pod="elasticsearch-applicationscaleupdown-0-09-05-14h07m47s/esnode-4"
Sep 05 14:24:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:15.301298    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"esnode-4\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") " pod="elasticsearch-applicationscaleupdown-0-09-05-14h07m47s/esnode-4"
Sep 05 14:24:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:15.404116    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:24:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:15.404155    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"esnode-4\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/b7d6f9d56c5681e5e356252594b4d8069bad26f04632b64f1471eb4c5460284d/globalmount\"" pod="elasticsearch-applicationscaleupdown-0-09-05-14h07m47s/esnode-4"
Sep 05 14:24:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:23.391525    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:24:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:24:49.391685    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:25:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:02.392590    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:25:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:11.390954    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:25:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:13.982330    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"elasticsearch-config\" (UniqueName: \"kubernetes.io/configmap/5dde2ff1-3c2f-4265-8a32-04bff6216421-elasticsearch-config\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:13.983271    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:13.983325    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-7frww\" (UniqueName: \"kubernetes.io/projected/5dde2ff1-3c2f-4265-8a32-04bff6216421-kube-api-access-7frww\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.004476    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/5dde2ff1-3c2f-4265-8a32-04bff6216421-kube-api-access-7frww" (OuterVolumeSpecName: "kube-api-access-7frww") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421"). InnerVolumeSpecName "kube-api-access-7frww". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: W0905 14:25:14.016520    6839 mount_helper_common.go:133] Warning: "/var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volume-subpaths/elasticsearch-config/elasticsearch/1" is not a mountpoint, deleting
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: W0905 14:25:14.021934    6839 empty_dir.go:519] Warning: Failed to clear quota on /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~configmap/elasticsearch-config: clearQuota called, but quotas disabled
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.030850    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/5dde2ff1-3c2f-4265-8a32-04bff6216421-elasticsearch-config" (OuterVolumeSpecName: "elasticsearch-config") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421"). InnerVolumeSpecName "elasticsearch-config". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.083846    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-7frww\" (UniqueName: \"kubernetes.io/projected/5dde2ff1-3c2f-4265-8a32-04bff6216421-kube-api-access-7frww\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.083874    6839 reconciler.go:384] "Volume detached for volume \"elasticsearch-config\" (UniqueName: \"kubernetes.io/configmap/5dde2ff1-3c2f-4265-8a32-04bff6216421-elasticsearch-config\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:14.453093    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^962001865137030276 podName:5dde2ff1-3c2f-4265-8a32-04bff6216421 nodeName:}" failed. No retries permitted until 2022-09-05 14:25:14.953068838 +0000 UTC m=+1606.628145253 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~csi/pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9/mount
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.712532    6839 scope.go:110] "RemoveContainer" containerID="b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.717634    6839 scope.go:110] "RemoveContainer" containerID="d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.721109    6839 scope.go:110] "RemoveContainer" containerID="b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:14.721389    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676\": not found" containerID="b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.721412    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676} err="failed to get container status \"b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676\": rpc error: code = NotFound desc = an error occurred when try to find container \"b35c731a56db9dc0778d2bcf80651e80bd9704662198d816f219912f10bb5676\": not found"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.721423    6839 scope.go:110] "RemoveContainer" containerID="d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:14.721696    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b\": not found" containerID="d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.721726    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b} err="failed to get container status \"d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b\": rpc error: code = NotFound desc = an error occurred when try to find container \"d16b7fde13957cc41c5b967554e13def235402e494fe5a58f2926fea12e03d5b\": not found"
Sep 05 14:25:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:14.991102    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:15.151699    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^962001865137030276 podName:5dde2ff1-3c2f-4265-8a32-04bff6216421 nodeName:}" failed. No retries permitted until 2022-09-05 14:25:16.15166927 +0000 UTC m=+1607.826745685 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~csi/pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9/mount
Sep 05 14:25:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:16.199067    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:16.295511    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^962001865137030276 podName:5dde2ff1-3c2f-4265-8a32-04bff6216421 nodeName:}" failed. No retries permitted until 2022-09-05 14:25:18.295478439 +0000 UTC m=+1609.970554854 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~csi/pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9/mount
Sep 05 14:25:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:18.314204    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:18.448255    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^962001865137030276 podName:5dde2ff1-3c2f-4265-8a32-04bff6216421 nodeName:}" failed. No retries permitted until 2022-09-05 14:25:22.44823024 +0000 UTC m=+1614.123306655 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~csi/pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9/mount
Sep 05 14:25:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:22.542180    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:22.702824    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^962001865137030276 podName:5dde2ff1-3c2f-4265-8a32-04bff6216421 nodeName:}" failed. No retries permitted until 2022-09-05 14:25:30.702800046 +0000 UTC m=+1622.377876452 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~csi/pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9/mount
Sep 05 14:25:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:23.391406    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:25:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:24.419668    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:27:26.419643074 +0000 UTC m=+1738.094719489 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:25:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:29.392182    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:25:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:29.392253    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg" podUID=06770dfb-c097-4a2a-89d8-05e752b6d0b7
Sep 05 14:25:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:30.709839    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:25:30.852678    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^962001865137030276 podName:5dde2ff1-3c2f-4265-8a32-04bff6216421 nodeName:}" failed. No retries permitted until 2022-09-05 14:25:46.852635529 +0000 UTC m=+1638.527711946 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes/kubernetes.io~csi/pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9/mount
Sep 05 14:25:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:43.391089    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:25:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:46.944157    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") pod \"5dde2ff1-3c2f-4265-8a32-04bff6216421\" (UID: \"5dde2ff1-3c2f-4265-8a32-04bff6216421\") "
Sep 05 14:25:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:47.047619    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^962001865137030276" (OuterVolumeSpecName: "es-data") pod "5dde2ff1-3c2f-4265-8a32-04bff6216421" (UID: "5dde2ff1-3c2f-4265-8a32-04bff6216421"). InnerVolumeSpecName "pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:25:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:47.145806    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:25:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:47.148787    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:25:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:47.149611    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^962001865137030276") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:25:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:47.247007    6839 reconciler.go:384] "Volume detached for volume \"pvc-9e6c7b47-2bc3-49bd-8474-1ea29c0d27e9\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^962001865137030276\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:25:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:25:52.398792    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=5dde2ff1-3c2f-4265-8a32-04bff6216421 path="/var/lib/kubelet/pods/5dde2ff1-3c2f-4265-8a32-04bff6216421/volumes"
Sep 05 14:26:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:26:12.391109    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:26:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:26:18.392321    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:26:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:26:34.391939    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:26:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:26:37.390977    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:26:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:26:49.390922    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:27:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:27:24.391721    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:27:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:27:27.009299    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:29:29.009266438 +0000 UTC m=+1860.684342853 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:27:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:27:36.394829    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:27:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:27:42.391891    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:27:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:27:45.395681    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:27:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:27:45.395756    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg" podUID=06770dfb-c097-4a2a-89d8-05e752b6d0b7
Sep 05 14:27:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:27:46.391136    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:27:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:27:58.394851    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:28:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:28:42.391580    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:28:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:28:46.390878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:28:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:28:58.391678    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:29:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:29:00.391595    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:29:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:29:06.391086    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:29:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:29:29.900392    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:31:31.900348085 +0000 UTC m=+1983.575424530 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:30:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:30:00.391167    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:30:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:30:00.391594    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:30:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:30:00.391623    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg" podUID=06770dfb-c097-4a2a-89d8-05e752b6d0b7
Sep 05 14:30:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:30:02.395104    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:30:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:30:06.390903    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:30:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:30:12.390927    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:30:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:30:20.392729    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:31:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:05.391712    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:31:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:13.391757    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:31:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:26.390875    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:31:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:26.391088    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:31:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:31:32.538968    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName: nodeName:}" failed. No retries permitted until 2022-09-05 14:33:34.538932435 +0000 UTC m=+2106.214008848 (durationBeforeRetry 2m2s). Error: MountVolume.SetUp failed for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "postgres-646f6f7487-xkbfg" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : rpc error: code = Internal desc = failed  to attach volume: Non-shared volume is already attached on another node. Non-shared volumes can only be attached on one node at a time.
Sep 05 14:31:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:41.919604    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-fzxs6\" (UniqueName: \"kubernetes.io/projected/41f74579-13d5-46d4-99e6-073f56acd616-kube-api-access-fzxs6\") pod \"41f74579-13d5-46d4-99e6-073f56acd616\" (UID: \"41f74579-13d5-46d4-99e6-073f56acd616\") "
Sep 05 14:31:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:41.935655    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/41f74579-13d5-46d4-99e6-073f56acd616-kube-api-access-fzxs6" (OuterVolumeSpecName: "kube-api-access-fzxs6") pod "41f74579-13d5-46d4-99e6-073f56acd616" (UID: "41f74579-13d5-46d4-99e6-073f56acd616"). InnerVolumeSpecName "kube-api-access-fzxs6". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:31:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:42.021049    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-fzxs6\" (UniqueName: \"kubernetes.io/projected/41f74579-13d5-46d4-99e6-073f56acd616-kube-api-access-fzxs6\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:31:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:42.640009    6839 scope.go:110] "RemoveContainer" containerID="7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d"
Sep 05 14:31:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:42.645258    6839 scope.go:110] "RemoveContainer" containerID="7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d"
Sep 05 14:31:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:31:42.645607    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d\": not found" containerID="7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d"
Sep 05 14:31:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:42.645637    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d} err="failed to get container status \"7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d\": rpc error: code = NotFound desc = an error occurred when try to find container \"7bc30d1d27226b972c39ca945a146a7ba507b8c31c82eea8c8c52db8f07ab45d\": not found"
Sep 05 14:31:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:43.392833    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:31:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:31:44.396365    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=41f74579-13d5-46d4-99e6-073f56acd616 path="/var/lib/kubelet/pods/41f74579-13d5-46d4-99e6-073f56acd616/volumes"
Sep 05 14:32:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:32:18.392422    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg"
Sep 05 14:32:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:32:18.392460    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[postgredb], unattached volumes=[postgredb kube-api-access-4pkkr]: timed out waiting for the condition" pod="postgres-applicationscaleupdown-0-09-05-14h07m47s/postgres-646f6f7487-xkbfg" podUID=06770dfb-c097-4a2a-89d8-05e752b6d0b7
Sep 05 14:32:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:32:34.392219    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:32:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:32:39.390875    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:32:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:32:41.391610    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:32:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:32:43.391609    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:32:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:32:51.391878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.163732    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-4pkkr\" (UniqueName: \"kubernetes.io/projected/06770dfb-c097-4a2a-89d8-05e752b6d0b7-kube-api-access-4pkkr\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.163855    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.176280    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/06770dfb-c097-4a2a-89d8-05e752b6d0b7-kube-api-access-4pkkr" (OuterVolumeSpecName: "kube-api-access-4pkkr") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7"). InnerVolumeSpecName "kube-api-access-4pkkr". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.264484    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-4pkkr\" (UniqueName: \"kubernetes.io/projected/06770dfb-c097-4a2a-89d8-05e752b6d0b7-kube-api-access-4pkkr\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:36.594561    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName:06770dfb-c097-4a2a-89d8-05e752b6d0b7 nodeName:}" failed. No retries permitted until 2022-09-05 14:33:37.094528418 +0000 UTC m=+2108.769604824 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes/kubernetes.io~csi/pvc-2041c110-d270-4fdc-9cb9-d58b5a101021/mount
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.882174    6839 scope.go:110] "RemoveContainer" containerID="3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492"
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.885435    6839 scope.go:110] "RemoveContainer" containerID="3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492"
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:36.885811    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492\": not found" containerID="3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492"
Sep 05 14:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:36.885842    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492} err="failed to get container status \"3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492\": rpc error: code = NotFound desc = an error occurred when try to find container \"3d5f149e8aed5220410adcb4fa39622cdf6df6fb22b495236c3d0572850a1492\": not found"
Sep 05 14:33:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:37.172021    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:37.375721    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName:06770dfb-c097-4a2a-89d8-05e752b6d0b7 nodeName:}" failed. No retries permitted until 2022-09-05 14:33:38.37569058 +0000 UTC m=+2110.050766988 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes/kubernetes.io~csi/pvc-2041c110-d270-4fdc-9cb9-d58b5a101021/mount
Sep 05 14:33:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:38.380790    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:38.552763    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName:06770dfb-c097-4a2a-89d8-05e752b6d0b7 nodeName:}" failed. No retries permitted until 2022-09-05 14:33:40.55273824 +0000 UTC m=+2112.227814655 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes/kubernetes.io~csi/pvc-2041c110-d270-4fdc-9cb9-d58b5a101021/mount
Sep 05 14:33:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:40.599737    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:40.830923    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName:06770dfb-c097-4a2a-89d8-05e752b6d0b7 nodeName:}" failed. No retries permitted until 2022-09-05 14:33:44.830885389 +0000 UTC m=+2116.505961804 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes/kubernetes.io~csi/pvc-2041c110-d270-4fdc-9cb9-d58b5a101021/mount
Sep 05 14:33:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:43.391315    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:33:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:44.391948    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:33:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:44.930365    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:45.071536    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName:06770dfb-c097-4a2a-89d8-05e752b6d0b7 nodeName:}" failed. No retries permitted until 2022-09-05 14:33:53.071486391 +0000 UTC m=+2124.746562804 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes/kubernetes.io~csi/pvc-2041c110-d270-4fdc-9cb9-d58b5a101021/mount
Sep 05 14:33:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:33:53.088826    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:33:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:33:53.261868    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^120070379015427430 podName:06770dfb-c097-4a2a-89d8-05e752b6d0b7 nodeName:}" failed. No retries permitted until 2022-09-05 14:34:09.261835233 +0000 UTC m=+2140.936911638 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "postgredb" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes/kubernetes.io~csi/pvc-2041c110-d270-4fdc-9cb9-d58b5a101021/mount
Sep 05 14:34:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:07.391021    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:34:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:07.391187    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:34:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:08.391094    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:34:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:09.310462    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"postgredb\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") pod \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\" (UID: \"06770dfb-c097-4a2a-89d8-05e752b6d0b7\") "
Sep 05 14:34:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:09.494107    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^120070379015427430" (OuterVolumeSpecName: "postgredb") pod "06770dfb-c097-4a2a-89d8-05e752b6d0b7" (UID: "06770dfb-c097-4a2a-89d8-05e752b6d0b7"). InnerVolumeSpecName "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:34:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:09.511412    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-2041c110-d270-4fdc-9cb9-d58b5a101021\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:34:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:09.513689    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:34:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:09.514815    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-2041c110-d270-4fdc-9cb9-d58b5a101021" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^120070379015427430") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:34:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:09.612541    6839 reconciler.go:384] "Volume detached for volume \"pvc-2041c110-d270-4fdc-9cb9-d58b5a101021\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^120070379015427430\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:34:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:12.394564    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=06770dfb-c097-4a2a-89d8-05e752b6d0b7 path="/var/lib/kubelet/pods/06770dfb-c097-4a2a-89d8-05e752b6d0b7/volumes"
Sep 05 14:34:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:44.391357    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:34:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:34:49.391092    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:35:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:11.390905    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:35:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:23.391150    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:35:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:38.391024    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:39.264908    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:35:39.264983    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="41f74579-13d5-46d4-99e6-073f56acd616" containerName="es-load"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:35:39.264993    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="5dde2ff1-3c2f-4265-8a32-04bff6216421" containerName="init-sysctl"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:35:39.265001    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="06770dfb-c097-4a2a-89d8-05e752b6d0b7" containerName="postgres"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:35:39.265008    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="5dde2ff1-3c2f-4265-8a32-04bff6216421" containerName="elasticsearch"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:39.265035    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="41f74579-13d5-46d4-99e6-073f56acd616" containerName="es-load"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:39.265042    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="5dde2ff1-3c2f-4265-8a32-04bff6216421" containerName="elasticsearch"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:39.265048    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="06770dfb-c097-4a2a-89d8-05e752b6d0b7" containerName="postgres"
Sep 05 14:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:39.419020    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-4s4ch\" (UniqueName: \"kubernetes.io/projected/333dd88b-8c22-41f2-baf7-50f99646d4cc-kube-api-access-4s4ch\") pod \"es-load-769678797c-ncx62\" (UID: \"333dd88b-8c22-41f2-baf7-50f99646d4cc\") " pod="elasticsearch-voldriverappdown-0-09-05-14h07m47s/es-load-769678797c-ncx62"
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.566176    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.625308    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-v47xk\" (UniqueName: \"kubernetes.io/projected/50025e5a-affc-4a6c-a357-a1d5d010b737-kube-api-access-v47xk\") pod \"vdbench-sharedv4-74b9988cdd-7kgrr\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") " pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr"
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.625355    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"vdbench-sharedv4-74b9988cdd-7kgrr\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") " pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr"
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.625377    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-d458b250-1019-4972-a88d-305081928b73\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"vdbench-sharedv4-74b9988cdd-7kgrr\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") " pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr"
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.728408    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.728466    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-d458b250-1019-4972-a88d-305081928b73\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"vdbench-sharedv4-74b9988cdd-7kgrr\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/cbeccfe7dca2bd5d6bcf1f5bd5355b0a03d73081bd2ba7208d7ad55cb784f927/globalmount\"" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr"
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.728408    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:35:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:51.728538    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"vdbench-sharedv4-74b9988cdd-7kgrr\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/96681d4c1d9b2a8e55bca401738ebfec5955764325cf9835b4771d4636d8a96b/globalmount\"" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr"
Sep 05 14:35:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:52.719665    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:35:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:53.038573    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ksh9n\" (UniqueName: \"kubernetes.io/projected/ac0e590f-dca5-4715-995e-74403ceda012-kube-api-access-ksh9n\") pod \"vdbench-sharedv4-74b9988cdd-lrfvd\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") " pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-lrfvd"
Sep 05 14:35:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:54.089372    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:35:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:54.393992    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:35:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:35:54.651189    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-ksxrs\" (UniqueName: \"kubernetes.io/projected/55faba26-5b80-454f-af2c-ee4f696ca821-kube-api-access-ksxrs\") pod \"vdbench-sharedv4-74b9988cdd-dj9qk\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") " pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-dj9qk"
Sep 05 14:36:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:12.403115    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:36:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:16.527800    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 14:36:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:16.659216    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-011e508a-9ed0-47f2-bd97-c8848263fd40\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"esnode-1\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") " pod="elasticsearch-voldriverappdown-0-09-05-14h07m47s/esnode-1"
Sep 05 14:36:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:16.659268    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-gjhdr\" (UniqueName: \"kubernetes.io/projected/82492342-e5c5-4cee-b1ab-f3fe1f277460-kube-api-access-gjhdr\") pod \"esnode-1\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") " pod="elasticsearch-voldriverappdown-0-09-05-14h07m47s/esnode-1"
Sep 05 14:36:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:16.659315    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"elasticsearch-config\" (UniqueName: \"kubernetes.io/configmap/82492342-e5c5-4cee-b1ab-f3fe1f277460-elasticsearch-config\") pod \"esnode-1\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") " pod="elasticsearch-voldriverappdown-0-09-05-14h07m47s/esnode-1"
Sep 05 14:36:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:16.764042    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 14:36:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:16.764086    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-011e508a-9ed0-47f2-bd97-c8848263fd40\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"esnode-1\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/142b776641ff31d838b4966e6373183b94e9603eb683877405c556f943bcc4fd/globalmount\"" pod="elasticsearch-voldriverappdown-0-09-05-14h07m47s/esnode-1"
Sep 05 14:36:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:27.392244    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:36:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:39.390925    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:36:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:51.396249    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:36:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:36:56.392006    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:37:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:37:31.391571    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:37:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:37:47.397242    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:37:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:37:57.390885    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:38:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:06.394143    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:38:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:12.392221    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:20.603456    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-4s4ch\" (UniqueName: \"kubernetes.io/projected/333dd88b-8c22-41f2-baf7-50f99646d4cc-kube-api-access-4s4ch\") pod \"333dd88b-8c22-41f2-baf7-50f99646d4cc\" (UID: \"333dd88b-8c22-41f2-baf7-50f99646d4cc\") "
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:20.658581    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/333dd88b-8c22-41f2-baf7-50f99646d4cc-kube-api-access-4s4ch" (OuterVolumeSpecName: "kube-api-access-4s4ch") pod "333dd88b-8c22-41f2-baf7-50f99646d4cc" (UID: "333dd88b-8c22-41f2-baf7-50f99646d4cc"). InnerVolumeSpecName "kube-api-access-4s4ch". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:20.704301    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-4s4ch\" (UniqueName: \"kubernetes.io/projected/333dd88b-8c22-41f2-baf7-50f99646d4cc-kube-api-access-4s4ch\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:20.881438    6839 scope.go:110] "RemoveContainer" containerID="0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df"
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:20.893513    6839 scope.go:110] "RemoveContainer" containerID="0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df"
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:38:20.893939    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df\": not found" containerID="0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df"
Sep 05 14:38:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:20.893980    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df} err="failed to get container status \"0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df\": rpc error: code = NotFound desc = an error occurred when try to find container \"0fdcab367f1f79bcc96bcdd533d2bf6006486a7af9710b5b93de945fbba996df\": not found"
Sep 05 14:38:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:22.395222    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=333dd88b-8c22-41f2-baf7-50f99646d4cc path="/var/lib/kubelet/pods/333dd88b-8c22-41f2-baf7-50f99646d4cc/volumes"
Sep 05 14:38:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:52.391546    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:38:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:38:57.391951    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.642326    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"elasticsearch-config\" (UniqueName: \"kubernetes.io/configmap/82492342-e5c5-4cee-b1ab-f3fe1f277460-elasticsearch-config\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.644277    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.644350    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-gjhdr\" (UniqueName: \"kubernetes.io/projected/82492342-e5c5-4cee-b1ab-f3fe1f277460-kube-api-access-gjhdr\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: W0905 14:39:02.659056    6839 mount_helper_common.go:133] Warning: "/var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volume-subpaths/elasticsearch-config/elasticsearch/1" is not a mountpoint, deleting
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: W0905 14:39:02.659924    6839 empty_dir.go:519] Warning: Failed to clear quota on /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~configmap/elasticsearch-config: clearQuota called, but quotas disabled
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.660962    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/configmap/82492342-e5c5-4cee-b1ab-f3fe1f277460-elasticsearch-config" (OuterVolumeSpecName: "elasticsearch-config") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460"). InnerVolumeSpecName "elasticsearch-config". PluginName "kubernetes.io/configmap", VolumeGidValue ""
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.661395    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/82492342-e5c5-4cee-b1ab-f3fe1f277460-kube-api-access-gjhdr" (OuterVolumeSpecName: "kube-api-access-gjhdr") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460"). InnerVolumeSpecName "kube-api-access-gjhdr". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.746082    6839 reconciler.go:384] "Volume detached for volume \"elasticsearch-config\" (UniqueName: \"kubernetes.io/configmap/82492342-e5c5-4cee-b1ab-f3fe1f277460-elasticsearch-config\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:39:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:02.746124    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-gjhdr\" (UniqueName: \"kubernetes.io/projected/82492342-e5c5-4cee-b1ab-f3fe1f277460-kube-api-access-gjhdr\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.010202    6839 scope.go:110] "RemoveContainer" containerID="7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.019826    6839 scope.go:110] "RemoveContainer" containerID="9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.027513    6839 scope.go:110] "RemoveContainer" containerID="7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:03.027963    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981\": not found" containerID="7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.028014    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981} err="failed to get container status \"7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981\": rpc error: code = NotFound desc = an error occurred when try to find container \"7c452e17785e26f343bf931d4c801ce7d6aeaa9564f5b7b4215fb51eb1318981\": not found"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.028030    6839 scope.go:110] "RemoveContainer" containerID="9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:03.028379    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8\": not found" containerID="9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.028408    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8} err="failed to get container status \"9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8\": rpc error: code = NotFound desc = an error occurred when try to find container \"9583db9ba8e8e9b6ba66175b4450e86604a4b696d90b09a1d7390f82cdaaa7a8\": not found"
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:03.138402    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^98370067822319174 podName:82492342-e5c5-4cee-b1ab-f3fe1f277460 nodeName:}" failed. No retries permitted until 2022-09-05 14:39:03.638371733 +0000 UTC m=+2435.313448148 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~csi/pvc-011e508a-9ed0-47f2-bd97-c8848263fd40/mount
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:03.656810    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:03.774457    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^98370067822319174 podName:82492342-e5c5-4cee-b1ab-f3fe1f277460 nodeName:}" failed. No retries permitted until 2022-09-05 14:39:04.77442166 +0000 UTC m=+2436.449498077 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~csi/pvc-011e508a-9ed0-47f2-bd97-c8848263fd40/mount
Sep 05 14:39:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:04.867039    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:04.968024    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^98370067822319174 podName:82492342-e5c5-4cee-b1ab-f3fe1f277460 nodeName:}" failed. No retries permitted until 2022-09-05 14:39:06.968000699 +0000 UTC m=+2438.643077114 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~csi/pvc-011e508a-9ed0-47f2-bd97-c8848263fd40/mount
Sep 05 14:39:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:07.001842    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:07.098144    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^98370067822319174 podName:82492342-e5c5-4cee-b1ab-f3fe1f277460 nodeName:}" failed. No retries permitted until 2022-09-05 14:39:11.098115598 +0000 UTC m=+2442.773192001 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~csi/pvc-011e508a-9ed0-47f2-bd97-c8848263fd40/mount
Sep 05 14:39:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:11.158403    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:11.287743    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^98370067822319174 podName:82492342-e5c5-4cee-b1ab-f3fe1f277460 nodeName:}" failed. No retries permitted until 2022-09-05 14:39:19.287679618 +0000 UTC m=+2450.962756033 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~csi/pvc-011e508a-9ed0-47f2-bd97-c8848263fd40/mount
Sep 05 14:39:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:14.407265    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:39:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:19.369652    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:39:19.497375    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^98370067822319174 podName:82492342-e5c5-4cee-b1ab-f3fe1f277460 nodeName:}" failed. No retries permitted until 2022-09-05 14:39:35.497346876 +0000 UTC m=+2467.172423280 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "es-data" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes/kubernetes.io~csi/pvc-011e508a-9ed0-47f2-bd97-c8848263fd40/mount
Sep 05 14:39:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:26.390952    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:39:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:29.391842    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:39:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:35.543829    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"es-data\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") pod \"82492342-e5c5-4cee-b1ab-f3fe1f277460\" (UID: \"82492342-e5c5-4cee-b1ab-f3fe1f277460\") "
Sep 05 14:39:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:35.635638    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^98370067822319174" (OuterVolumeSpecName: "es-data") pod "82492342-e5c5-4cee-b1ab-f3fe1f277460" (UID: "82492342-e5c5-4cee-b1ab-f3fe1f277460"). InnerVolumeSpecName "pvc-011e508a-9ed0-47f2-bd97-c8848263fd40". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:39:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:35.645075    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-011e508a-9ed0-47f2-bd97-c8848263fd40\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:39:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:35.651531    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:39:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:35.651993    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-011e508a-9ed0-47f2-bd97-c8848263fd40" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^98370067822319174") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:39:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:35.746036    6839 reconciler.go:384] "Volume detached for volume \"pvc-011e508a-9ed0-47f2-bd97-c8848263fd40\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^98370067822319174\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:39:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:42.394782    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=82492342-e5c5-4cee-b1ab-f3fe1f277460 path="/var/lib/kubelet/pods/82492342-e5c5-4cee-b1ab-f3fe1f277460/volumes"
Sep 05 14:39:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:39:58.393976    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:40:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:40:17.392225    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:40:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:40:28.392327    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:40:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:40:28.392836    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:40:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:40:31.391012    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:41:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:41:09.391690    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:41:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:41:30.391947    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:41:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:41:40.391560    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:41:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:41:45.390861    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:41:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:41:46.390755    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:42:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:42:30.393779    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:42:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:42:45.391511    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:42:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:42:49.390911    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:42:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:42:52.391465    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:43:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:43:01.391108    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:43:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:43:33.391037    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:43:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:43:56.391236    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:44:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:44:12.391447    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:44:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:44:14.393019    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:44:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:44:31.390931    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:44:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:44:41.390895    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:45:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:45:18.390861    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:45:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:45:19.390682    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:45:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:45:21.391444    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:45:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:45:32.394314    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:46:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:46:00.394065    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:46:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:46:26.391521    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:46:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:46:45.391364    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:46:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:46:47.391603    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:46:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:46:47.392456    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:47:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:47:08.391878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:47:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:47:48.395625    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:47:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:47:53.391752    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:48:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:48:04.391427    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:48:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:48:14.390842    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:48:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:48:35.390552    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:49:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:49:02.395340    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:49:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:49:14.393676    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:49:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:49:16.392639    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:49:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:49:32.391130    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:50:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:50:01.390749    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:50:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:50:11.391617    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:50:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:50:36.391715    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:50:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:50:43.390695    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:50:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:50:59.391158    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:51:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:51:08.394393    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:51:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:51:13.391245    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:51:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:51:39.391190    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:52:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:52:07.391637    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:52:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:52:25.391153    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:52:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:52:26.390971    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:52:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:52:43.391643    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:07.391012    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:08.711210    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:08.711324    6839 scope.go:110] "RemoveContainer" containerID="941df04b861df49b808c18ddc952609ba2c3fffffa1a2f2cf22ea43c71458684"
Sep 05 14:53:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:08.711334    6839 scope.go:110] "RemoveContainer" containerID="f383fbdcdbca169abb8776d5e6e757d42b8ac6883ae8878af204a57e7847bfff"
Sep 05 14:53:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:09.715329    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:10.716508    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:30.034486    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:30.324579    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:50.037008    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:51.391740    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:53:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:53:52.391887    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:54:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:54:19.523359    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:54:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:54:34.391409    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:55:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:55:04.391805    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:55:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:55:11.391571    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:55:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:55:20.390993    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:55:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:55:25.391386    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.484092    6839 remote_runtime.go:484] "StopContainer from runtime service failed" err="rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\" to be killed: wait container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\": context deadline exceeded" containerID="60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920"
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.484197    6839 kuberuntime_container.go:727] "Container termination failed with gracePeriod" err="rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\" to be killed: wait container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\": context deadline exceeded" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-dj9qk" podUID=55faba26-5b80-454f-af2c-ee4f696ca821 containerName="vdbench" containerID="containerd://60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920" gracePeriod=30
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.484251    6839 kuberuntime_container.go:752] "Kill container failed" err="rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\" to be killed: wait container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\": context deadline exceeded" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-dj9qk" podUID=55faba26-5b80-454f-af2c-ee4f696ca821 containerName="vdbench" containerID={Type:containerd ID:60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920}
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.484948    6839 remote_runtime.go:484] "StopContainer from runtime service failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" containerID="506123e3e94e6c412d0dfb898a140654025256a5a4036a841f7122d7c0f1d769"
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.485003    6839 kuberuntime_container.go:727] "Container termination failed with gracePeriod" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-lrfvd" podUID=ac0e590f-dca5-4715-995e-74403ceda012 containerName="vdbench" containerID="containerd://506123e3e94e6c412d0dfb898a140654025256a5a4036a841f7122d7c0f1d769" gracePeriod=30
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.485034    6839 kuberuntime_container.go:752] "Kill container failed" err="rpc error: code = DeadlineExceeded desc = context deadline exceeded" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-lrfvd" podUID=ac0e590f-dca5-4715-995e-74403ceda012 containerName="vdbench" containerID={Type:containerd ID:506123e3e94e6c412d0dfb898a140654025256a5a4036a841f7122d7c0f1d769}
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.493506    6839 remote_runtime.go:484] "StopContainer from runtime service failed" err="rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\" to be killed: wait container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\": context deadline exceeded" containerID="56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3"
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.493596    6839 kuberuntime_container.go:727] "Container termination failed with gracePeriod" err="rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\" to be killed: wait container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\": context deadline exceeded" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr" podUID=50025e5a-affc-4a6c-a357-a1d5d010b737 containerName="vdbench" containerID="containerd://56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3" gracePeriod=30
Sep 05 14:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:55:51.493627    6839 kuberuntime_container.go:752] "Kill container failed" err="rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\" to be killed: wait container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\": context deadline exceeded" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr" podUID=50025e5a-affc-4a6c-a357-a1d5d010b737 containerName="vdbench" containerID={Type:containerd ID:56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3}
Sep 05 14:55:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:55:53.390928    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:56:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:19.390942    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:56:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:28.391485    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:56:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:34.391716    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:56:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:42.392205    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:44.809901    6839 kubelet.go:1784] failed to "KillContainer" for "vdbench" with KillContainerError: "rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\" to be killed: wait container \"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\": context deadline exceeded"
Sep 05 14:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:44.809950    6839 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"KillContainer\" for \"vdbench\" with KillContainerError: \"rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \\\"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\\\" to be killed: wait container \\\"56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3\\\": context deadline exceeded\"" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7kgrr" podUID=50025e5a-affc-4a6c-a357-a1d5d010b737
Sep 05 14:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:44.812801    6839 kubelet.go:1784] failed to "KillContainer" for "vdbench" with KillContainerError: "rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\" to be killed: wait container \"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\": context deadline exceeded"
Sep 05 14:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:44.812849    6839 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"KillContainer\" for \"vdbench\" with KillContainerError: \"rpc error: code = DeadlineExceeded desc = an error occurs during waiting for container \\\"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\\\" to be killed: wait container \\\"60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920\\\": context deadline exceeded\"" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-dj9qk" podUID=55faba26-5b80-454f-af2c-ee4f696ca821
Sep 05 14:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:44.823845    6839 kubelet.go:1784] failed to "KillContainer" for "vdbench" with KillContainerError: "rpc error: code = DeadlineExceeded desc = context deadline exceeded"
Sep 05 14:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:44.823880    6839 pod_workers.go:951] "Error syncing pod, skipping" err="failed to \"KillContainer\" for \"vdbench\" with KillContainerError: \"rpc error: code = DeadlineExceeded desc = context deadline exceeded\"" pod="vdbench-sharedv4-voldriverappdown-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-lrfvd" podUID=ac0e590f-dca5-4715-995e-74403ceda012
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.251129    6839 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="3d6e8f6a041b9aaa493b5e51366a4895e2d5f21520c2fa41844e2a08bcae487a"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.252576    6839 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="4ca6176c13deef11825c77e6309163ec95d47a544cbc7f11ace04c97d3346829"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.253507    6839 pod_container_deletor.go:79] "Container not found in pod's containers" containerID="1d470fed6455287d5e201b3c58e010f704facbe65278b20df1a7534b6731e232"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.340565    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-v47xk\" (UniqueName: \"kubernetes.io/projected/50025e5a-affc-4a6c-a357-a1d5d010b737-kube-api-access-v47xk\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.342468    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.342823    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:45.8428046 +0000 UTC m=+3497.517881003 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.346516    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.346808    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:45.846793993 +0000 UTC m=+3497.521870422 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.357162    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/50025e5a-affc-4a6c-a357-a1d5d010b737-kube-api-access-v47xk" (OuterVolumeSpecName: "kube-api-access-v47xk") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737"). InnerVolumeSpecName "kube-api-access-v47xk". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.448482    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.449280    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:45.949261233 +0000 UTC m=+3497.624337649 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.449624    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.449657    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-ksh9n\" (UniqueName: \"kubernetes.io/projected/ac0e590f-dca5-4715-995e-74403ceda012-kube-api-access-ksh9n\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.449678    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-ksxrs\" (UniqueName: \"kubernetes.io/projected/55faba26-5b80-454f-af2c-ee4f696ca821-kube-api-access-ksxrs\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.450593    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:45.950569745 +0000 UTC m=+3497.625646159 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.451211    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.451516    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:45.951500454 +0000 UTC m=+3497.626576881 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.452259    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.452351    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-v47xk\" (UniqueName: \"kubernetes.io/projected/50025e5a-affc-4a6c-a357-a1d5d010b737-kube-api-access-v47xk\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.452542    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:45.952531921 +0000 UTC m=+3497.627608334 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.458764    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/55faba26-5b80-454f-af2c-ee4f696ca821-kube-api-access-ksxrs" (OuterVolumeSpecName: "kube-api-access-ksxrs") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821"). InnerVolumeSpecName "kube-api-access-ksxrs". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.460385    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/ac0e590f-dca5-4715-995e-74403ceda012-kube-api-access-ksh9n" (OuterVolumeSpecName: "kube-api-access-ksh9n") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012"). InnerVolumeSpecName "kube-api-access-ksh9n". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.553892    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-ksh9n\" (UniqueName: \"kubernetes.io/projected/ac0e590f-dca5-4715-995e-74403ceda012-kube-api-access-ksh9n\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.553924    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-ksxrs\" (UniqueName: \"kubernetes.io/projected/55faba26-5b80-454f-af2c-ee4f696ca821-kube-api-access-ksxrs\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.857729    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.857828    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.858083    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:46.858067253 +0000 UTC m=+3498.533143655 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.858179    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:46.858159845 +0000 UTC m=+3498.533236264 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.959019    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.959225    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.959318    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:45.959362    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.959395    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:46.959377077 +0000 UTC m=+3498.634453495 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.959589    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:46.959578409 +0000 UTC m=+3498.634654810 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.959633    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:46.959621542 +0000 UTC m=+3498.634697969 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:45.959772    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:46.959699951 +0000 UTC m=+3498.634776353 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:46.868046    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:46.868215    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:46.868828    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:48.868810278 +0000 UTC m=+3500.543886690 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:46.868878    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:48.868870855 +0000 UTC m=+3500.543947255 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:46.968544    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:46.968599    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:46.968687    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:46.968721    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:46.969725    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:48.969707869 +0000 UTC m=+3500.644784283 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:46.969836    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:48.969827297 +0000 UTC m=+3500.644903711 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:46.969887    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:48.96987922 +0000 UTC m=+3500.644955634 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:46.969925    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:48.969919451 +0000 UTC m=+3500.644995866 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:48.885913    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:48.886054    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:48.886476    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:52.88645963 +0000 UTC m=+3504.561536032 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:48.886523    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:52.886512804 +0000 UTC m=+3504.561589205 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:48.986688    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:48.986780    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:48.986855    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:48.986891    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:48.987043    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:52.987026639 +0000 UTC m=+3504.662103052 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:48.987092    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:52.987085149 +0000 UTC m=+3504.662161589 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:48.987195    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:52.987179482 +0000 UTC m=+3504.662255899 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:48.987566    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:56:52.987553887 +0000 UTC m=+3504.662630289 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: no such file or directory"
Sep 05 14:56:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:50.323681    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:56:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:52.926712    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:52.926843    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:53.028091    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:53.028148    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:53.028236    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:56:53.028274    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:53.069740    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:01.069709972 +0000 UTC m=+3512.744786385 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:53.071298    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:01.071276587 +0000 UTC m=+3512.746353002 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:53.220159    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:01.220133897 +0000 UTC m=+3512.895210311 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:53.220631    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:01.220611131 +0000 UTC m=+3512.895687545 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:53.452208    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:01.452182184 +0000 UTC m=+3513.127258586 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:56:53.777139    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:01.777112365 +0000 UTC m=+3513.452188779 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:00.391474    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:01.113850    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:01.113977    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:01.233209    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:17.233184033 +0000 UTC m=+3528.908260440 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:01.244685    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:17.24465874 +0000 UTC m=+3528.919735153 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:01.315568    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:01.315674    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:01.516840    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:01.529798    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:17.529770641 +0000 UTC m=+3529.204847055 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:01.538014    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:17.53798902 +0000 UTC m=+3529.213065435 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:01.616293    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:17.616267405 +0000 UTC m=+3529.291343819 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:01.819686    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:57:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:01.906042    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:17.90601625 +0000 UTC m=+3529.581092665 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:15.547302    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:17.242706    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:17.345023    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:17.362253    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:49.362205585 +0000 UTC m=+3561.037282000 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:17.440386    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:50025e5a-affc-4a6c-a357-a1d5d010b737 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:49.44034837 +0000 UTC m=+3561.115424785 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:17.547326    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:17.547538    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:17.648149    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:17.683309    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:49.683275598 +0000 UTC m=+3561.358352013 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:17.694716    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:55faba26-5b80-454f-af2c-ee4f696ca821 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:49.694677278 +0000 UTC m=+3561.369753692 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:17.775342    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^385915596530033791 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:49.7753047 +0000 UTC m=+3561.450381114 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes/kubernetes.io~csi/pvc-d458b250-1019-4972-a88d-305081928b73/mount
Sep 05 14:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:17.951864    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:57:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 14:57:18.057575    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1107545556147400920 podName:ac0e590f-dca5-4715-995e-74403ceda012 nodeName:}" failed. No retries permitted until 2022-09-05 14:57:50.057541389 +0000 UTC m=+3561.732617794 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes/kubernetes.io~csi/pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0/mount
Sep 05 14:57:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:20.838374    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:57:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:30.391024    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:57:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:31.700266    6839 scope.go:110] "RemoveContainer" containerID="60faf75992363b63e7444a8d5afecb5bffbbeed7a55445a67440e805b5945920"
Sep 05 14:57:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:31.713182    6839 scope.go:110] "RemoveContainer" containerID="506123e3e94e6c412d0dfb898a140654025256a5a4036a841f7122d7c0f1d769"
Sep 05 14:57:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:31.718199    6839 scope.go:110] "RemoveContainer" containerID="56fd1d7e8df2b1944905d49c252d679570f50229b68af0d430a5c5e3294f4bb3"
Sep 05 14:57:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:33.391357    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.433783    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.523920    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^385915596530033791" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737"). InnerVolumeSpecName "pvc-d458b250-1019-4972-a88d-305081928b73". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.534591    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"50025e5a-affc-4a6c-a357-a1d5d010b737\" (UID: \"50025e5a-affc-4a6c-a357-a1d5d010b737\") "
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.623314    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^1107545556147400920" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "50025e5a-affc-4a6c-a357-a1d5d010b737" (UID: "50025e5a-affc-4a6c-a357-a1d5d010b737"). InnerVolumeSpecName "pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.736609    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.736705    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"55faba26-5b80-454f-af2c-ee4f696ca821\" (UID: \"55faba26-5b80-454f-af2c-ee4f696ca821\") "
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.837251    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.889286    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^1107545556147400920" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821"). InnerVolumeSpecName "pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:57:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:49.898377    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^385915596530033791" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "55faba26-5b80-454f-af2c-ee4f696ca821" (UID: "55faba26-5b80-454f-af2c-ee4f696ca821"). InnerVolumeSpecName "pvc-d458b250-1019-4972-a88d-305081928b73". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.041897    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^385915596530033791" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012"). InnerVolumeSpecName "pvc-d458b250-1019-4972-a88d-305081928b73". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.141256    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") pod \"ac0e590f-dca5-4715-995e-74403ceda012\" (UID: \"ac0e590f-dca5-4715-995e-74403ceda012\") "
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.141346    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-d458b250-1019-4972-a88d-305081928b73\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.145663    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.147466    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-d458b250-1019-4972-a88d-305081928b73" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^385915596530033791") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.236681    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^1107545556147400920" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "ac0e590f-dca5-4715-995e-74403ceda012" (UID: "ac0e590f-dca5-4715-995e-74403ceda012"). InnerVolumeSpecName "pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.242243    6839 reconciler.go:384] "Volume detached for volume \"pvc-d458b250-1019-4972-a88d-305081928b73\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^385915596530033791\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.242320    6839 reconciler.go:377] "operationExecutor.UnmountDevice started for volume \"pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" "
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.245369    6839 csi_attacher.go:614] kubernetes.io/csi: attacher.UnmountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping UnmountDevice...
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.246058    6839 operation_generator.go:977] UnmountDevice succeeded for volume "pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1107545556147400920") on node "ip-10-13-112-170.pwx.dev.purestorage.com"
Sep 05 14:57:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:50.343395    6839 reconciler.go:384] "Volume detached for volume \"pvc-0ff78a88-3b3f-4e74-bb20-614a01879ee0\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1107545556147400920\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 14:57:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:52.399678    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=50025e5a-affc-4a6c-a357-a1d5d010b737 path="/var/lib/kubelet/pods/50025e5a-affc-4a6c-a357-a1d5d010b737/volumes"
Sep 05 14:57:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:52.417826    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=55faba26-5b80-454f-af2c-ee4f696ca821 path="/var/lib/kubelet/pods/55faba26-5b80-454f-af2c-ee4f696ca821/volumes"
Sep 05 14:57:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:57:52.419455    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=ac0e590f-dca5-4715-995e-74403ceda012 path="/var/lib/kubelet/pods/ac0e590f-dca5-4715-995e-74403ceda012/volumes"
Sep 05 14:58:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:58:04.391267    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:58:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:58:30.391576    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 14:58:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:58:33.391060    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:58:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:58:38.391144    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:58:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:58:53.391548    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:59:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:59:31.391620    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 14:59:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:59:41.391777    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 14:59:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:59:44.391375    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 14:59:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:59:56.394003    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 14:59:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 14:59:57.391553    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:00:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:00:33.391480    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:00:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:00:57.390758    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:01:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:01:01.390844    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:01:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:01:07.391134    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:01:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:01:10.391091    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:01:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:01:49.391518    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:02:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:02:14.391160    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:02:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:02:17.391471    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:02:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:02:20.392174    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:02:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:02:30.391843    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:02:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:02:57.391120    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:03:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:03:30.392404    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:03:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:03:30.392746    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:03:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:03:32.391799    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:03:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:03:41.390642    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:04:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:04:22.392053    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:04:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:04:39.391247    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:04:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:04:46.391384    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:04:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:04:53.391233    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:04:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:04:59.391523    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:05:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:05:27.390611    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:06:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:00.391549    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:06:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:04.391196    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.248550    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:06:07.248636    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="50025e5a-affc-4a6c-a357-a1d5d010b737" containerName="vdbench"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:06:07.248649    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="82492342-e5c5-4cee-b1ab-f3fe1f277460" containerName="init-sysctl"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:06:07.248667    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="82492342-e5c5-4cee-b1ab-f3fe1f277460" containerName="elasticsearch"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:06:07.248674    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="333dd88b-8c22-41f2-baf7-50f99646d4cc" containerName="es-load"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:06:07.248680    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="ac0e590f-dca5-4715-995e-74403ceda012" containerName="vdbench"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:06:07.248685    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="55faba26-5b80-454f-af2c-ee4f696ca821" containerName="vdbench"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.248728    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="333dd88b-8c22-41f2-baf7-50f99646d4cc" containerName="es-load"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.248750    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="50025e5a-affc-4a6c-a357-a1d5d010b737" containerName="vdbench"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.248756    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="82492342-e5c5-4cee-b1ab-f3fe1f277460" containerName="elasticsearch"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.248766    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="ac0e590f-dca5-4715-995e-74403ceda012" containerName="vdbench"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.248774    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="55faba26-5b80-454f-af2c-ee4f696ca821" containerName="vdbench"
Sep 05 15:06:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:07.389826    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-xts74\" (UniqueName: \"kubernetes.io/projected/7b7962cf-6442-42f1-b016-c6b2e790f58f-kube-api-access-xts74\") pod \"es-load-769678797c-psdjr\" (UID: \"7b7962cf-6442-42f1-b016-c6b2e790f58f\") " pod="elasticsearch-voldrivercrash-0-09-05-14h07m47s/es-load-769678797c-psdjr"
Sep 05 15:06:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:14.392062    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.496114    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.562425    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-vqxts\" (UniqueName: \"kubernetes.io/projected/704c584f-f8a5-487f-aadc-61ad4f2f0810-kube-api-access-vqxts\") pod \"vdbench-sharedv4-74b9988cdd-rk8g8\" (UID: \"704c584f-f8a5-487f-aadc-61ad4f2f0810\") " pod="vdbench-sharedv4-voldrivercrash-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-rk8g8"
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.562500    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-e314a8e6-e677-4ff2-b1e4-00603de8055e\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^630053183417591705\") pod \"vdbench-sharedv4-74b9988cdd-rk8g8\" (UID: \"704c584f-f8a5-487f-aadc-61ad4f2f0810\") " pod="vdbench-sharedv4-voldrivercrash-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-rk8g8"
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.562533    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-d6934764-eed4-477f-be02-097467550b07\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^649657884110828259\") pod \"vdbench-sharedv4-74b9988cdd-rk8g8\" (UID: \"704c584f-f8a5-487f-aadc-61ad4f2f0810\") " pod="vdbench-sharedv4-voldrivercrash-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-rk8g8"
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.687200    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.687241    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.687289    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-d6934764-eed4-477f-be02-097467550b07\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^649657884110828259\") pod \"vdbench-sharedv4-74b9988cdd-rk8g8\" (UID: \"704c584f-f8a5-487f-aadc-61ad4f2f0810\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/411167bdae84dfca4df602228b887df56a38372f7bb28f9ca8011fe274d6970c/globalmount\"" pod="vdbench-sharedv4-voldrivercrash-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-rk8g8"
Sep 05 15:06:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:19.687283    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-e314a8e6-e677-4ff2-b1e4-00603de8055e\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^630053183417591705\") pod \"vdbench-sharedv4-74b9988cdd-rk8g8\" (UID: \"704c584f-f8a5-487f-aadc-61ad4f2f0810\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/2aab46665319d10d48d10bece77f4c0fdd511f853de5a67acc1605e5916d9c6e/globalmount\"" pod="vdbench-sharedv4-voldrivercrash-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-rk8g8"
Sep 05 15:06:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:23.391139    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:06:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:24.697032    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:06:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:24.901439    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-gfvwp\" (UniqueName: \"kubernetes.io/projected/aa597ba7-9ebd-46f0-8266-f1d203f1a55f-kube-api-access-gfvwp\") pod \"vdbench-sharedv4-74b9988cdd-7jxxg\" (UID: \"aa597ba7-9ebd-46f0-8266-f1d203f1a55f\") " pod="vdbench-sharedv4-voldrivercrash-0-09-05-14h07m47s/vdbench-sharedv4-74b9988cdd-7jxxg"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.611244    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.738433    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-s4csp\" (UniqueName: \"kubernetes.io/projected/59cab706-7552-4810-9998-5ab88a0d18b5-kube-api-access-s4csp\") pod \"vdbench-sv4-svc-57678cbc89-qs7qd\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-qs7qd"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.738540    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-0d81053d-6952-404d-b213-2adea82bc609\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"vdbench-sv4-svc-57678cbc89-qs7qd\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-qs7qd"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.738853    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"vdbench-sv4-svc-57678cbc89-qs7qd\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-qs7qd"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.791517    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.842138    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.842194    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-0d81053d-6952-404d-b213-2adea82bc609\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"vdbench-sv4-svc-57678cbc89-qs7qd\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/6b821a89f3c326df7e964e1576794870ab7f8dbf4f5bf25d2df31660913bde27/globalmount\"" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-qs7qd"
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.842364    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 15:06:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:34.842403    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"vdbench-sv4-svc-57678cbc89-qs7qd\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/e9a63f6db3f82751dbc2276a3331b0ac71a2f0a06382f368dae5c391ed538d05/globalmount\"" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-qs7qd"
Sep 05 15:06:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:36.051078    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-spgvn\" (UniqueName: \"kubernetes.io/projected/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b-kube-api-access-spgvn\") pod \"vdbench-sv4-svc-57678cbc89-jkknc\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-jkknc"
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.233290    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.307815    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-91e3ed33-86b0-4a7b-b339-49cd2fa6a01f\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^752541933074768767\") pod \"nginx-6b5d97d5cb-m2xjx\" (UID: \"9eceef41-924e-41c4-9cb0-bbb06a3961e2\") " pod="nginx-sharedv4-voldrivercrash-0-09-05-14h07m47s/nginx-6b5d97d5cb-m2xjx"
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.307896    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-s562x\" (UniqueName: \"kubernetes.io/projected/9eceef41-924e-41c4-9cb0-bbb06a3961e2-kube-api-access-s562x\") pod \"nginx-6b5d97d5cb-m2xjx\" (UID: \"9eceef41-924e-41c4-9cb0-bbb06a3961e2\") " pod="nginx-sharedv4-voldrivercrash-0-09-05-14h07m47s/nginx-6b5d97d5cb-m2xjx"
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.307936    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"pvc-26b49b39-0d91-408d-90bd-4366fa2669b9\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^11339043257686155\") pod \"nginx-6b5d97d5cb-m2xjx\" (UID: \"9eceef41-924e-41c4-9cb0-bbb06a3961e2\") " pod="nginx-sharedv4-voldrivercrash-0-09-05-14h07m47s/nginx-6b5d97d5cb-m2xjx"
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.415620    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.415677    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-91e3ed33-86b0-4a7b-b339-49cd2fa6a01f\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^752541933074768767\") pod \"nginx-6b5d97d5cb-m2xjx\" (UID: \"9eceef41-924e-41c4-9cb0-bbb06a3961e2\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/8e80b0b77e9e9273ce5c8a11ebea5ef71bc5384507b3bd49b7f65461cd6deddf/globalmount\"" pod="nginx-sharedv4-voldrivercrash-0-09-05-14h07m47s/nginx-6b5d97d5cb-m2xjx"
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.416127    6839 csi_attacher.go:358] kubernetes.io/csi: attacher.MountDevice STAGE_UNSTAGE_VOLUME capability not set. Skipping MountDevice...
Sep 05 15:06:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:39.416165    6839 operation_generator.go:658] "MountVolume.MountDevice succeeded for volume \"pvc-26b49b39-0d91-408d-90bd-4366fa2669b9\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^11339043257686155\") pod \"nginx-6b5d97d5cb-m2xjx\" (UID: \"9eceef41-924e-41c4-9cb0-bbb06a3961e2\") device mount path \"/var/lib/kubelet/plugins/kubernetes.io/csi/pxd.portworx.com/4f4618a7b5ac9d4397ebd4b589b6e89d0ee897feda1a70dedb5363fe2ce0a33c/globalmount\"" pod="nginx-sharedv4-voldrivercrash-0-09-05-14h07m47s/nginx-6b5d97d5cb-m2xjx"
Sep 05 15:06:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:06:42.397125    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:07:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:07:08.391791    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:07:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:07:20.393607    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:07:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:07:24.392569    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:07:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:07:31.391614    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:08:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:08:05.391909    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:08:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:08:30.394768    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:08:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:08:30.395028    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:08:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:08:41.391199    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:08:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:08:54.391981    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:28.391575    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:39.303424    6839 scope.go:110] "RemoveContainer" containerID="f383fbdcdbca169abb8776d5e6e757d42b8ac6883ae8878af204a57e7847bfff"
Sep 05 15:09:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:39.303836    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:39.303962    6839 scope.go:110] "RemoveContainer" containerID="1eb7eb0edd9c5401b6e7fee3b01cec823bd23e5957109c0d2167dd396ebb2e0c"
Sep 05 15:09:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:39.303979    6839 scope.go:110] "RemoveContainer" containerID="34043eb8602062aae6b8e907c77424ee5ec14a1aae9fff72101017049fa01e61"
Sep 05 15:09:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:39.313681    6839 scope.go:110] "RemoveContainer" containerID="941df04b861df49b808c18ddc952609ba2c3fffffa1a2f2cf22ea43c71458684"
Sep 05 15:09:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:40.309590    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:41.311528    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:48.391055    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:56.391259    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:09:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:09:59.391118    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:10:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:10:00.326043    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:10:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:10:09.948836    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:10:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:10:52.391891    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:02.391386    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:16.391161    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:24.394332    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:26.168417    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:26.342936    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-9s77d\" (UniqueName: \"kubernetes.io/projected/5a21d20f-cacd-43fe-be3e-194c34c673cd-kube-api-access-9s77d\") pod \"vdbench-sv4-svc-57678cbc89-25pgg\" (UID: \"5a21d20f-cacd-43fe-be3e-194c34c673cd\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-25pgg"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:26.344158    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:26.844131299 +0000 UTC m=+4378.519207713 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:26.344788    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:26.84476552 +0000 UTC m=+4378.519841975 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:26.640828    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:26.905570    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:27.905548501 +0000 UTC m=+4379.580624915 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:26.906347    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:27.906333831 +0000 UTC m=+4379.581410232 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:26.954720    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-lw95l\" (UniqueName: \"kubernetes.io/projected/0454503f-4399-46fc-ac26-7ada4ecaaa70-kube-api-access-lw95l\") pod \"vdbench-sv4-svc-57678cbc89-prrhl\" (UID: \"0454503f-4399-46fc-ac26-7ada4ecaaa70\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:11:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:27.967903    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.967876728 +0000 UTC m=+4381.642953147 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:27.968323    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.968250953 +0000 UTC m=+4381.643327367 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.562484    6839 scope.go:110] "RemoveContainer" containerID="94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.571004    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-s4csp\" (UniqueName: \"kubernetes.io/projected/59cab706-7552-4810-9998-5ab88a0d18b5-kube-api-access-s4csp\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.571716    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.572221    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.572281    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"kube-api-access-spgvn\" (UniqueName: \"kubernetes.io/projected/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b-kube-api-access-spgvn\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.572749    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.072716322 +0000 UTC m=+4380.747792740 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.572835    6839 scope.go:110] "RemoveContainer" containerID="94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.573335    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12\": not found" containerID="94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.573425    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12} err="failed to get container status \"94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12\": rpc error: code = NotFound desc = an error occurred when try to find container \"94d9b7bc9df7a1f38848fb2bd658bb4c8d9731fb2e26f34d79b55b119d3e0e12\": not found"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.573445    6839 scope.go:110] "RemoveContainer" containerID="6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.574408    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.074389564 +0000 UTC m=+4380.749465984 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.576618    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.577092    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.077067679 +0000 UTC m=+4380.752144103 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.577188    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.577606    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.077591851 +0000 UTC m=+4380.752668269 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.577781    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.077765333 +0000 UTC m=+4380.752841760 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.577966    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.077941516 +0000 UTC m=+4380.753017945 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.589006    6839 scope.go:110] "RemoveContainer" containerID="6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.589563    6839 remote_runtime.go:604] "ContainerStatus from runtime service failed" err="rpc error: code = NotFound desc = an error occurred when try to find container \"6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0\": not found" containerID="6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.589602    6839 pod_container_deletor.go:52] "DeleteContainer returned error" containerID={Type:containerd ID:6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0} err="failed to get container status \"6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0\": rpc error: code = NotFound desc = an error occurred when try to find container \"6439a65720641dd0bca2b4d5d7e73f3a2988bf709718861c0be76fc85d2a58e0\": not found"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.591671    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b-kube-api-access-spgvn" (OuterVolumeSpecName: "kube-api-access-spgvn") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b"). InnerVolumeSpecName "kube-api-access-spgvn". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.591748    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/projected/59cab706-7552-4810-9998-5ab88a0d18b5-kube-api-access-s4csp" (OuterVolumeSpecName: "kube-api-access-s4csp") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5"). InnerVolumeSpecName "kube-api-access-s4csp". PluginName "kubernetes.io/projected", VolumeGidValue ""
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.678048    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.678168    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.678274    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.678481    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-spgvn\" (UniqueName: \"kubernetes.io/projected/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b-kube-api-access-spgvn\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.678522    6839 reconciler.go:384] "Volume detached for volume \"kube-api-access-s4csp\" (UniqueName: \"kubernetes.io/projected/59cab706-7552-4810-9998-5ab88a0d18b5-kube-api-access-s4csp\") on node \"ip-10-13-112-170.pwx.dev.purestorage.com\" DevicePath \"\""
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.678858    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.178832749 +0000 UTC m=+4380.853909172 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.678902    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.178879509 +0000 UTC m=+4380.853955926 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.679276    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.179246255 +0000 UTC m=+4380.854322673 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.779902    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.279884538 +0000 UTC m=+4380.954960952 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.780326    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.280309933 +0000 UTC m=+4380.955386335 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.880108    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.880168    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:28.880222    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.880800    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.380776882 +0000 UTC m=+4381.055853296 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.880854    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.380845643 +0000 UTC m=+4381.055922057 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.880891    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.380885159 +0000 UTC m=+4381.055961574 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.982676    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.482657327 +0000 UTC m=+4381.157733740 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:28.982739    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.482723093 +0000 UTC m=+4381.157799495 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.083291    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.083396    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.084066    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.584049101 +0000 UTC m=+4381.259125514 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.084116    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.584106862 +0000 UTC m=+4381.259183278 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.184002    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.184775    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.684752755 +0000 UTC m=+4381.359829174 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.185011    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.684995911 +0000 UTC m=+4381.360072326 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.185067    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.185059313 +0000 UTC m=+4381.860135728 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.287860    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.287961    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.288032    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.288086    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.289024    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.289001179 +0000 UTC m=+4381.964077594 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.289097    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.789085884 +0000 UTC m=+4381.464162299 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.289151    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.28914084 +0000 UTC m=+4381.964217243 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.289206    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.789196641 +0000 UTC m=+4381.464273047 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.390345    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.8903226 +0000 UTC m=+4381.565399019 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.390726    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.890712849 +0000 UTC m=+4381.565789262 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.490587    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.490745    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.491415    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.991392572 +0000 UTC m=+4381.666468989 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.491506    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:29.991480413 +0000 UTC m=+4381.666556829 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.593002    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.092977338 +0000 UTC m=+4381.768053753 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.593453    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.093438492 +0000 UTC m=+4381.768514907 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.693089    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.693248    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.693589    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.193560667 +0000 UTC m=+4381.868637084 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.693641    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.193625701 +0000 UTC m=+4381.868702104 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.796035    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.29600187 +0000 UTC m=+4381.971078294 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.796553    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.296530577 +0000 UTC m=+4381.971606995 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.895463    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:29.895622    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.896120    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.396101246 +0000 UTC m=+4382.071177661 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:29.896140    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.396132645 +0000 UTC m=+4382.071209048 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.002595    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.502568663 +0000 UTC m=+4382.177645081 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.003145    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.503123938 +0000 UTC m=+4382.178200357 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.101636    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.101771    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.102726    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.602697371 +0000 UTC m=+4382.277773780 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.102757    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.602745577 +0000 UTC m=+4382.277821978 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.204689    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.704658565 +0000 UTC m=+4382.379734991 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.204752    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.704732144 +0000 UTC m=+4382.379808560 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.304288    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.304396    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.304478    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.304570    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.305324    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.30529757 +0000 UTC m=+4383.980373973 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.305391    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.805380682 +0000 UTC m=+4382.480457084 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.305445    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.305438058 +0000 UTC m=+4383.980514461 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.305508    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.805483865 +0000 UTC m=+4382.480560281 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.406729    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.906707251 +0000 UTC m=+4382.581783666 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.406843    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:30.906818117 +0000 UTC m=+4382.581894533 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.507393    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.507686    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.508007    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.007986246 +0000 UTC m=+4382.683062667 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.508029    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.008021308 +0000 UTC m=+4382.683097711 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.611019    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.110999363 +0000 UTC m=+4382.786075777 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.611272    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.111247045 +0000 UTC m=+4382.786323463 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.711393    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.711532    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.711954    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.211936385 +0000 UTC m=+4382.887012786 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.712014    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.212005521 +0000 UTC m=+4382.887081924 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.712482    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.212466612 +0000 UTC m=+4382.887543039 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.712517    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.212507523 +0000 UTC m=+4382.887583926 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.812307    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:30.812465    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.813208    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.313191171 +0000 UTC m=+4382.988267585 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.813261    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.313252663 +0000 UTC m=+4382.988329077 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.915085    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.415016927 +0000 UTC m=+4383.090093344 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:30.915129    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.415115485 +0000 UTC m=+4383.090191888 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.015748    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.016487    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.516389864 +0000 UTC m=+4383.191466280 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.016646    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.017721    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.517701544 +0000 UTC m=+4383.192777962 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.017799    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.51778788 +0000 UTC m=+4383.192864304 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.118635    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.119432    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.619409956 +0000 UTC m=+4383.294486372 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.119516    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.619502446 +0000 UTC m=+4383.294578863 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.219526    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.220554    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.720519603 +0000 UTC m=+4383.395596017 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.220777    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.720767679 +0000 UTC m=+4383.395844094 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.320859    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.321740    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.821719847 +0000 UTC m=+4383.496796250 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.321979    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.821964834 +0000 UTC m=+4383.497041250 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.422202    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.423103    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.92308583 +0000 UTC m=+4383.598162244 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.423156    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:31.923149756 +0000 UTC m=+4383.598226170 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.522995    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.524269    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.024238194 +0000 UTC m=+4383.699314612 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.525037    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.024995087 +0000 UTC m=+4383.700071502 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.623814    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.623872    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.624224    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.124206059 +0000 UTC m=+4383.799282486 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.624375    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.624366442 +0000 UTC m=+4384.299442858 (durationBeforeRetry 1s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.624571    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.124556914 +0000 UTC m=+4383.799633329 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.725827    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.726828    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.22679867 +0000 UTC m=+4383.901875085 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.726867    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.226843954 +0000 UTC m=+4383.901920369 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.827541    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.827998    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.327971249 +0000 UTC m=+4384.003047673 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.828401    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.328385848 +0000 UTC m=+4384.003462252 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:31.929024    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.929923    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.429872971 +0000 UTC m=+4384.104949386 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:31.930202    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.430173548 +0000 UTC m=+4384.105249964 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.030432    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.031618    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.531590848 +0000 UTC m=+4384.206667264 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.031656    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.531644269 +0000 UTC m=+4384.206720672 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.131839    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.133119    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.633073393 +0000 UTC m=+4384.308149806 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.133435    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.633421688 +0000 UTC m=+4384.308498102 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.232685    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.233843    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.733817105 +0000 UTC m=+4384.408893528 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.234018    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.733998711 +0000 UTC m=+4384.409075131 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.333711    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.333774    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.334792    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.834763819 +0000 UTC m=+4384.509840236 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.334896    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:36.334886314 +0000 UTC m=+4388.009962716 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.338886    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.838866172 +0000 UTC m=+4384.513942574 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.435410    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.435532    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.435869    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.935848106 +0000 UTC m=+4384.610924509 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.435978    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:36.435963707 +0000 UTC m=+4388.111040145 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.436093    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:32.936074978 +0000 UTC m=+4384.611151421 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.537484    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.537583    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.538757    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.038731715 +0000 UTC m=+4384.713808138 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.539048    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.039033922 +0000 UTC m=+4384.714110325 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.539115    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.539104684 +0000 UTC m=+4386.214181089 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.638740    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.640025    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.140005469 +0000 UTC m=+4384.815081884 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.640373    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.140360504 +0000 UTC m=+4384.815436906 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.739622    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.740663    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.240642757 +0000 UTC m=+4384.915719178 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.740926    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.240910768 +0000 UTC m=+4384.915987193 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.840647    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.841431    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.341408953 +0000 UTC m=+4385.016485372 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.841557    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.341539969 +0000 UTC m=+4385.016616369 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:32.942094    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.942668    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.442650022 +0000 UTC m=+4385.117726440 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:32.942972    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.442953208 +0000 UTC m=+4385.118029629 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.042751    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.043268    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.543245521 +0000 UTC m=+4385.218321997 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.043299    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.543291405 +0000 UTC m=+4385.218367806 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.143250    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.143744    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.643720119 +0000 UTC m=+4385.318796539 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.144349    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.644330513 +0000 UTC m=+4385.319406928 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.144367    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.644360511 +0000 UTC m=+4385.319436913 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.245358    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.245570    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.245631    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.245880    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.745855743 +0000 UTC m=+4385.420932162 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.245977    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.745959454 +0000 UTC m=+4385.421035870 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.246024    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:35.245992317 +0000 UTC m=+4386.921068729 (durationBeforeRetry 2s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.347711    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.847686015 +0000 UTC m=+4385.522762429 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.347908    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.847886293 +0000 UTC m=+4385.522962709 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.448254    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.448363    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.448765    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.948748735 +0000 UTC m=+4385.623825150 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.448827    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:33.948805788 +0000 UTC m=+4385.623882198 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.549400    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.049378674 +0000 UTC m=+4385.724455076 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.550141    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.050119782 +0000 UTC m=+4385.725196195 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.649953    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.650081    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.650723    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.150701185 +0000 UTC m=+4385.825777602 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.650780    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.150772422 +0000 UTC m=+4385.825848840 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-persistent-storage-enc" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.754760    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.254728453 +0000 UTC m=+4385.929804878 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:33.755394    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:34.255369592 +0000 UTC m=+4385.930446015 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : kubernetes.io/csi: mounter.SetUpAt failed to check for STAGE_UNSTAGE_VOLUME capability: rpc error: code = Unavailable desc = connection error: desc = "transport: Error while dialing dial unix /var/lib/kubelet/plugins/pxd.portworx.com/csi.sock: connect: connection refused"
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.855667    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:33.855919    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:34.391876    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:34.588672    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:35.486984    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^1128534796363700257" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5"). InnerVolumeSpecName "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 15:11:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:35.571998    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:39.57197271 +0000 UTC m=+4391.247049119 (durationBeforeRetry 4s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:37.727123    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:38.227086586 +0000 UTC m=+4389.902163002 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = Failed to mount volume 920849628428829313: rpc error: code = Internal desc = Failed to mount volume 920849628428829313: Error in grpc: rpc error: code = Unavailable desc = all SubConns are in TransientFailure
Sep 05 15:11:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:37.810258    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:37.810325    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:39.942663    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:40.442629552 +0000 UTC m=+4392.117705955 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = Failed to mount volume 1128534796363700257: Put "http://10.13.114.5:9001/v1/osd-volumes/1128534796363700257": EOF
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:40.029553    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-persistent-storage-enc\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^1128534796363700257\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.101353    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:48.101327359 +0000 UTC m=+4399.776403761 (durationBeforeRetry 8s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.101557    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:40.601530434 +0000 UTC m=+4392.276606852 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:40.151354    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^1128534796363700257" (OuterVolumeSpecName: "vdbench-persistent-storage-enc") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b"). InnerVolumeSpecName "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.171507    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:40.671463813 +0000 UTC m=+4392.346540218 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:40.231732    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.274674    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:44.274640426 +0000 UTC m=+4395.949716846 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/1128534796363700257": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.330812    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:40.830780661 +0000 UTC m=+4392.505857076 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.374820    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:40.874793009 +0000 UTC m=+4392.549869428 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/1128534796363700257": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.374855    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:40.874846482 +0000 UTC m=+4392.549922904 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:40.434005    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.534212    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.034180172 +0000 UTC m=+4392.709256579 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.567220    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.067191951 +0000 UTC m=+4392.742268353 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:40.635532    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.824035    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.324007136 +0000 UTC m=+4392.999083541 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.874574    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.374542752 +0000 UTC m=+4393.049619169 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:40.938200    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:40.979645    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.97961722 +0000 UTC m=+4393.654693622 (durationBeforeRetry 1s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/1128534796363700257": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:41.041705    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.541668943 +0000 UTC m=+4393.216745364 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:41.177964    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.677937374 +0000 UTC m=+4393.353013777 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:41.241163    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:41.343108    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.843082162 +0000 UTC m=+4393.518158564 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:41.481802    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:41.981766288 +0000 UTC m=+4393.656842707 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:41.543065    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:41.746901    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:42.246873921 +0000 UTC m=+4393.921950336 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:41.899968    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:42.399939041 +0000 UTC m=+4394.075015444 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:41.947232    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.090561    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:44.090528896 +0000 UTC m=+4395.765605314 (durationBeforeRetry 2s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/1128534796363700257": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.146569    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:42.646531417 +0000 UTC m=+4394.321607822 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.182601    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:42.682574587 +0000 UTC m=+4394.357650989 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:42.250762    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.542538    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:43.042486433 +0000 UTC m=+4394.717562855 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.591657    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:43.091623313 +0000 UTC m=+4394.766699738 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:42.656254    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.946715    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:43.446677951 +0000 UTC m=+4395.121754365 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:42.995353    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:43.495327121 +0000 UTC m=+4395.170403524 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:43.060047    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:43.343589    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:43.843558559 +0000 UTC m=+4395.518634963 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:43.396661    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:43.89663463 +0000 UTC m=+4395.571711045 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:43.462794    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:43.748203    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:44.248170034 +0000 UTC m=+4395.923246444 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:43.801293    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:44.301260228 +0000 UTC m=+4395.976336646 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:43.865846    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:44.147371    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:44.647343629 +0000 UTC m=+4396.322420043 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:44.216662    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:44.716631027 +0000 UTC m=+4396.391707447 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:44.216877    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:48.216858407 +0000 UTC m=+4399.891934813 (durationBeforeRetry 4s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/1128534796363700257": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:44.270320    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:44.551846    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:45.051811661 +0000 UTC m=+4396.726888082 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:44.612734    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:45.112708329 +0000 UTC m=+4396.787784742 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:44.674100    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:44.951132    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:45.451097356 +0000 UTC m=+4397.126173780 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:45.016771    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:45.516734319 +0000 UTC m=+4397.191810733 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:45.078672    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:45.350288    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:45.850251943 +0000 UTC m=+4397.525328362 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:45.417125    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:45.917098946 +0000 UTC m=+4397.592175360 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:45.482324    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:45.751083    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:46.251052636 +0000 UTC m=+4397.926129039 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:45.819088    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:46.319051698 +0000 UTC m=+4397.994128112 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:45.886703    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:46.149701    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:46.649660286 +0000 UTC m=+4398.324736707 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:46.225844    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:46.725814647 +0000 UTC m=+4398.400891048 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:46.289744    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:46.562473    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:47.06244314 +0000 UTC m=+4398.737519546 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:46.629210    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:47.129181187 +0000 UTC m=+4398.804257601 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:46.693849    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:46.945840    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:47.445802674 +0000 UTC m=+4399.120879091 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:47.034235    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:47.534200831 +0000 UTC m=+4399.209277240 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:47.098215    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:47.354620    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:47.854590662 +0000 UTC m=+4399.529667066 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:47.442210    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:47.942175618 +0000 UTC m=+4399.617252036 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: Put "http://10.13.114.5:9001/v1/osd-volumes/920849628428829313": dial tcp 10.13.114.5:9001: connect: connection refused
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:47.502103    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:47.750536    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:48.250480664 +0000 UTC m=+4399.925557081 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:47.844761    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:48.344724344 +0000 UTC m=+4400.019800760 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:47.906538    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:48.108269    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:48.159749    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:48.659714846 +0000 UTC m=+4400.334791262 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:48.346875    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:56.346835895 +0000 UTC m=+4408.021912314 (durationBeforeRetry 8s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:48.545538    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:12:04.545505604 +0000 UTC m=+4416.220582021 (durationBeforeRetry 16s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:48.573331    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:49.073298574 +0000 UTC m=+4400.748374989 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:48.612236    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:48.948687    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:49.448655461 +0000 UTC m=+4401.123731867 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:49.061086    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:49.56105939 +0000 UTC m=+4401.236135803 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:49.116896    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:49.350026    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:49.849997944 +0000 UTC m=+4401.525074359 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:49.456123    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:49.956093092 +0000 UTC m=+4401.631169512 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:49.520920    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:49.747237    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:50.247197788 +0000 UTC m=+4401.922274194 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:49.863390    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:50.363361708 +0000 UTC m=+4402.038438122 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:49.925264    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:50.152689    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:50.652663095 +0000 UTC m=+4402.327739498 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:50.262223    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:50.762196547 +0000 UTC m=+4402.437272949 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:50.329376    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:50.550241    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:51.050213203 +0000 UTC m=+4402.725289617 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:50.668384    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:51.168357926 +0000 UTC m=+4402.843434346 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:50.733027    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:50.948679    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:51.448652387 +0000 UTC m=+4403.123728790 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:51.076834    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:51.576807601 +0000 UTC m=+4403.251884003 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:51.135937    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:51.347432    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:51.847404956 +0000 UTC m=+4403.522481371 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:51.478892    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:51.978856585 +0000 UTC m=+4403.653932990 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:51.540407    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:51.750074    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:52.250041268 +0000 UTC m=+4403.925117681 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:51.884857    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:52.38481944 +0000 UTC m=+4404.059895868 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:51.943065    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:52.167893    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:52.667847283 +0000 UTC m=+4404.342923712 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:52.280724    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:52.780687392 +0000 UTC m=+4404.455763810 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:52.345798    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:52.546284    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:53.04625691 +0000 UTC m=+4404.721333324 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:52.584841    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:53.084815019 +0000 UTC m=+4404.759891433 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:52.648243    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:52.946939    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:53.446901033 +0000 UTC m=+4405.121977446 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:52.985124    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:53.485095634 +0000 UTC m=+4405.160172037 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:53.053462    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:53.350439    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:53.850408514 +0000 UTC m=+4405.525484929 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:53.392052    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:53.892024443 +0000 UTC m=+4405.567100858 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:53.456186    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:53.765773    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:54.265747007 +0000 UTC m=+4405.940823410 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:53.901664    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:54.40163516 +0000 UTC m=+4406.076711577 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:53.962374    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:54.155780    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:54.655753327 +0000 UTC m=+4406.330829741 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:54.203894    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:54.703864894 +0000 UTC m=+4406.378941307 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:54.269087    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:54.553262    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:55.053229139 +0000 UTC m=+4406.728305543 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:54.610885    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:55.110848713 +0000 UTC m=+4406.785925137 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:54.673318    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:54.970624    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:55.470592394 +0000 UTC m=+4407.145668808 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:55.017324    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:55.517289973 +0000 UTC m=+4407.192366384 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:55.077169    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:55.349598    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:55.849569081 +0000 UTC m=+4407.524645494 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:55.423390    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:55.923359159 +0000 UTC m=+4407.598435572 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:55.481827    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:55.548335    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:55.756771    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:56.256736425 +0000 UTC m=+4407.931812848 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:55.833252    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:56.333215366 +0000 UTC m=+4408.008291789 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:55.886781    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:56.150897    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:56.650867807 +0000 UTC m=+4408.325944211 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:56.227648    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:56.727620354 +0000 UTC m=+4408.402696755 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:56.291125    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:56.433100    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^1128534796363700257 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:12.433068358 +0000 UTC m=+4424.108144781 (durationBeforeRetry 16s). Error: MountVolume.SetUp failed for volume "pvc-9c1df276-bdc1-4044-b78c-a2aaff3fd03a" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^1128534796363700257") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:56.600723    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:57.100698519 +0000 UTC m=+4408.775774923 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:56.739921    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:57.239892475 +0000 UTC m=+4408.914968889 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:56.800400    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:56.957202    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:57.457176403 +0000 UTC m=+4409.132252809 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:57.048400    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:57.548371972 +0000 UTC m=+4409.223448386 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:57.102382    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:57.357947    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:57.857913079 +0000 UTC m=+4409.532989488 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:57.443671    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:57.943642805 +0000 UTC m=+4409.618719211 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:57.506213    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:57.770885    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:58.270849422 +0000 UTC m=+4409.945925837 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:57.852243    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:58.352216246 +0000 UTC m=+4410.027292660 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:57.910692    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:58.149899    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:58.649870147 +0000 UTC m=+4410.324946552 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:58.250832    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:58.750806673 +0000 UTC m=+4410.425883087 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:58.314599    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:58.549309    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:59.049283478 +0000 UTC m=+4410.724359891 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:58.667065    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:59.16703506 +0000 UTC m=+4410.842111474 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:58.718453    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:58.953074    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:11:59.45303252 +0000 UTC m=+4411.128108935 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:59.060364    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:59.560306592 +0000 UTC m=+4411.235383084 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:59.122169    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:59.348244    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:11:59.848219232 +0000 UTC m=+4411.523295646 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:59.469620    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:11:59.969582991 +0000 UTC m=+4411.644659414 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:59.526160    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:59.752027    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:00.251992672 +0000 UTC m=+4411.927069087 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:11:59.863133    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:00.363106529 +0000 UTC m=+4412.038182942 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-prrhl" (UID: "0454503f-4399-46fc-ac26-7ada4ecaaa70") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:11:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:11:59.930008    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:00.169794    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:00.669770377 +0000 UTC m=+4412.344846780 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:00.272805    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:00.772778655 +0000 UTC m=+4412.447855073 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:00.333222    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:00.570294    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:01.07025781 +0000 UTC m=+4412.745334216 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:00.676271    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:01.176245575 +0000 UTC m=+4412.851321989 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:00.737248    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:00.951197    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:01.451170927 +0000 UTC m=+4413.126247341 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:01.082186    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:01.582153376 +0000 UTC m=+4413.257229799 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:01.141286    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:01.351246    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:01.851216279 +0000 UTC m=+4413.526292710 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:01.481173    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:01.981146847 +0000 UTC m=+4413.656223261 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:01.544128    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:01.776564    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:02.276531088 +0000 UTC m=+4413.951607511 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:01.891387    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:02.39135209 +0000 UTC m=+4414.066428507 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:01.947575    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:02.152355    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:02.652330725 +0000 UTC m=+4414.327407129 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:02.292733    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:02.792702621 +0000 UTC m=+4414.467779038 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:02.351631    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:02.551459    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:03.05143098 +0000 UTC m=+4414.726507394 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:02.590637    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:03.090601963 +0000 UTC m=+4414.765678380 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:02.654714    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:02.969088    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:03.46905426 +0000 UTC m=+4415.144130684 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:03.091435    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:03.591404048 +0000 UTC m=+4415.266480468 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:03.159186    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:03.354974    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:03.854948378 +0000 UTC m=+4415.530024793 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:03.405352    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:03.905320047 +0000 UTC m=+4415.580396448 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:03.462360    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:03.757486    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:59cab706-7552-4810-9998-5ab88a0d18b5 nodeName:}" failed. No retries permitted until 2022-09-05 15:12:04.257455492 +0000 UTC m=+4415.932531898 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:03.804531    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:04.304482702 +0000 UTC m=+4415.979559104 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:03.866800    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:04.160369    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:12:04.660341986 +0000 UTC m=+4416.335418400 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:04.224017    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:04.723988228 +0000 UTC m=+4416.399064643 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:04.270472    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:04.563109    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:12:05.063074463 +0000 UTC m=+4416.738150876 (durationBeforeRetry 500ms). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:04.612271    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName: nodeName:}" failed. No retries permitted until 2022-09-05 15:12:05.112244077 +0000 UTC m=+4416.787320491 (durationBeforeRetry 500ms). Error: MountVolume.SetUp failed for volume "pvc-0d81053d-6952-404d-b213-2adea82bc609" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "vdbench-sv4-svc-57678cbc89-25pgg" (UID: "5a21d20f-cacd-43fe-be3e-194c34c673cd") : rpc error: code = Internal desc = failed  to attach volume: rpc error: code = Unavailable desc = Resource has not been initialized
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:04.674317    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"59cab706-7552-4810-9998-5ab88a0d18b5\" (UID: \"59cab706-7552-4810-9998-5ab88a0d18b5\") "
Sep 05 15:12:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:04.674384    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:12:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:05.294985    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:12:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:05.948868    6839 nestedpendingoperations.go:335] Operation for "{volumeName:kubernetes.io/csi/pxd.portworx.com^920849628428829313 podName:da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b nodeName:}" failed. No retries permitted until 2022-09-05 15:12:37.948841598 +0000 UTC m=+4449.623918013 (durationBeforeRetry 32s). Error: UnmountVolume.TearDown failed for volume "vdbench-output-persistent-storage" (UniqueName: "kubernetes.io/csi/pxd.portworx.com^920849628428829313") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b") : kubernetes.io/csi: Unmounter.TearDownAt failed: rpc error: code = Internal desc = Mount path still exists: /var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes/kubernetes.io~csi/pvc-0d81053d-6952-404d-b213-2adea82bc609/mount
Sep 05 15:12:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:05.948922    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^920849628428829313" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "59cab706-7552-4810-9998-5ab88a0d18b5" (UID: "59cab706-7552-4810-9998-5ab88a0d18b5"). InnerVolumeSpecName "pvc-0d81053d-6952-404d-b213-2adea82bc609". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 15:12:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:12.391274    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:12:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:12.395587    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=59cab706-7552-4810-9998-5ab88a0d18b5 path="/var/lib/kubelet/pods/59cab706-7552-4810-9998-5ab88a0d18b5/volumes"
Sep 05 15:12:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:17.391151    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:12:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:20.149383    6839 reconciler.go:201] "operationExecutor.UnmountVolume started for volume \"vdbench-output-persistent-storage\" (UniqueName: \"kubernetes.io/csi/pxd.portworx.com^920849628428829313\") pod \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\" (UID: \"da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b\") "
Sep 05 15:12:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:21.103001    6839 operation_generator.go:863] UnmountVolume.TearDown succeeded for volume "kubernetes.io/csi/pxd.portworx.com^920849628428829313" (OuterVolumeSpecName: "vdbench-output-persistent-storage") pod "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" (UID: "da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b"). InnerVolumeSpecName "pvc-0d81053d-6952-404d-b213-2adea82bc609". PluginName "kubernetes.io/csi", VolumeGidValue ""
Sep 05 15:12:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:23.089986    6839 topology_manager.go:200] "Topology Admit Handler"
Sep 05 15:12:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:23.090078    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" containerName="vdbench"
Sep 05 15:12:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:12:23.090097    6839 cpu_manager.go:394] "RemoveStaleState: removing container" podUID="59cab706-7552-4810-9998-5ab88a0d18b5" containerName="vdbench"
Sep 05 15:12:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:23.090149    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="59cab706-7552-4810-9998-5ab88a0d18b5" containerName="vdbench"
Sep 05 15:12:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:23.090158    6839 memory_manager.go:345] "RemoveStaleState removing state" podUID="da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b" containerName="vdbench"
Sep 05 15:12:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:23.176719    6839 reconciler.go:342] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kube-api-access-z7hgk\" (UniqueName: \"kubernetes.io/projected/4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91-kube-api-access-z7hgk\") pod \"vdbench-sv4-svc-57678cbc89-z87mw\" (UID: \"4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91\") " pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:12:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:32.451455    6839 kubelet_volumes.go:160] "Cleaned up orphaned pod volumes dir" podUID=da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b path="/var/lib/kubelet/pods/da5715fd-1a6a-45ea-bbe5-5cd2dba0ce6b/volumes"
Sep 05 15:12:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:39.390703    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:12:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:12:42.392413    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:13:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:13:21.391600    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:13:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:13:23.392554    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:13:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:13:29.655068    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:13:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:13:29.655127    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:13:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:13:34.393966    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:13:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:13:50.395380    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:13:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:13:55.393045    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:14:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:14:26.113285    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:14:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:14:26.113358    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:14:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:14:35.404626    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:14:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:14:40.396292    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:14:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:14:45.391187    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:14:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:14:56.391169    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:14:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:14:57.392566    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:15:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:15:43.391762    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:15:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:15:43.391829    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:15:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:15:45.392089    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:16:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:16:00.391964    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:16:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:16:01.390990    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:16:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:16:09.394391    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:16:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:16:15.392286    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:16:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:16:39.392595    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:16:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:16:39.392641    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:16:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:16:52.392275    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:17:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:17:19.390796    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:17:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:17:22.392665    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:17:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:17:39.391939    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:17:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:17:40.391755    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:17:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:17:58.391911    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:17:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:17:58.391974    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:18:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:18:21.391300    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:18:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:18:30.393476    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:18:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:18:31.391002    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:18:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:18:53.398205    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:18:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:18:53.398253    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:19:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:19:00.392515    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:19:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:19:05.391585    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:19:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:19:24.391331    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:19:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:19:53.392131    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:19:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:19:54.433497    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:20:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:20:05.428433    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:20:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:20:12.391162    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:20:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:20:12.391203    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:20:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:20:21.391059    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:20:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:20:38.391751    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:20:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:20:58.392206    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:20:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:20:59.392098    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:21:10.391339    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:21:10.391735    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:21:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:21:10.391778    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:21:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:21:33.391037    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:21:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:21:46.391843    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:22:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:22:00.391599    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:22:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:22:22.392590    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:22:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:22:26.391729    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:22:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:22:29.392033    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:22:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:22:29.392129    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:22:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:22:36.391411    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:22:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:22:54.392956    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:23:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:23:21.391439    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:23:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:23:27.392172    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:23:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:23:27.392213    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:23:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:23:41.391199    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:23:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:23:51.391605    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:24:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:24:03.391025    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:24:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:24:11.391204    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:24:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:24:30.392045    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:24:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:24:46.391987    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:24:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:24:46.392027    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:24:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:24:54.396621    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:24:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:24:55.391363    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:25:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:25:20.392370    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:25:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:25:28.393414    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:25:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:25:41.395007    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:25:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:25:41.395051    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:25:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:25:56.391274    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:25:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:25:59.391154    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:26:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:26:01.390910    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:26:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:26:32.392103    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:26:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:26:35.394413    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:27:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:27:03.393963    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:27:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:27:03.394009    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:27:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:27:08.390887    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:27:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:27:14.393640    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:27:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:27:25.391760    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:27:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:27:50.391759    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:27:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:27:52.391906    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:27:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:27:56.392382    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:27:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:27:56.392422    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:28:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:28:14.395131    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:28:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:28:34.392410    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:28:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:28:42.391708    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:29:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:29:11.390904    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:29:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:29:16.391938    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:29:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:29:18.392893    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:29:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:29:20.391686    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:29:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:29:20.391737    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:30:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:30:01.391740    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:30:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:30:10.391680    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:30:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:30:10.391717    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:30:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:30:11.391092    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:30:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:30:37.393368    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:30:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:30:40.392730    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:30:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:30:41.391152    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:31:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:31:16.391024    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:31:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:31:16.391777    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:31:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:31:37.393970    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:31:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:31:37.394020    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:31:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:31:53.390830    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:32:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:32:03.390729    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:32:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:32:03.391163    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:32:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:32:22.392387    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:32:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:32:24.391793    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:32:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:32:24.391843    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:32:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:32:27.391709    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:33:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:33:19.391815    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:33:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:33:19.392633    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:33:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:33:23.390879    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:33:36.393941    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:33:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:33:41.390936    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:33:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:33:55.392554    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:33:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:33:55.392747    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:34:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:34:24.391172    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:34:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:34:41.394879    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:34:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:34:41.394923    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:34:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:34:44.392792    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:34:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:34:45.390878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:34:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:34:47.392128    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:35:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:35:07.391649    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:35:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:35:30.391873    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:35:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:35:50.392409    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:35:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:35:52.396528    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:36:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:36:09.391063    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:36:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:36:12.391470    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:36:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:36:12.391524    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:36:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:36:12.391697    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:36:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:36:48.392498    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:36:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:36:56.393943    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:36:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:36:56.393999    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:37:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:37:00.395136    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:37:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:37:17.391626    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:37:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:37:19.392468    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:37:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:37:31.392077    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:37:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:37:59.392078    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:38:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:38:17.393589    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:38:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:38:26.393947    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:38:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:38:26.393981    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:38:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:38:29.391818    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:38:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:38:36.391277    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:38:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:38:52.392788    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:39:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:39:13.395440    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:39:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:39:13.395480    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:39:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:39:27.390970    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:39:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:39:32.391537    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:39:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:39:46.393863    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:39:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:39:55.392975    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:40:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:40:01.398527    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:40:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:40:35.391519    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:40:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:40:40.395177    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:40:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:40:40.395213    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:40:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:40:57.391877    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:40:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:40:58.392044    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:41:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:41:03.392090    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:41:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:41:05.393970    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:41:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:41:29.392696    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:41:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:41:29.392746    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:41:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:41:46.391882    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:42:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:42:15.390682    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:42:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:42:16.432904    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:42:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:42:20.392368    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:42:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:42:20.392390    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:42:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:42:52.391112    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:42:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:42:54.395327    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:42:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:42:54.395361    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:43:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:43:22.391128    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:43:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:43:32.393092    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:43:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:43:34.394703    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:43:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:43:46.398670    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:43:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:43:46.398708    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:43:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:43:50.391085    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:44:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:44:11.400197    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:44:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:44:24.392322    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:44:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:44:53.392007    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:44:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:44:55.392128    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:44:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:44:56.391249    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:45:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:45:08.391999    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:45:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:45:08.392039    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:45:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:45:39.391232    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:45:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:45:49.391164    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:45:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:45:55.390965    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:46:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:46:03.415448    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:46:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:46:03.415504    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:46:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:46:14.391598    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:46:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:46:25.390915    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:46:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:46:51.391413    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:46:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:46:56.393241    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:47:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:47:11.391655    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:47:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:47:17.390984    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:47:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:47:25.391563    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:47:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:47:25.391612    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:47:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:47:32.391751    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:48:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:48:04.393072    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:48:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:48:21.392054    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:48:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:48:21.392248    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:48:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:48:21.392278    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:48:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:48:23.391180    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:48:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:48:43.390784    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:48:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:48:52.392201    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:49:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:49:22.406298    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:49:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:49:30.392050    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:49:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:49:40.394290    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:49:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:49:40.394325    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:49:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:49:41.390909    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:49:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:49:49.392410    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:50:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:50:07.391718    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:50:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:50:33.392127    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:50:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:50:37.394700    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:50:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:50:37.394743    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:50:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:50:43.391499    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:50:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:50:54.391903    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:51:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:51:09.390836    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:51:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:51:11.391328    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:51:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:51:50.395232    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:51:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:51:56.391726    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:51:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:51:56.391780    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:51:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:51:56.392425    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:52:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:52:13.392933    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:52:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:52:24.391746    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:52:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:52:31.392360    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:52:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:52:53.394631    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:52:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:52:53.394690    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:52:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:52:57.391929    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:53:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:53:07.391367    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:53:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:53:23.392961    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:53:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:53:25.395185    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:53:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:53:34.392678    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:54:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:54:13.390977    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:54:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:54:13.397755    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:54:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:54:13.397807    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:54:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:54:31.391018    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:54:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:54:31.391379    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:54:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:54:32.392128    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:54:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:54:53.391215    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:55:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:55:07.394772    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:55:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:55:07.394841    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:55:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:55:17.391710    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:55:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:55:36.405077    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:55:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:55:40.393406    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:55:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:55:54.391974    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:55:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:55:55.391415    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:56:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:56:29.394933    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:56:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:56:29.395975    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:56:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:56:44.392963    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:56:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:56:53.391152    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:56:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:56:56.394187    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:57:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:57:05.391292    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:57:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:57:17.391124    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:57:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:57:21.394847    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:57:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:57:21.394905    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:58:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:58:06.403251    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:58:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:58:07.390962    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:58:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:58:10.391868    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 15:58:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:58:13.391136    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:58:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:58:18.393910    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:58:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:58:46.392303    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 15:58:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:58:46.392515    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 15:59:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:59:09.392223    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 15:59:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:59:16.390939    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 15:59:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:59:31.390710    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 15:59:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:59:34.391482    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 15:59:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:59:35.393889    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 15:59:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 15:59:35.393944    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 15:59:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 15:59:40.397554    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:00:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:00:23.390935    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:00:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:00:28.391934    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:00:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:00:40.391865    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:00:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:00:49.390828    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:01:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:01:00.391813    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:01:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:01:03.392972    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:01:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:01:03.393033    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:01:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:01:33.391347    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:01:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:01:50.393132    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:01:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:01:50.393177    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:01:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:01:55.391653    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:02:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:02:09.390980    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:02:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:02:14.394296    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:02:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:02:16.395037    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:02:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:02:41.391810    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:03:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:03:02.394799    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:03:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:03:19.392913    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:03:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:03:19.392957    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:03:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:03:28.395270    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:03:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:03:34.396238    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:03:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:03:42.392216    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:04:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:04:08.392669    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:04:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:04:08.392784    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:04:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:04:10.392741    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:04:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:04:25.391642    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:04:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:04:35.390954    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:04:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:04:59.391254    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:05:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:05:09.391673    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:05:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:05:17.391115    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:05:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:05:35.391974    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:05:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:05:35.395826    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:05:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:05:35.395878    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:05:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:05:49.391672    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:06:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:06:12.391835    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:06:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:06:17.391398    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:06:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:06:21.391624    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:06:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:06:25.395717    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:06:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:06:25.395773    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:06:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:06:58.392202    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:07:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:07:00.391978    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:07:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:07:25.391559    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:07:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:07:37.391219    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:07:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:07:42.391432    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:07:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:07:50.404480    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:07:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:07:50.404542    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:08:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:08:01.391737    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:08:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:08:28.392417    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:08:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:08:29.391271    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:08:43.393765    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:08:43.393924    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:08:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:08:46.396950    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:08:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:08:56.392462    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:09:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:09:25.390900    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:09:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:09:35.391986    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:09:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:09:54.393195    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:09:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:09:56.393977    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:10:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:10:04.392048    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:10:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:10:05.393298    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:10:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:10:05.393344    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:10:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:10:37.391595    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:10:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:10:46.392148    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:11:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:11:00.392045    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:11:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:11:00.392109    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:11:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:11:16.391382    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:11:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:11:19.391462    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:11:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:11:21.390830    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:11:40.392140    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:12:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:12:13.391417    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:12:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:12:20.393473    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:12:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:12:22.394611    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:12:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:12:22.394669    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:12:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:12:35.391229    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:12:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:12:41.392598    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:12:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:12:49.391582    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:13:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:13:16.391762    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:13:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:13:16.391805    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:13:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:13:39.391026    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:13:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:13:45.391389    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:13:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:13:48.392607    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:13:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:13:52.393956    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:14:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:14:02.391925    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:14:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:14:37.392118    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:14:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:14:37.392161    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:14:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:14:48.391141    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:14:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:14:58.394175    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:15:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:15:06.392245    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:15:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:15:11.390876    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:15:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:15:26.394753    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:15:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:15:34.393660    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:15:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:15:34.393702    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:15:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:15:53.391976    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:16:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:16:09.391055    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:16:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:16:13.392420    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:16:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:16:21.390589    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:16:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:16:37.417287    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:16:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:16:54.391326    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:16:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:16:54.391384    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:17:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:17:12.395909    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:17:15.391500    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:17:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:17:18.391845    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:17:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:17:50.393061    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:17:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:17:50.393102    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:17:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:17:51.391597    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:18:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:18:05.391796    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:18:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:18:19.392068    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:18:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:18:25.396563    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:18:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:18:36.392329    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:19:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:19:11.397747    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:19:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:19:11.397802    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:19:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:19:13.391441    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:19:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:19:26.391909    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:19:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:19:37.391856    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:19:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:19:40.392981    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:19:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:19:47.393584    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:20:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:20:05.394101    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:20:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:20:05.394165    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:20:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:20:41.392230    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:20:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:20:50.396064    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:20:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:20:54.392377    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:20:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:20:55.391054    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:21:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:21:14.391674    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:21:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:21:29.393424    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:21:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:21:29.393476    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:21:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:21:53.391309    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:22:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:22:14.393060    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:22:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:22:15.390965    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:22:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:22:19.391973    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:22:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:22:19.392146    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:22:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:22:23.391151    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:22:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:22:41.390984    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:23:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:23:10.394075    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:23:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:23:25.390871    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:23:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:23:34.391678    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:23:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:23:44.391987    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:23:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:23:45.399675    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:23:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:23:45.399729    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:23:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:23:47.391663    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:24:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:24:13.391927    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:24:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:24:31.393257    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:24:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:24:34.392118    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:24:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:24:34.392176    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:24:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:24:39.391104    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:24:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:24:51.390964    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:24:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:24:51.391433    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:25:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:25:21.391042    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:25:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:25:39.391819    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:25:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:25:46.395460    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:25:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:25:54.393257    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:25:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:25:56.391176    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:25:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:25:59.392430    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:25:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:25:59.392483    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:26:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:26:32.391580    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:26:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:26:49.394728    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:26:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:26:49.394776    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:26:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:26:52.394389    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:27:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:27:02.392294    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:27:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:27:07.391253    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:27:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:27:08.392576    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:27:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:27:52.391553    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:27:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:27:58.391882    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:28:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:28:14.393453    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:28:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:28:17.394627    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:28:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:28:17.394669    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:28:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:28:29.390854    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:28:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:28:37.391273    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:29:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:29:02.393821    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:29:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:29:05.392410    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:29:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:29:05.392587    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:29:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:29:07.391936    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:29:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:29:40.392461    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:29:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:29:47.391858    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:29:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:29:50.391794    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:30:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:30:13.391275    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:30:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:30:21.392131    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:30:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:30:35.394526    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:30:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:30:35.394574    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:31:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:31:04.408732    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:31:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:31:04.409021    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:31:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:31:18.391778    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:31:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:31:19.391358    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:31:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:31:20.392526    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:31:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:31:20.392576    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:31:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:31:44.392157    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:32:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:32:19.399828    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:32:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:32:21.391078    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:32:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:32:21.391848    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:32:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:32:24.393405    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:32:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:32:49.393751    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:32:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:32:49.393809    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:33:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:33:01.391530    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:33:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:33:34.392140    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:33:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:33:34.392179    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:33:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:33:37.391760    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:33:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:33:41.391345    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:33:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:33:44.390964    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:33:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:33:49.391283    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:34:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:34:08.395218    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:34:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:34:55.391146    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:35:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:35:00.392362    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:35:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:35:03.391256    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:35:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:35:07.396528    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:35:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:35:07.396571    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:35:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:35:11.390782    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:35:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:35:35.395969    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:35:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:35:49.392535    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:35:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:35:49.392583    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:36:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:36:02.396472    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:36:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:36:15.390829    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:36:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:36:17.390701    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:36:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:36:23.390982    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:36:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:36:44.393036    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:37:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:37:17.394118    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:37:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:37:25.394351    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:37:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:37:25.394406    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:37:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:37:26.391478    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:37:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:37:26.391618    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:37:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:37:42.392520    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:38:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:38:02.393878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:38:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:38:07.392866    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:38:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:38:07.392924    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:38:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:38:37.391777    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:38:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:38:45.391721    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:38:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:38:48.391658    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:38:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:38:50.393981    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:39:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:39:30.392180    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:39:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:39:41.409713    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:39:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:39:41.409787    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:39:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:39:54.397361    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:39:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:39:55.390620    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:39:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:39:55.391301    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:40:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:40:11.390728    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:40:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:40:21.393747    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:40:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:40:21.393861    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:40:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:40:38.391335    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:41:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:41:06.391476    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:41:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:41:10.391903    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:41:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:41:16.396049    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:41:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:41:28.393834    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:41:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:41:58.394415    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:41:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:41:58.394483    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:42:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:42:07.391716    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:42:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:42:08.396964    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:42:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:42:17.444981    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:42:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:42:33.391012    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:42:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:42:37.392054    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:42:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:42:37.392095    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:42:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:42:52.391288    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:43:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:43:29.396556    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:43:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:43:33.391462    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:43:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:43:40.392132    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:43:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:43:40.392955    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:43:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:43:54.394469    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:44:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:44:12.393642    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:44:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:44:12.393695    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:44:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:44:36.394484    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:44:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:44:50.401704    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:44:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:44:51.391352    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:44:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:44:52.394105    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:44:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:44:52.394173    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:45:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:45:04.393284    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:45:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:45:08.401616    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:45:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:45:40.395985    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:45:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:45:52.391875    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:46:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:46:03.391268    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:46:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:46:24.391169    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:46:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:46:26.391453    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:46:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:46:26.391507    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:46:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:46:28.392270    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:47:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:47:01.392880    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:47:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:47:07.396760    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:47:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:47:07.396807    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:47:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:47:10.391988    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:47:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:47:17.393268    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:47:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:47:41.391031    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:47:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:47:54.391882    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:48:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:48:06.393475    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:48:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:48:36.390782    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:48:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:48:40.392601    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:48:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:48:44.396453    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:48:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:48:44.396508    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:48:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:48:46.395692    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:49:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:49:20.391577    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:49:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:49:25.391527    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:49:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:49:25.391566    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:49:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:49:35.425721    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:49:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:49:50.394903    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:49:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:49:58.396023    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:50:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:50:07.394971    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:50:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:50:43.391213    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:50:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:50:54.391583    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:50:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:50:59.392211    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:50:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:50:59.396630    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:50:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:50:59.396674    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:51:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:51:18.391348    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:51:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:51:20.395329    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:51:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:51:40.428853    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:51:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:51:40.428896    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:51:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:51:54.393826    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:52:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:52:05.390759    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:52:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:52:18.392389    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:52:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:52:38.420842    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:52:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:52:41.397604    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:53:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:53:00.395371    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:53:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:53:13.401621    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:53:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:53:13.401707    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:53:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:53:24.395498    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:53:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:53:33.392830    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:53:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:53:54.393334    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:53:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:53:54.393371    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:53:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:53:59.391316    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:54:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:54:09.396055    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:54:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:54:10.392409    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:54:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:54:31.391479    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:54:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:54:38.392550    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:55:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:55:07.391121    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:55:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:55:21.391866    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:55:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:55:28.395165    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:55:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:55:30.396651    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:55:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:55:30.396688    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:55:51.398464    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:56:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:56:02.390926    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:56:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:56:11.393383    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:56:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:56:11.393441    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:56:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:56:14.400883    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:56:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:56:27.391537    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:56:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:56:31.391583    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:57:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:57:07.391425    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:57:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:57:18.400931    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:57:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:57:25.391976    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:57:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:57:40.392005    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:57:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:57:48.394685    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 16:57:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:57:48.394723    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 16:57:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:57:58.391191    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:58:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:58:18.394033    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 16:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:58:29.399560    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 16:58:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 16:58:29.399605    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 16:58:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:58:41.398062    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 16:58:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:58:46.395062    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 16:58:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:58:47.392049    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 16:59:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:59:27.390834    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 16:59:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 16:59:43.392653    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:00:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:00:05.419868    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:00:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:00:05.419910    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:00:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:00:06.391281    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:00:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:00:07.392090    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:00:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:00:10.391480    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:00:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:00:43.398611    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:00:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:00:43.398686    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:00:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:00:48.394122    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:01:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:01:06.392528    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:01:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:01:21.391518    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:01:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:01:23.392211    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:01:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:01:37.393526    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:01:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:01:49.394990    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:02:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:02:13.398274    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:02:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:02:20.399420    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:02:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:02:20.399510    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:02:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:02:33.390931    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:02:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:02:44.398976    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:02:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:02:45.391529    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:02:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:02:58.391536    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:02:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:02:58.391590    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:03:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:03:02.390994    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:03:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:03:20.407557    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:03:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:03:48.391017    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:03:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:03:52.394199    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:03:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:03:57.391090    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:04:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:04:14.394933    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:04:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:04:21.391454    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:04:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:04:34.393522    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:04:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:04:34.393565    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:04:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:04:55.390634    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:04:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:04:57.393060    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:05:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:05:15.392336    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:05:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:05:15.392377    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:05:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:05:18.393938    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:05:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:05:42.393836    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:05:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:05:46.398097    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:06:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:06:01.392323    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:06:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:06:12.391301    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:06:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:06:37.390924    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:06:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:06:51.391385    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:06:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:06:52.396078    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:06:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:06:52.396150    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:07:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:07:11.391266    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:07:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:07:11.391878    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:07:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:07:31.391663    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:07:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:07:33.395354    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:07:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:07:33.395421    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:08:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:08:03.391199    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:08:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:08:13.392201    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:08:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:08:19.402253    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:08:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:08:37.391891    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:09:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:09:00.391920    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:09:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:09:10.403557    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:09:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:09:10.403640    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:09:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:09:20.391290    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:09:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:09:40.391764    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:09:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:09:43.391708    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:09:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:09:50.392071    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:09:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:09:50.392118    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:09:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:09:50.392637    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:10:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:10:18.391771    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:10:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:10:37.392272    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:11:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:11:06.416344    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:11:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:11:07.391243    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:11:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:11:20.391780    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:11:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:11:25.394271    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:11:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:11:25.394321    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:11:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:11:46.391907    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:11:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:11:51.392420    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:12:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:12:06.399741    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:12:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:12:06.399790    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:12:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:12:11.403683    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:12:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:12:12.391312    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:12:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:12:42.391412    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:13:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:13:16.392220    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:13:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:13:17.392331    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:13:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:13:32.391021    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:13:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:13:37.392061    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:13:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:13:39.392913    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:13:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:13:39.392990    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:13:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:13:59.390956    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:14:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:14:22.395127    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:14:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:14:22.395179    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:14:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:14:39.391260    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:14:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:14:44.393713    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:14:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:14:45.392937    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:14:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:14:46.392148    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:15:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:15:04.402220    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:15:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:15:43.391519    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:15:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:15:51.391294    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:15:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:15:54.397356    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:15:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:15:54.397428    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:16:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:16:00.393886    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:16:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:16:02.392020    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:16:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:16:34.406142    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:16:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:16:40.396520    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:16:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:16:40.396567    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:16:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:16:44.391633    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:17:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:17:03.391048    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:17:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:17:17.390766    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:17:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:17:29.397000    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:17:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:17:39.391881    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:17:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:17:58.392778    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:18:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:18:12.395201    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:18:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:18:12.395241    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:18:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:18:24.392481    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:18:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:18:24.392626    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:18:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:18:37.390789    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:18:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:18:48.391829    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:18:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:18:56.399690    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:18:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:18:56.399737    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:19:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:19:10.391377    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:19:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:19:41.394183    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:19:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:19:51.391435    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:19:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:19:53.397242    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:20:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:20:04.395752    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:20:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:20:25.391779    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:20:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:20:28.402678    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:20:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:20:28.402748    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:21:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:21:04.394273    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:21:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:21:07.392196    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:21:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:21:09.391782    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:21:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:21:11.394608    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:21:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:21:11.394649    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:21:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:21:27.391154    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:21:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:21:41.392062    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:22:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:22:24.391051    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:22:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:22:26.391746    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:22:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:22:27.398368    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:22:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:22:45.434775    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:22:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:22:45.434825    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:22:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:22:52.393088    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:23:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:23:09.390868    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:23:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:23:26.392640    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:23:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:23:26.392688    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:23:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:23:29.396477    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:23:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:23:30.391606    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:23:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:23:38.394874    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:24:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:24:06.392833    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:24:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:24:30.391068    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:24:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:24:36.390923    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:24:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:24:42.391478    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:24:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:24:49.391138    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:25:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:25:01.394600    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:25:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:25:01.394800    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:25:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:25:11.391192    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:25:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:25:42.391687    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:25:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:25:43.394671    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:25:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:25:43.394724    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:25:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:25:53.391788    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:26:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:26:06.390932    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:26:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:26:06.391918    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:26:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:26:14.394017    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:27:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:27:07.391250    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:27:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:27:09.390710    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:27:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:27:15.394869    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:27:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:27:17.392193    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:27:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:27:17.392263    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:27:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:27:21.393695    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:27:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:27:31.396138    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:27:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:27:57.395033    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:27:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:27:57.395074    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:28:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:28:11.390821    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:28:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:28:30.392055    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:28:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:28:36.392973    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:28:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:28:38.393847    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:28:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:28:50.399441    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:29:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:29:21.392411    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:29:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:29:31.392126    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:29:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:29:31.392170    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:29:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:29:49.391624    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:29:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:29:52.392168    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:29:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:29:57.396583    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:30:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:30:09.391701    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:30:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:30:12.396856    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:30:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:30:12.396911    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:30:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:30:26.396764    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:30:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:30:51.423838    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:31:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:31:01.390691    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:31:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:31:04.393855    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:31:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:31:22.393684    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:31:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:31:30.396686    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:31:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:31:48.390981    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:31:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:31:48.391026    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:32:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:32:00.393596    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:32:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:32:21.394515    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:32:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:32:29.398351    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:32:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:32:29.398399    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:32:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:32:30.393852    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:32:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:32:34.398993    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:32:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:32:39.391563    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:33:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:33:09.391144    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:33:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:33:33.397683    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:33:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:33:38.395960    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:34:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:34:00.391032    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:34:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:34:03.391934    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:34:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:34:03.391977    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:34:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:34:04.394002    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:34:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:34:18.392968    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:34:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:34:45.399813    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:34:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:34:45.399860    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:34:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:34:54.395019    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:34:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:34:58.393999    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:35:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:35:13.391413    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:35:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:35:19.391592    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:35:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:35:28.391284    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:36:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:36:07.391101    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:36:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:36:19.390711    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:36:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:36:20.391632    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:36:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:36:20.391672    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:36:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:36:23.390978    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:36:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:36:28.391098    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:36:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:36:35.390902    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:37:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:37:02.391782    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:37:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:37:02.391826    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:37:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:37:33.391444    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:37:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:37:37.392117    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:37:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:37:40.392072    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:37:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:37:42.392421    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:37:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:37:46.396614    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:38:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:38:34.403383    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:38:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:38:34.403424    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:38:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:38:39.391416    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:38:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:38:50.394459    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:38:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:38:54.392305    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:39:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:39:03.390953    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:39:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:39:07.395996    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:39:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:39:18.394401    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:39:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:39:18.394603    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:39:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:39:59.399179    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:40:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:40:02.391998    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:40:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:40:06.425584    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:40:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:40:12.395132    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:40:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:40:25.391095    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:40:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:40:51.402995    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:40:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:40:51.403039    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:41:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:41:15.399520    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:41:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:41:21.391478    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:41:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:41:22.392497    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:41:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:41:25.390936    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:41:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:41:36.396469    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:41:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:41:36.396520    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:41:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:41:44.391732    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:42:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:42:19.390888    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:42:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:42:27.391267    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:42:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:42:31.395165    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:42:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:42:42.398255    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:42:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:42:47.396585    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:43:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:43:06.391984    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:43:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:43:06.392081    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:43:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:43:36.391602    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:43:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:43:39.390764    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:43:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:43:51.392321    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:43:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:43:51.392361    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:43:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:43:56.391917    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:44:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:44:02.391851    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:44:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:44:05.394639    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:44:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:44:55.391547    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:44:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:44:57.391807    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:45:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:45:03.391785    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:45:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:45:21.391798    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:45:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:45:22.413953    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:45:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:45:23.391116    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:45:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:45:23.391156    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:46:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:46:01.392011    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:46:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:46:05.394744    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:46:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:46:05.394830    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:46:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:46:09.392481    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:46:10 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:46:10.391907    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:46:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:46:26.399453    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:46:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:46:31.390681    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:47:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:47:22.390961    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:47:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:47:32.397937    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:47:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:47:35.391146    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:47:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:47:39.392165    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:47:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:47:39.392604    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:47:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:47:39.392934    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:47:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:47:47.412670    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:48:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:48:22.392230    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:48:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:48:22.392294    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:48:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:48:36.392187    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:48:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:48:47.391500    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:48:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:48:53.391082    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:48:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:48:54.391898    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:49:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:49:05.390968    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:49:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:49:57.392150    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:49:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:49:57.392211    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:49:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:49:58.392918    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:50:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:50:00.394545    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:50:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:50:04.395890    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:50:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:50:15.397527    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:50:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:50:35.395680    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:50:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:50:40.393697    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:50:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:50:40.393738    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:51:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:51:05.391051    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:51:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:51:16.395066    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:51:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:51:19.391879    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:51:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:51:26.390758    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:51:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:51:53.391205    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:52:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:52:07.395377    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:52:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:52:13.397810    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:52:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:52:13.398043    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:52:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:52:17.391171    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:52:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:52:43.398420    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:52:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:52:45.391533    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:52:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:52:54.404926    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:52:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:52:54.404968    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:52:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:52:59.391314    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:53:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:53:25.394743    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:53:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:53:39.391137    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:54:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:54:01.391309    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:54:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:54:11.391710    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:54:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:54:25.392720    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:54:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:54:27.392878    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:54:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:54:27.392924    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:54:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:54:36.394227    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:55:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:55:09.390663    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:55:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:55:12.391879    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:55:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:55:12.391920    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:55:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:55:29.391461    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:55:37 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:55:37.393843    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:55:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:55:51.390953    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:55:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:55:57.390903    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:56:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:56:31.390650    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:56:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:56:42.391649    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:56:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:56:42.391693    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:56:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:56:43.392142    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:57:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:57:05.390934    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:57:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:57:08.394363    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:57:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:57:21.393592    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:57:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:57:27.392404    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:57:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:57:27.392447    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:57:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:57:36.392026    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:58:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:58:04.391574    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:58:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:58:12.395381    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:58:23 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:58:23.390740    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:58:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:58:42.394806    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 17:58:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:58:51.390916    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 17:58:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:58:57.399780    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 17:58:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:58:57.399835    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 17:59:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:59:29.391032    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 17:59:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:59:33.399146    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 17:59:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:59:44.392818    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 17:59:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 17:59:44.393105    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 17:59:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:59:49.397446    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 17:59:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 17:59:58.397394    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:00:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:00:17.391059    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:00:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:00:46.391458    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:00:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:00:59.390699    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:01:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:01:13.391623    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:01:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:01:14.397418    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:01:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:01:14.397565    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:01:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:01:16.398092    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:01:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:01:21.391347    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:01:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:01:51.397899    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:02:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:02:02.391885    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:02:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:02:02.391924    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:02:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:02:02.392707    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:02:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:02:18.393726    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:02:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:02:33.398870    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:02:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:02:44.393733    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:03:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:03:04.400572    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:03:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:03:14.399784    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:03:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:03:31.394629    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:03:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:03:31.394676    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:03:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:03:34.399126    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:03:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:03:40.396199    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:04:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:04:00.399324    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:04:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:04:16.399770    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:04:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:04:16.399818    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:04:21 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:04:21.391059    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:04:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:04:34.391039    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:04:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:04:44.395829    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:04:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:04:47.391697    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:05:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:05:22.394620    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:05:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:05:30.395251    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:05:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:05:46.404692    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:05:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:05:46.404757    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:05:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:05:53.390749    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:05:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:05:56.394710    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:06:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:06:12.392016    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:06:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:06:31.392434    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:06:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:06:31.392691    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:06:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:06:35.391141    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:06:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:06:47.391240    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:06:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:06:57.335443    6839 scope.go:110] "RemoveContainer" containerID="84c7ef7bcd8189d86156729622441d51a0fb45122f0877c028576830ee44aec1"
Sep 05 18:06:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:06:58.338958    6839 scope.go:110] "RemoveContainer" containerID="71ef94f06f63d38ccec2883cf12b52448e63e4e9a2f447cf0419cf3ff41bdff7"
Sep 05 18:07:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:07:08.393389    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:07:16 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:07:16.399030    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:07:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:07:22.401255    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:07:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:07:52.395346    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:08:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:08:02.396416    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:08:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:08:02.396474    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:08:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:08:05.395208    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:08:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:08:34.397929    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:08:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:08:36.391621    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:08:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:08:43.391960    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:08:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:08:45.397738    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:08:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:08:45.397805    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:09:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:09:11.397224    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:09:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:09:27.392038    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:09:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:09:53.390818    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:10:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:10:05.397841    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:10:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:10:13.391837    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:10:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:10:17.394652    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:10:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:10:17.394701    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:10:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:10:24.396080    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:10:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:10:44.394015    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:10:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:10:59.394665    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:10:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:10:59.395054    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:11:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:11:13.397069    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:11:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:11:18.396806    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:11:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:11:30.399522    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:11:40 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:11:40.396236    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:11:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:11:58.400229    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:12:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:12:18.391975    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:12:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:12:31.398748    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:12:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:12:31.398805    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:12:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:12:34.393179    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:12:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:12:39.397228    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:12:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:12:44.429745    6839 scope.go:110] "RemoveContainer" containerID="e6836232aef94a60155046106c5389d78d0399c95d7cd357b90e1aa9b04c00aa"
Sep 05 18:12:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:12:48.391942    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:13:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:13:12.395998    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:13:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:13:13.399052    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:13:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:13:13.399137    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:13:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:13:20.391710    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:13:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:13:45.391780    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:13:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:13:49.391175    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:14:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:14:13.391258    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:14:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:14:19.391656    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:14:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:14:47.392548    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:14:47 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:14:47.392667    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-lw95l vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:14:48 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:14:48.391561    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:14:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:14:49.391443    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:15:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:15:19.391622    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:15:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:15:24.392616    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:15:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:15:29.392938    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:15:29 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:15:29.393001    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:15:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:15:35.391188    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:16:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:16:07.391594    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:16:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:16:08.396246    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:16:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:16:32.391853    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:16:43 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:16:43.391828    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:16:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:16:59.392144    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:17:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:17:02.391745    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:17:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:17:02.391791    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:17:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:17:15.391623    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:17:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:17:27.394027    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:17:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:17:44.391849    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:17:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:17:45.393017    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:17:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:17:45.393226    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:17:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:17:56.396772    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:18:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:18:24.394589    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:18:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:18:44.391968    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:18:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:18:49.391866    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:19:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:19:13.391110    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:19:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:19:17.392121    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:19:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:19:20.400379    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:19:20 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:19:20.400439    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:19:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:19:41.391677    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:19:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:19:50.391965    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:20:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:20:02.392373    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:20:02 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:20:02.392417    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:20:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:20:05.392058    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:20:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:20:15.391680    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:20:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:20:36.391758    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:20:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:20:45.391601    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:21:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:21:18.391501    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:21:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:21:22.392230    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:21:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:21:31.391785    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:21:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:21:36.393220    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:21:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:21:36.393273    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:22:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:22:03.392699    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:22:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:22:06.392566    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:22:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:22:19.396386    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:22:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:22:19.396467    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:22:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:22:27.391737    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:22:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:22:28.391726    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:22:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:22:51.393585    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:23:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:23:17.390780    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:23:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:23:35.391920    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:23:35 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:23:35.391947    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:23:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:23:39.391221    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:23:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:23:52.392855    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:23:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:23:52.392927    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:23:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:23:57.393577    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:24:27 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:24:27.391775    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:24:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:24:33.394453    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:24:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:24:33.394515    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-output-persistent-storage kube-api-access-z7hgk vdbench-persistent-storage-enc]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:24:52 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:24:52.391962    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:24:53 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:24:53.392684    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:25:05 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:25:05.392630    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:25:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:25:11.446050    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:25:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:25:51.392209    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:26:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:26:07.392316    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:26:07 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:26:07.392385    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:26:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:26:13.392127    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:26:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:26:14.407815    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:26:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:26:22.393762    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:26:30 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:26:30.391785    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:26:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:26:50.391776    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:26:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:26:50.391843    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:27:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:27:12.391278    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:27:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:27:17.391213    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:27:28 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:27:28.399526    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:27:34 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:27:34.394077    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:27:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:27:36.397784    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:28:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:28:25.398625    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:28:25 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:28:25.398680    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-lw95l vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:28:38 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:28:38.391585    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:28:41 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:28:41.391846    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:28:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:28:45.391312    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:28:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:28:46.392151    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:28:55 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:28:55.391826    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:29:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:29:04.395612    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:29:04 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:29:04.395662    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:29:44 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:29:44.399349    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:29:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:29:54.393116    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:29:58 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:29:58.394034    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:30:12 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:30:12.393901    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:30:14 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:30:14.417839    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:30:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:30:42.392884    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:30:42 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:30:42.392941    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:30:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:30:54.391858    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:30:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:30:56.391607    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:31:13 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:31:13.391952    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:31:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:31:17.391707    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:31:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:31:19.393919    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:31:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:31:19.394001    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[kube-api-access-z7hgk vdbench-persistent-storage-enc vdbench-output-persistent-storage]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:31:24 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:31:24.391882    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:32:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:32:08.394078    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:32:08 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:32:08.394294    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:32:31 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:32:31.391161    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:32:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:32:36.394250    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:32:46 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:32:46.392066    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:33:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:33:00.392170    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:33:00 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:33:00.392224    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:33:17 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:33:17.392177    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:33:19 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:33:19.392073    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:33:36.392772    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:33:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:33:36.392824    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:33:50 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:33:50.392233    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:33:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:33:54.394633    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:33:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:33:57.391840    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:34:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:34:22.391888    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:34:22 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:34:22.392317    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:35:01 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:35:01.391742    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:35:15 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:35:15.393225    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:35:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:35:18.392752    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:35:18 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:35:18.392833    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:35:26 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:35:26.391056    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:35:39 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:35:39.393473    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:35:49 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:35:49.391263    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:35:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:35:54.392110    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:35:54 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:35:54.392156    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
Sep 05 18:36:06 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:36:06.391104    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:36:36 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:36:36.392174    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:36:51 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:36:51.391617    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:36:56 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:36:56.391936    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:36:59 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:36:59.391269    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:37:32 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:37:32.392221    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-telemetry-phonehome-l7wws" secret="" err="secret \"regcred\" not found"
Sep 05 18:37:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:37:33.392602    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl"
Sep 05 18:37:33 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:37:33.392974    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-lw95l]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-prrhl" podUID=0454503f-4399-46fc-ac26-7ada4ecaaa70
Sep 05 18:37:45 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:37:45.391949    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/tp-nextpx-k3s-op-spddry-22-09-05-14-02-26-px-int-69jff" secret="" err="secret \"regcred\" not found"
Sep 05 18:37:57 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:37:57.391952    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/stork-7ff877c64-4ddf8" secret="" err="secret \"regcred\" not found"
Sep 05 18:38:03 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:38:03.391649    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/px-csi-ext-55db7dcbc4-n4mnh" secret="" err="secret \"regcred\" not found"
Sep 05 18:38:09 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: I0905 18:38:09.391034    6839 kubelet_pods.go:888] "Unable to retrieve pull secret, the image pull may not succeed." pod="kube-system/portworx-api-lqjz4" secret="" err="secret \"regcred\" not found"
Sep 05 18:38:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:38:11.395479    6839 kubelet.go:1709] "Unable to attach or mount volumes for pod; skipping pod" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw"
Sep 05 18:38:11 ip-10-13-112-170.pwx.dev.purestorage.com k3s[6839]: E0905 18:38:11.395766    6839 pod_workers.go:951] "Error syncing pod, skipping" err="unmounted volumes=[vdbench-output-persistent-storage], unattached volumes=[vdbench-persistent-storage-enc vdbench-output-persistent-storage kube-api-access-z7hgk]: timed out waiting for the condition" pod="vdbench-sv4-svc-voldrivercrash-0-09-05-14h07m47s/vdbench-sv4-svc-57678cbc89-z87mw" podUID=4b8d2ad3-3fe4-47c2-b3a1-ddd0cda70e91
