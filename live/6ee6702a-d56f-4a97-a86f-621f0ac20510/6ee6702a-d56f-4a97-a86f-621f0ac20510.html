<!DOCTYPE html>
    <html>
    <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.css">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script src="https://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.js"></script>
        <style>
      .container {
        display: flex;
        align-items: right;
        justify-content: right
      }
      img {
        max-width: 100%
      }
      .image {
        flex-basis: 70%;
        order: 1;
      }
      .text {
        color: #89CFF0;
        padding-right: 20px;
        font: italic 30px "Fira Sans", serif;
      }
    </style>

    </head>
    <body>



    <div data-role="page" id="pageone">
    <div class="container">
      <div class="text">
        <h1>Hawk-Eye</h1>
      </div>
      <div class="image">
        <img src="logo.jpeg">
      </div>
    </div>
    <div data-role="header">
        <h1>Information</h1>
      </div>

      <div data-role="main" class="ui-content">    <div data-role="collapsible">
      <h1>Cluster</h1><div data-role="collapsible">
        <h1>pxctl status</h1>
        <pre>Status: [32mPX is operational[0m
Telemetry: [33mDisabled or Unhealthy[0m
Metering: [32mHealthy[0m
License: [91mPX-Essential (ERROR: License is expired, Another cluster registered with the same userID. Unlink the previously registered cluster on PX-Central.)[0m
Node ID: 9a6378b7-7caf-474d-81bc-14c8ef4eb51f
	IP: 192.168.51.87 
 	Local Storage Pool: 1 pool
[0m	POOL	IO_PRIORITY	RAID_LEVEL	USABLE	USED	STATUS	ZONE		REGION[0m
[32m	0	HIGH		raid0		150 GiB	7.5 GiB	Online	us-east-1b	us-east-1[0m
[0m	Local Storage Devices: 1 device[0m
[0m	Device	Path		Media Type		Size		Last-Scan[0m
[32m	0:1	/dev/nvme1n1	STORAGE_MEDIUM_NVME	150 GiB		28 Sep 22 05:13 UTC[0m
[32m	total			-			150 GiB[0m
[0m	Cache Devices:[0m
[0m	 * No cache devices[0m
[0m	Kvdb Device:[0m
[0m	Device Path	Size[0m
[32m	/dev/nvme2n1	150 GiB[0m
[0m	 * Internal kvdb on this node is using this dedicated kvdb device to store its data.[0m
[0mCluster Summary[0m
[0m	Cluster ID: px-cluster-63b62bdd-3485-435b-9ab8-8e715a65c465[0m
[0m	Cluster UUID: 20fc20be-77c9-4c14-bed8-892ee7974469[0m
[0m	Scheduler: kubernetes[0m
[0m	Nodes: 5 node(s) with storage (5 online)[0m
[0m	IP		ID					SchedulerNodeName		Auth		StorageNode	Used	Capacity	Status	StorageStatus	Version		Kernel				OS[0m
[32m	192.168.82.121	ed89eb5f-1b91-43cf-a171-c906a40a799b	ip-192-168-82-121.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.51.87	9a6378b7-7caf-474d-81bc-14c8ef4eb51f	ip-192-168-51-87.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up (This node)	2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.20.4	386dd1b8-9064-48c4-adf8-edf61b8ca15c	ip-192-168-20-4.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.91.7	2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	ip-192-168-91-7.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.18.191	17f392d7-342a-48fb-850f-06a8b7515ed0	ip-192-168-18-191.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[0mGlobal Storage Pool
	Total Used    	:  38 GiB
	Total Capacity	:  750 GiB
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl cd list-drives</h1>
        <pre>Error: Subcommand is missing or invalid. This command requires a valid sub-command.
Usage:
  pxctl clouddrive [flags]
  pxctl clouddrive [command]

Aliases:
  clouddrive, cd

Available Commands:
  inspect       Inspect and view all the drives of a DriveSet
  list          List all the cloud drives currently being used
  list-drives   List all the cloud drives currently being used
  transfer      Transfers the cloud drive set from given source node to a destination node
  update-labels Updates the labels on the drive set for the provided node.

Flags:
  -h, --help   help for clouddrive

Global Flags:
      --ca string            path to root certificate for ssl usage
      --cert string          path to client certificate for ssl usage
      --color                output with color coding
      --config string        config file (default is $HOME/.pxctl.yaml)
      --context string       context name that overrides the current auth context
  -j, --json                 output in json
      --key string           path to client key for ssl usage
      --output-type string   use "wide" to show more details
      --raw                  raw CLI output for instrumentation
      --ssl                  ssl enabled for portworx

Use "pxctl clouddrive [command] --help" for more information about a command.

</pre>
      </div><div data-role="collapsible">
        <h1>pxctl alerts show</h1>
        <pre>[4;1mType	ID			Resource				Severity	Count	LastSeen			FirstSeen			Description																								
[0m[31mNODE	NodeStateChange		17f392d7-342a-48fb-850f-06a8b7515ed0	ALARM		1	Sep 28 05:13:07 UTC 2022	Sep 28 05:13:07 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		9a6378b7-7caf-474d-81bc-14c8ef4eb51f	ALARM		1	Sep 28 05:13:21 UTC 2022	Sep 28 05:13:21 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		386dd1b8-9064-48c4-adf8-edf61b8ca15c	ALARM		1	Sep 28 05:13:23 UTC 2022	Sep 28 05:13:23 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		ed89eb5f-1b91-43cf-a171-c906a40a799b	ALARM		1	Sep 28 05:13:24 UTC 2022	Sep 28 05:13:24 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	ALARM		1	Sep 28 05:13:26 UTC 2022	Sep 28 05:13:26 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[32mNODE	NodeStartSuccess	17f392d7-342a-48fb-850f-06a8b7515ed0	NOTIFY		1	Sep 28 05:13:30 UTC 2022	Sep 28 05:13:30 UTC 2022	PX is ready on this node																						
[0m[31mNODE	ClusterManagerFailure	c9ae5b5a-fa3f-43ea-884f-9aae4d04dee7	ALARM		1	Sep 28 05:13:31 UTC 2022	Sep 28 05:13:31 UTC 2022	Failed to start cluster manager on node [192.168.51.111]: Unable to add a NEW node as cluster is operating at maximum capacity (5 nodes). Please remove a node before attempting to add a new node.	
[0m[32mNODE	NodeStartSuccess	9a6378b7-7caf-474d-81bc-14c8ef4eb51f	NOTIFY		1	Sep 28 05:13:57 UTC 2022	Sep 28 05:13:57 UTC 2022	PX is ready on this node																						
[0m[32mNODE	NodeStartSuccess	386dd1b8-9064-48c4-adf8-edf61b8ca15c	NOTIFY		1	Sep 28 05:14:03 UTC 2022	Sep 28 05:14:03 UTC 2022	PX is ready on this node																						
[0m[32mNODE	NodeStartSuccess	ed89eb5f-1b91-43cf-a171-c906a40a799b	NOTIFY		1	Sep 28 05:14:27 UTC 2022	Sep 28 05:14:27 UTC 2022	PX is ready on this node																						
[0m[32mNODE	NodeStartSuccess	2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	NOTIFY		1	Sep 28 05:14:34 UTC 2022	Sep 28 05:14:34 UTC 2022	PX is ready on this node																						
[0m[33mCLUSTER	MeteringAgentWarning						WARN		1	Sep 28 06:13:45 UTC 2022	Sep 28 06:13:45 UTC 2022	Unable to reach to billing server: Cannot send metric to the billing endpoint: Cannot send metric to the billing endpoint: Response Code: 500, error in sending metering information, Err: {"message":"cannot register usage, Err: cannot register new cluster, all available essentials licenses exhausted for user 74b6a08c-e439-11eb-8b5b-4ef4c7a81109","code":500}
	
[0m[31mCLUSTER	MeteringAgentCritical		ALARM	2	Sep 28 07:14:01 UTC 2022	Sep 28 05:13:28 UTC 2022	Unable to reach to billing server: Cannot send metric to the billing endpoint: Cannot send metric to the billing endpoint: Response Code: 500, error in sending metering information, Err: {"message":"cannot register usage, Err: cannot register new cluster, all available essentials licenses exhausted for user 74b6a08c-e439-11eb-8b5b-4ef4c7a81109","code":500}
	
[0m</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv kvdb members</h1>
        <pre>Kvdb Cluster Members: 
[4;1mID					PEER URLs				CLIENT URLs			LEADER	HEALTHY	DBSIZE[0m
[37m9a6378b7-7caf-474d-81bc-14c8ef4eb51f	[http://portworx-2.internal.kvdb:9018]	[http://192.168.51.87:9019]	false	true	520 KiB[0m
[37med89eb5f-1b91-43cf-a171-c906a40a799b	[http://portworx-3.internal.kvdb:9018]	[http://192.168.82.121:9019]	false	true	524 KiB[0m
[37m17f392d7-342a-48fb-850f-06a8b7515ed0	[http://portworx-1.internal.kvdb:9018]	[http://192.168.18.191:9019]	true	true	532 KiB[0m

</pre>
      </div><div data-role="collapsible">
        <h1>pxctl volume list</h1>
        <pre>ID	NAME	SIZE	HA	SHARED	ENCRYPTED	PROXY-VOLUME	IO_PRIORITY	STATUS	SNAP-ENABLED	
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-18-191.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>blkid: invalid option -- 'f'
Try 'blkid -h' for more information.
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  8064eb26-52ea-43a9-9c1c-a024256c4abf 
	IO Priority:  HIGH 
	Labels:  eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,beta.kubernetes.io/os=linux,kubernetes.io/hostname=ip-192-168-18-191.ec2.internal,failure-domain.beta.kubernetes.io/zone=us-east-1a,topology.portworx.io/zone=us-east-1a,eks.amazonaws.com/sourceLaunchTemplateVersion=1,alpha.eksctl.io/nodegroup-name=storage-nodes,kubernetes.io/os=linux,topology.kubernetes.io/region=us-east-1,beta.kubernetes.io/arch=amd64,medium=STORAGE_MEDIUM_NVME,failure-domain.beta.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1a,beta.kubernetes.io/instance-type=t3.xlarge,node.kubernetes.io/instance-type=t3.xlarge,alpha.eksctl.io/cluster-name=nrevanna-cluster3,topology.portworx.io/region=us-east-1,role=worker,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,eks.amazonaws.com/nodegroup=storage-nodes,iopriority=HIGH,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,kubernetes.io/arch=amd64 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-18-191.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0   80G  0 disk 
|-nvme0n1p1   259:1    0   80G  0 part /
`-nvme0n1p128 259:2    0    1M  0 part 
nvme1n1       259:3    0  150G  0 disk 
nvme2n1       259:4    0  150G  0 disk 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-82-121.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>blkid: invalid option -- 'f'
Try 'blkid -h' for more information.
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  5f54add0-2f46-4d3c-9c70-eadb57f42041 
	IO Priority:  HIGH 
	Labels:  kubernetes.io/os=linux,kubernetes.io/arch=amd64,eks.amazonaws.com/sourceLaunchTemplateVersion=1,alpha.eksctl.io/cluster-name=nrevanna-cluster3,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,medium=STORAGE_MEDIUM_NVME,role=worker,eks.amazonaws.com/capacityType=ON_DEMAND,beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t3.xlarge,topology.portworx.io/region=us-east-1,alpha.eksctl.io/nodegroup-name=storage-nodes,iopriority=HIGH,topology.kubernetes.io/region=us-east-1,node.kubernetes.io/instance-type=t3.xlarge,topology.portworx.io/zone=us-east-1c,failure-domain.beta.kubernetes.io/zone=us-east-1c,failure-domain.beta.kubernetes.io/region=us-east-1,eks.amazonaws.com/nodegroup=storage-nodes,kubernetes.io/hostname=ip-192-168-82-121.ec2.internal,beta.kubernetes.io/os=linux,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,topology.kubernetes.io/zone=us-east-1c 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-82-121.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0   80G  0 disk 
|-nvme0n1p1   259:1    0   80G  0 part /
`-nvme0n1p128 259:2    0    1M  0 part 
nvme1n1       259:3    0  150G  0 disk 
nvme2n1       259:4    0  150G  0 disk 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-51-87.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>blkid: invalid option -- 'f'
Try 'blkid -h' for more information.
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  e8e80e6e-3861-44bf-97c3-590016091c5b 
	IO Priority:  HIGH 
	Labels:  kubernetes.io/os=linux,kubernetes.io/arch=amd64,topology.kubernetes.io/zone=us-east-1b,role=worker,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,topology.portworx.io/zone=us-east-1b,beta.kubernetes.io/os=linux,medium=STORAGE_MEDIUM_NVME,kubernetes.io/hostname=ip-192-168-51-87.ec2.internal,failure-domain.beta.kubernetes.io/region=us-east-1,iopriority=HIGH,eks.amazonaws.com/nodegroup=storage-nodes,topology.kubernetes.io/region=us-east-1,eks.amazonaws.com/capacityType=ON_DEMAND,node.kubernetes.io/instance-type=t3.xlarge,beta.kubernetes.io/instance-type=t3.xlarge,eks.amazonaws.com/sourceLaunchTemplateVersion=1,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,failure-domain.beta.kubernetes.io/zone=us-east-1b,alpha.eksctl.io/cluster-name=nrevanna-cluster3,alpha.eksctl.io/nodegroup-name=storage-nodes,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,beta.kubernetes.io/arch=amd64,topology.portworx.io/region=us-east-1 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-51-87.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0   80G  0 disk 
|-nvme0n1p1   259:1    0   80G  0 part /
`-nvme0n1p128 259:2    0    1M  0 part 
nvme1n1       259:3    0  150G  0 disk 
nvme2n1       259:4    0  150G  0 disk 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-20-4.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>blkid: invalid option -- 'f'
Try 'blkid -h' for more information.
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  f7742d86-8684-4ef7-83da-3e1b2e4c9cd3 
	IO Priority:  HIGH 
	Labels:  eks.amazonaws.com/nodegroup=storage-nodes,beta.kubernetes.io/arch=amd64,kubernetes.io/arch=amd64,alpha.eksctl.io/cluster-name=nrevanna-cluster3,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,topology.portworx.io/region=us-east-1,iopriority=HIGH,topology.kubernetes.io/zone=us-east-1a,failure-domain.beta.kubernetes.io/zone=us-east-1a,node.kubernetes.io/instance-type=t3.xlarge,failure-domain.beta.kubernetes.io/region=us-east-1,eks.amazonaws.com/sourceLaunchTemplateVersion=1,beta.kubernetes.io/os=linux,beta.kubernetes.io/instance-type=t3.xlarge,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,kubernetes.io/os=linux,alpha.eksctl.io/nodegroup-name=storage-nodes,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,topology.portworx.io/zone=us-east-1a,role=worker,medium=STORAGE_MEDIUM_NVME,kubernetes.io/hostname=ip-192-168-20-4.ec2.internal,topology.kubernetes.io/region=us-east-1 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-20-4.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0   80G  0 disk 
|-nvme0n1p1   259:1    0   80G  0 part /
`-nvme0n1p128 259:2    0    1M  0 part 
nvme1n1       259:3    0  150G  0 disk 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-91-7.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>blkid: invalid option -- 'f'
Try 'blkid -h' for more information.
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  7ad347b4-2add-4e64-a873-e1aae94539e7 
	IO Priority:  HIGH 
	Labels:  failure-domain.beta.kubernetes.io/region=us-east-1,beta.kubernetes.io/arch=amd64,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,failure-domain.beta.kubernetes.io/zone=us-east-1c,alpha.eksctl.io/nodegroup-name=storage-nodes,alpha.eksctl.io/cluster-name=nrevanna-cluster3,medium=STORAGE_MEDIUM_NVME,eks.amazonaws.com/nodegroup=storage-nodes,eks.amazonaws.com/capacityType=ON_DEMAND,beta.kubernetes.io/instance-type=t3.xlarge,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,kubernetes.io/hostname=ip-192-168-91-7.ec2.internal,kubernetes.io/os=linux,kubernetes.io/arch=amd64,eks.amazonaws.com/sourceLaunchTemplateVersion=1,iopriority=HIGH,topology.kubernetes.io/region=us-east-1,node.kubernetes.io/instance-type=t3.xlarge,topology.portworx.io/zone=us-east-1c,topology.kubernetes.io/zone=us-east-1c,topology.portworx.io/region=us-east-1,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,role=worker,beta.kubernetes.io/os=linux 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-91-7.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0   80G  0 disk 
|-nvme0n1p1   259:1    0   80G  0 part /
`-nvme0n1p128 259:2    0    1M  0 part 
nvme1n1       259:3    0  150G  0 disk 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-51-111.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>blkid: invalid option -- 'f'
Try 'blkid -h' for more information.
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>[31mPX is not running on 127.0.0.1 host: Could not reach 'HealthMonitor'[0m
[30;1m
List of last known failures:

[0m[4;1mType	ID			Resource				Severity	Count	LastSeen			FirstSeen			Description																								
[0m[31mNODE	ClusterManagerFailure	c9ae5b5a-fa3f-43ea-884f-9aae4d04dee7	ALARM		1	Sep 28 05:13:31 UTC 2022	Sep 28 05:13:31 UTC 2022	Failed to start cluster manager on node [192.168.51.111]: Unable to add a NEW node as cluster is operating at maximum capacity (5 nodes). Please remove a node before attempting to add a new node.	
[0m</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-51-111.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
nvme0n1       259:0    0  80G  0 disk 
|-nvme0n1p1   259:1    0  80G  0 part /
`-nvme0n1p128 259:2    0   1M  0 part 
</pre>
      </div>
        </div>
        </div><div data-role="header">
        <h1>Timeline</h1>
      </div>

      <div data-role="main" class="ui-content">    <div data-role="collapsible">
      <h1>Volume Timeline</h1><pre>
            ||||||||||||||||||||||||||||||||||
            ||||||||||||||||||||||||||||||||||
            \\\\\\\\\\\\\\\\\
                \\\\\\\\\\\\\\\\
                    \\\\\\\\\\\\\\
            |||||||||||||||||||||||||||||||||||
            |||||||||||||||||||||||||||||||||||
                        </pre>
    
        </div>
            <div data-role="collapsible">
      <h1>Another Timeline</h1>
        </div>
        </div><div data-role="header">
        <h1>Fingerprints</h1>
      </div>

      <div data-role="main" class="ui-content">    <div data-role="collapsible">
      <h1>Know Issues</h1><div data-role="collapsible">
        <h1>Must fix 1</h1>
        <pre>More details</pre>
      </div><div data-role="collapsible">
        <h1>Must fix 2</h1>
        <pre>More details</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>Recommended fixes</h1><div data-role="collapsible">
        <h1>Recommendation 1</h1>
        <pre>More details</pre>
      </div><div data-role="collapsible">
        <h1>Recommendation 2</h1>
        <pre>More details</pre>
      </div>
        </div>
        </div></div>

</body>
</html>