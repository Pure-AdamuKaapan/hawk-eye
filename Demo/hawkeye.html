<!DOCTYPE html>
    <html>
    <head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.css">
    <script src="https://code.jquery.com/jquery-1.11.3.min.js"></script>
    <script src="https://code.jquery.com/mobile/1.4.5/jquery.mobile-1.4.5.min.js"></script>
        <style>
      .container {
        display: flex;
        align-items: right;
        justify-content: right
      }
      img {
        max-width: 100%
      }
      .image {
        flex-basis: 70%;
        order: 1;
      }
      .text {
        color: #89CFF0;
        padding-right: 20px;
        font: italic 30px "Fira Sans", serif;
      }
    </style>

    </head>
    <body>



    <div data-role="page" id="pageone">
    <div class="container">
      <div class="text">
        <h1>Hawk-Eye</h1>
      </div>
      <div class="image">
        <img src="logo.jpeg">
      </div>
    </div>
    <div data-role="header">
        <h1>Information</h1>
      </div>

      <div data-role="main" class="ui-content">    <div data-role="collapsible">
      <h1>Cluster</h1><div data-role="collapsible">
        <h1>pxctl status</h1>
        <pre>Status: [32mPX is operational[0m
Telemetry: [33mDisabled or Unhealthy[0m
Metering: [32mHealthy[0m
License: [91mPX-Essential (ERROR: License is expired, Another cluster registered with the same userID. Unlink the previously registered cluster on PX-Central.)[0m
Node ID: 9a6378b7-7caf-474d-81bc-14c8ef4eb51f
	IP: 192.168.51.87 
 	Local Storage Pool: 1 pool
[0m	POOL	IO_PRIORITY	RAID_LEVEL	USABLE	USED	STATUS	ZONE		REGION[0m
[32m	0	HIGH		raid0		150 GiB	7.5 GiB	Online	us-east-1b	us-east-1[0m
[0m	Local Storage Devices: 1 device[0m
[0m	Device	Path		Media Type		Size		Last-Scan[0m
[32m	0:1	/dev/nvme1n1	STORAGE_MEDIUM_NVME	150 GiB		28 Sep 22 05:13 UTC[0m
[32m	total			-			150 GiB[0m
[0m	Cache Devices:[0m
[0m	 * No cache devices[0m
[0m	Kvdb Device:[0m
[0m	Device Path	Size[0m
[32m	/dev/nvme2n1	150 GiB[0m
[0m	 * Internal kvdb on this node is using this dedicated kvdb device to store its data.[0m
[0mCluster Summary[0m
[0m	Cluster ID: px-cluster-63b62bdd-3485-435b-9ab8-8e715a65c465[0m
[0m	Cluster UUID: 20fc20be-77c9-4c14-bed8-892ee7974469[0m
[0m	Scheduler: kubernetes[0m
[0m	Nodes: 5 node(s) with storage (5 online)[0m
[0m	IP		ID					SchedulerNodeName		Auth		StorageNode	Used	Capacity	Status	StorageStatus	Version		Kernel				OS[0m
[32m	192.168.82.121	ed89eb5f-1b91-43cf-a171-c906a40a799b	ip-192-168-82-121.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.51.87	9a6378b7-7caf-474d-81bc-14c8ef4eb51f	ip-192-168-51-87.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up (This node)	2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.20.4	386dd1b8-9064-48c4-adf8-edf61b8ca15c	ip-192-168-20-4.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.91.7	2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	ip-192-168-91-7.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[32m	192.168.18.191	17f392d7-342a-48fb-850f-06a8b7515ed0	ip-192-168-18-191.ec2.internal	Disabled	Yes		7.5 GiB	150 GiB		Online	Up		2.11.4-96ccc8b	5.4.209-116.367.amzn2.x86_64	Amazon Linux 2[0m
[0mGlobal Storage Pool
	Total Used    	:  38 GiB
	Total Capacity	:  750 GiB
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl cd list-drives</h1>
        <pre>[4;1mCloud Drives Summary[0m
[4;1m
Total number of drives: 8[0m
[4;1m
Drive List[0m
[37m	Drive ID		NodeID					Zone		Labels	[0m
[37m	vol-000305374238cf22a	9a6378b7-7caf-474d-81bc-14c8ef4eb51f	us-east-1b	-[0m
[37m	vol-08f00bd8e14c2c558	9a6378b7-7caf-474d-81bc-14c8ef4eb51f	us-east-1b	-[0m
[37m	vol-0413014eca3b2e85f	ed89eb5f-1b91-43cf-a171-c906a40a799b	us-east-1c	-[0m
[37m	vol-051fa18c3f2565304	ed89eb5f-1b91-43cf-a171-c906a40a799b	us-east-1c	-[0m
[37m	vol-0eaac95e300a128d4	17f392d7-342a-48fb-850f-06a8b7515ed0	us-east-1a	-[0m
[37m	vol-0ead7a2fdf768a4f9	17f392d7-342a-48fb-850f-06a8b7515ed0	us-east-1a	-[0m
[37m	vol-0fc326e672d4a2f38	2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	us-east-1c	-[0m
[37m	vol-060140db7fa5d4432	386dd1b8-9064-48c4-adf8-edf61b8ca15c	us-east-1a	-[0m

</pre>
      </div><div data-role="collapsible">
        <h1>pxctl alerts show</h1>
        <pre>[4;1mType	ID			Resource				Severity	Count	LastSeen			FirstSeen			Description																								
[0m[31mNODE	NodeStateChange		17f392d7-342a-48fb-850f-06a8b7515ed0	ALARM		1	Sep 28 05:13:07 UTC 2022	Sep 28 05:13:07 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		9a6378b7-7caf-474d-81bc-14c8ef4eb51f	ALARM		1	Sep 28 05:13:21 UTC 2022	Sep 28 05:13:21 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		386dd1b8-9064-48c4-adf8-edf61b8ca15c	ALARM		1	Sep 28 05:13:23 UTC 2022	Sep 28 05:13:23 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		ed89eb5f-1b91-43cf-a171-c906a40a799b	ALARM		1	Sep 28 05:13:24 UTC 2022	Sep 28 05:13:24 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[31mNODE	NodeStateChange		2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	ALARM		1	Sep 28 05:13:26 UTC 2022	Sep 28 05:13:26 UTC 2022	Node is not in quorum. Waiting to connect to peer nodes on port 9002. Ensure port 9002 is not blocked.													
[0m[32mNODE	NodeStartSuccess	17f392d7-342a-48fb-850f-06a8b7515ed0	NOTIFY		1	Sep 28 05:13:30 UTC 2022	Sep 28 05:13:30 UTC 2022	PX is ready on this node																						
[0m[31mNODE	ClusterManagerFailure	c9ae5b5a-fa3f-43ea-884f-9aae4d04dee7	ALARM		1	Sep 28 05:13:31 UTC 2022	Sep 28 05:13:31 UTC 2022	Failed to start cluster manager on node [192.168.51.111]: Unable to add a NEW node as cluster is operating at maximum capacity (5 nodes). Please remove a node before attempting to add a new node.	
[0m[32mNODE	NodeStartSuccess	9a6378b7-7caf-474d-81bc-14c8ef4eb51f	NOTIFY		1	Sep 28 05:13:57 UTC 2022	Sep 28 05:13:57 UTC 2022	PX is ready on this node																						
[0m[32mNODE	NodeStartSuccess	386dd1b8-9064-48c4-adf8-edf61b8ca15c	NOTIFY		1	Sep 28 05:14:03 UTC 2022	Sep 28 05:14:03 UTC 2022	PX is ready on this node																						
[0m[32mNODE	NodeStartSuccess	ed89eb5f-1b91-43cf-a171-c906a40a799b	NOTIFY		1	Sep 28 05:14:27 UTC 2022	Sep 28 05:14:27 UTC 2022	PX is ready on this node																						
[0m[32mNODE	NodeStartSuccess	2f9ab2f6-4aa1-4fa2-9d4c-3994f8723951	NOTIFY		1	Sep 28 05:14:34 UTC 2022	Sep 28 05:14:34 UTC 2022	PX is ready on this node																						
[0m[33mCLUSTER	MeteringAgentWarning						WARN		1	Sep 28 06:13:45 UTC 2022	Sep 28 06:13:45 UTC 2022	Unable to reach to billing server: Cannot send metric to the billing endpoint: Cannot send metric to the billing endpoint: Response Code: 500, error in sending metering information, Err: {"message":"cannot register usage, Err: cannot register new cluster, all available essentials licenses exhausted for user 74b6a08c-e439-11eb-8b5b-4ef4c7a81109","code":500}
	
[0m[31mCLUSTER	MeteringAgentCritical		ALARM	3	Sep 28 08:14:17 UTC 2022	Sep 28 05:13:28 UTC 2022	Unable to reach to billing server: Cannot send metric to the billing endpoint: Cannot send metric to the billing endpoint: Response Code: 500, error in sending metering information, Err: {"message":"cannot register usage, Err: cannot register new cluster, all available essentials licenses exhausted for user 74b6a08c-e439-11eb-8b5b-4ef4c7a81109","code":500}
	
[0m</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv kvdb members</h1>
        <pre>Kvdb Cluster Members: 
[4;1mID					PEER URLs				CLIENT URLs			LEADER	HEALTHY	DBSIZE[0m
[37m17f392d7-342a-48fb-850f-06a8b7515ed0	[http://portworx-1.internal.kvdb:9018]	[http://192.168.18.191:9019]	true	true	532 KiB[0m
[37m9a6378b7-7caf-474d-81bc-14c8ef4eb51f	[http://portworx-2.internal.kvdb:9018]	[http://192.168.51.87:9019]	false	true	520 KiB[0m
[37med89eb5f-1b91-43cf-a171-c906a40a799b	[http://portworx-3.internal.kvdb:9018]	[http://192.168.82.121:9019]	false	true	524 KiB[0m

</pre>
      </div><div data-role="collapsible">
        <h1>pxctl volume list</h1>
        <pre>ID	NAME	SIZE	HA	SHARED	ENCRYPTED	PROXY-VOLUME	IO_PRIORITY	STATUS	SNAP-ENABLED	
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-18-191.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>/dev/nvme0n1: PTUUID="88b9b632-8f96-41d2-8820-0d935e0d42cf" PTTYPE="gpt"
/dev/nvme0n1p1: LABEL="/" UUID="027092f5-b7f8-4b7a-8eb4-bb3417968c9b" TYPE="xfs" PARTLABEL="Linux" PARTUUID="5da2b78b-6e3b-4976-b2fa-087124118e4d"
/dev/nvme0n1p128: PARTLABEL="BIOS Boot Partition" PARTUUID="b9688053-bffe-4385-948c-01e807d94ef4"
/dev/nvme1n1: LABEL="pxpool=0,mdpoolid=0,initinprogress,mdvol" UUID="0964be4b-85b4-4d0f-8a15-4d51cc11c4b1" UUID_SUB="13a85571-5cac-4b38-b85a-1eb68f415f5f" TYPE="btrfs"
/dev/nvme2n1: LABEL="kvdbvol" UUID="fd41f82c-adb1-42b2-863c-f3f2a51b8f6f" TYPE="xfs"
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  8064eb26-52ea-43a9-9c1c-a024256c4abf 
	IO Priority:  HIGH 
	Labels:  node.kubernetes.io/instance-type=t3.xlarge,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,medium=STORAGE_MEDIUM_NVME,kubernetes.io/hostname=ip-192-168-18-191.ec2.internal,alpha.eksctl.io/nodegroup-name=storage-nodes,kubernetes.io/arch=amd64,topology.portworx.io/zone=us-east-1a,alpha.eksctl.io/cluster-name=nrevanna-cluster3,eks.amazonaws.com/sourceLaunchTemplateVersion=1,beta.kubernetes.io/os=linux,topology.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1a,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,iopriority=HIGH,failure-domain.beta.kubernetes.io/zone=us-east-1a,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,topology.portworx.io/region=us-east-1,role=worker,eks.amazonaws.com/capacityType=ON_DEMAND,beta.kubernetes.io/arch=amd64,kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=us-east-1,beta.kubernetes.io/instance-type=t3.xlarge,eks.amazonaws.com/nodegroup=storage-nodes 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-18-191.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME FSTYPE LABEL                UUID                                 MOUNTPOINT
nvme0n1
|                                                                     
|-nvme0n1p1
|    xfs    /                    027092f5-b7f8-4b7a-8eb4-bb3417968c9b /
`-nvme0n1p128
                                                                      
nvme1n1
     btrfs  pxpool=0,mdpoolid=0,initinprogress,mdvol
                                 0964be4b-85b4-4d0f-8a15-4d51cc11c4b1 
nvme2n1
     xfs    kvdbvol              fd41f82c-adb1-42b2-863c-f3f2a51b8f6f 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-82-121.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>/dev/nvme0n1: PTUUID="88b9b632-8f96-41d2-8820-0d935e0d42cf" PTTYPE="gpt"
/dev/nvme0n1p1: LABEL="/" UUID="027092f5-b7f8-4b7a-8eb4-bb3417968c9b" TYPE="xfs" PARTLABEL="Linux" PARTUUID="5da2b78b-6e3b-4976-b2fa-087124118e4d"
/dev/nvme0n1p128: PARTLABEL="BIOS Boot Partition" PARTUUID="b9688053-bffe-4385-948c-01e807d94ef4"
/dev/nvme1n1: LABEL="pxpool=0,mdpoolid=0,initinprogress,mdvol" UUID="d685bc73-4e4f-4b9f-b4c1-64f980c39a40" UUID_SUB="22650622-8757-4f28-9fcc-dd7e90de4932" TYPE="btrfs"
/dev/nvme2n1: LABEL="kvdbvol" UUID="20c7f877-8252-4305-bbc6-c10f398686c5" TYPE="xfs"
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  5f54add0-2f46-4d3c-9c70-eadb57f42041 
	IO Priority:  HIGH 
	Labels:  kubernetes.io/arch=amd64,role=worker,kubernetes.io/os=linux,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,beta.kubernetes.io/arch=amd64,eks.amazonaws.com/capacityType=ON_DEMAND,medium=STORAGE_MEDIUM_NVME,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,topology.kubernetes.io/region=us-east-1,eks.amazonaws.com/sourceLaunchTemplateVersion=1,beta.kubernetes.io/instance-type=t3.xlarge,alpha.eksctl.io/nodegroup-name=storage-nodes,topology.kubernetes.io/zone=us-east-1c,kubernetes.io/hostname=ip-192-168-82-121.ec2.internal,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,failure-domain.beta.kubernetes.io/zone=us-east-1c,iopriority=HIGH,eks.amazonaws.com/nodegroup=storage-nodes,topology.portworx.io/zone=us-east-1c,alpha.eksctl.io/cluster-name=nrevanna-cluster3,topology.portworx.io/region=us-east-1,failure-domain.beta.kubernetes.io/region=us-east-1,beta.kubernetes.io/os=linux,node.kubernetes.io/instance-type=t3.xlarge 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-82-121.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME FSTYPE LABEL                UUID                                 MOUNTPOINT
nvme0n1
|                                                                     
|-nvme0n1p1
|    xfs    /                    027092f5-b7f8-4b7a-8eb4-bb3417968c9b /
`-nvme0n1p128
                                                                      
nvme1n1
     btrfs  pxpool=0,mdpoolid=0,initinprogress,mdvol
                                 d685bc73-4e4f-4b9f-b4c1-64f980c39a40 
nvme2n1
     xfs    kvdbvol              20c7f877-8252-4305-bbc6-c10f398686c5 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-51-87.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>/dev/nvme0n1p1: LABEL="/" UUID="027092f5-b7f8-4b7a-8eb4-bb3417968c9b" TYPE="xfs" PARTLABEL="Linux" PARTUUID="5da2b78b-6e3b-4976-b2fa-087124118e4d"
/dev/nvme1n1: LABEL="initinprogress,mdpoolid=0,pxpool=0,mdvol" UUID="bc1bebad-3318-458f-baa8-92b1a25f884a" UUID_SUB="ff2d60c1-4a1e-44fc-84c6-163d0e6e1a2a" TYPE="btrfs"
/dev/nvme2n1: LABEL="kvdbvol" UUID="400955f8-e809-46e1-b2b3-3b28076d0bc2" TYPE="xfs"
/dev/nvme0n1: PTUUID="88b9b632-8f96-41d2-8820-0d935e0d42cf" PTTYPE="gpt"
/dev/nvme0n1p128: PARTLABEL="BIOS Boot Partition" PARTUUID="b9688053-bffe-4385-948c-01e807d94ef4"
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  e8e80e6e-3861-44bf-97c3-590016091c5b 
	IO Priority:  HIGH 
	Labels:  kubernetes.io/hostname=ip-192-168-51-87.ec2.internal,failure-domain.beta.kubernetes.io/region=us-east-1,alpha.eksctl.io/cluster-name=nrevanna-cluster3,eks.amazonaws.com/capacityType=ON_DEMAND,beta.kubernetes.io/instance-type=t3.xlarge,beta.kubernetes.io/arch=amd64,topology.portworx.io/region=us-east-1,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,topology.kubernetes.io/region=us-east-1,iopriority=HIGH,failure-domain.beta.kubernetes.io/zone=us-east-1b,alpha.eksctl.io/nodegroup-name=storage-nodes,medium=STORAGE_MEDIUM_NVME,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,eks.amazonaws.com/sourceLaunchTemplateVersion=1,topology.portworx.io/zone=us-east-1b,eks.amazonaws.com/nodegroup=storage-nodes,node.kubernetes.io/instance-type=t3.xlarge,role=worker,beta.kubernetes.io/os=linux,kubernetes.io/arch=amd64,kubernetes.io/os=linux,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,topology.kubernetes.io/zone=us-east-1b 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-51-87.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME FSTYPE LABEL                UUID                                 MOUNTPOINT
nvme0n1
|                                                                     
|-nvme0n1p1
|    xfs    /                    027092f5-b7f8-4b7a-8eb4-bb3417968c9b /
`-nvme0n1p128
                                                                      
nvme1n1
     btrfs  initinprogress,mdpoolid=0,pxpool=0,mdvol
                                 bc1bebad-3318-458f-baa8-92b1a25f884a 
nvme2n1
     xfs    kvdbvol              400955f8-e809-46e1-b2b3-3b28076d0bc2 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-20-4.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>/dev/nvme0n1: PTUUID="88b9b632-8f96-41d2-8820-0d935e0d42cf" PTTYPE="gpt"
/dev/nvme0n1p1: LABEL="/" UUID="027092f5-b7f8-4b7a-8eb4-bb3417968c9b" TYPE="xfs" PARTLABEL="Linux" PARTUUID="5da2b78b-6e3b-4976-b2fa-087124118e4d"
/dev/nvme0n1p128: PARTLABEL="BIOS Boot Partition" PARTUUID="b9688053-bffe-4385-948c-01e807d94ef4"
/dev/nvme1n1: LABEL="pxpool=0,mdpoolid=0,initinprogress,mdvol" UUID="c2c7ada0-7867-4304-a866-45c489673d8f" UUID_SUB="00b622db-06e3-4d6c-b546-d0fb1509303e" TYPE="btrfs"
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  f7742d86-8684-4ef7-83da-3e1b2e4c9cd3 
	IO Priority:  HIGH 
	Labels:  node.kubernetes.io/instance-type=t3.xlarge,topology.portworx.io/region=us-east-1,eks.amazonaws.com/nodegroup=storage-nodes,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,failure-domain.beta.kubernetes.io/zone=us-east-1a,beta.kubernetes.io/arch=amd64,topology.kubernetes.io/region=us-east-1,eks.amazonaws.com/capacityType=ON_DEMAND,kubernetes.io/os=linux,iopriority=HIGH,alpha.eksctl.io/cluster-name=nrevanna-cluster3,role=worker,beta.kubernetes.io/instance-type=t3.xlarge,medium=STORAGE_MEDIUM_NVME,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,alpha.eksctl.io/nodegroup-name=storage-nodes,topology.portworx.io/zone=us-east-1a,kubernetes.io/hostname=ip-192-168-20-4.ec2.internal,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,failure-domain.beta.kubernetes.io/region=us-east-1,beta.kubernetes.io/os=linux,eks.amazonaws.com/sourceLaunchTemplateVersion=1,topology.kubernetes.io/zone=us-east-1a,kubernetes.io/arch=amd64 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-20-4.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME FSTYPE LABEL                UUID                                 MOUNTPOINT
nvme0n1
|                                                                     
|-nvme0n1p1
|    xfs    /                    027092f5-b7f8-4b7a-8eb4-bb3417968c9b /
`-nvme0n1p128
                                                                      
nvme1n1
     btrfs  pxpool=0,mdpoolid=0,initinprogress,mdvol
                                 c2c7ada0-7867-4304-a866-45c489673d8f 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-91-7.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>/dev/nvme0n1: PTUUID="88b9b632-8f96-41d2-8820-0d935e0d42cf" PTTYPE="gpt"
/dev/nvme0n1p1: LABEL="/" UUID="027092f5-b7f8-4b7a-8eb4-bb3417968c9b" TYPE="xfs" PARTLABEL="Linux" PARTUUID="5da2b78b-6e3b-4976-b2fa-087124118e4d"
/dev/nvme0n1p128: PARTLABEL="BIOS Boot Partition" PARTUUID="b9688053-bffe-4385-948c-01e807d94ef4"
/dev/nvme1n1: LABEL="mdpoolid=0,pxpool=0,initinprogress,mdvol" UUID="e2b35c29-692a-46eb-95e5-1dc8225f54b3" UUID_SUB="32b56252-41e9-4357-9c18-661cce3deedb" TYPE="btrfs"
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>PX drive configuration:
Pool ID: 0 
	UUID:  7ad347b4-2add-4e64-a873-e1aae94539e7 
	IO Priority:  HIGH 
	Labels:  beta.kubernetes.io/instance-type=t3.xlarge,medium=STORAGE_MEDIUM_NVME,eks.amazonaws.com/nodegroup-image=ami-00cc7446b763f6466,alpha.eksctl.io/cluster-name=nrevanna-cluster3,topology.portworx.io/zone=us-east-1c,topology.kubernetes.io/region=us-east-1,kubernetes.io/os=linux,k8s.io/cloud-provider-aws=5de246a5bbeb40c0113d48459436a4cb,beta.kubernetes.io/os=linux,beta.kubernetes.io/arch=amd64,eks.amazonaws.com/sourceLaunchTemplateId=lt-0bf075fc176b34b9c,iopriority=HIGH,node.kubernetes.io/instance-type=t3.xlarge,kubernetes.io/arch=amd64,eks.amazonaws.com/capacityType=ON_DEMAND,failure-domain.beta.kubernetes.io/zone=us-east-1c,topology.portworx.io/region=us-east-1,alpha.eksctl.io/nodegroup-name=storage-nodes,failure-domain.beta.kubernetes.io/region=us-east-1,topology.kubernetes.io/zone=us-east-1c,role=worker,eks.amazonaws.com/nodegroup=storage-nodes,kubernetes.io/hostname=ip-192-168-91-7.ec2.internal,eks.amazonaws.com/sourceLaunchTemplateVersion=1 
	Size: 150 GiB 
	Status: [32mOnline[0m 
	Has metadata:  Yes 
	Balanced:  Yes 
	Drives:
	1: /dev/nvme1n1, Total size 150 GiB, [32mOnline[0m
	Cache Drives:
	No Cache drives found in this pool
</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-91-7.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME FSTYPE LABEL                UUID                                 MOUNTPOINT
nvme0n1
|                                                                     
|-nvme0n1p1
|    xfs    /                    027092f5-b7f8-4b7a-8eb4-bb3417968c9b /
`-nvme0n1p128
                                                                      
nvme1n1
     btrfs  mdpoolid=0,pxpool=0,initinprogress,mdvol
                                 e2b35c29-692a-46eb-95e5-1dc8225f54b3 
</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>ip-192-168-51-111.ec2.internal</h1><div data-role="collapsible">
        <h1>blkid</h1>
        <pre>/dev/nvme0n1: PTUUID="88b9b632-8f96-41d2-8820-0d935e0d42cf" PTTYPE="gpt"
/dev/nvme0n1p1: LABEL="/" UUID="027092f5-b7f8-4b7a-8eb4-bb3417968c9b" TYPE="xfs" PARTLABEL="Linux" PARTUUID="5da2b78b-6e3b-4976-b2fa-087124118e4d"
/dev/nvme0n1p128: PARTLABEL="BIOS Boot Partition" PARTUUID="b9688053-bffe-4385-948c-01e807d94ef4"
</pre>
      </div><div data-role="collapsible">
        <h1>pxctl sv pool show</h1>
        <pre>[31mPX is not running on 127.0.0.1 host: Could not reach 'HealthMonitor'[0m
[30;1m
List of last known failures:

[0m[4;1mType	ID			Resource				Severity	Count	LastSeen			FirstSeen			Description																								
[0m[31mNODE	ClusterManagerFailure	c9ae5b5a-fa3f-43ea-884f-9aae4d04dee7	ALARM		1	Sep 28 05:13:31 UTC 2022	Sep 28 05:13:31 UTC 2022	Failed to start cluster manager on node [192.168.51.111]: Unable to add a NEW node as cluster is operating at maximum capacity (5 nodes). Please remove a node before attempting to add a new node.	
[0m</pre>
      </div><div data-role="collapsible">
        <h1>Node name</h1>
        <pre>Linux ip-192-168-51-111.ec2.internal 5.4.209-116.367.amzn2.x86_64 #1 SMP Wed Aug 31 00:09:52 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
</pre>
      </div><div data-role="collapsible">
        <h1>lsblk</h1>
        <pre>NAME          FSTYPE LABEL UUID                                 MOUNTPOINT
nvme0n1                                                         
|-nvme0n1p1   xfs    /     027092f5-b7f8-4b7a-8eb4-bb3417968c9b /
`-nvme0n1p128                                                   
</pre>
      </div>
        </div>
        </div><div data-role="header">
        <h1>Timeline</h1>
      </div>

      <div data-role="main" class="ui-content">    <div data-role="collapsible">
      <h1>Volume Timeline</h1><pre>
        <img src="sharedv4.png">
        <a href="sharedv4.html">Interactive Dashboard</a>
                        </pre>
    
        </div>
            <div data-role="collapsible">
      <h1>Another Timeline</h1>
        </div>
        </div><div data-role="header">
        <h1>Fingerprints</h1>
      </div>

      <div data-role="main" class="ui-content">    <div data-role="collapsible">
      <h1>Know Issues</h1><div data-role="collapsible">
        <h1>Must fix 1</h1>
        <pre>More details</pre>
      </div><div data-role="collapsible">
        <h1>Must fix 2</h1>
        <pre>More details</pre>
      </div>
        </div>
            <div data-role="collapsible">
      <h1>Recommended fixes</h1><div data-role="collapsible">
        <h1>Recommendation 1</h1>
        <pre>More details</pre>
      </div><div data-role="collapsible">
        <h1>Recommendation 2</h1>
        <pre>More details</pre>
      </div>
        </div>
        </div></div>

</body>
</html>
